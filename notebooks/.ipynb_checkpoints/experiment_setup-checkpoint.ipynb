{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de9dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbccb8",
   "metadata": {},
   "source": [
    "# Dataset 1: Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a4a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Loading dataset 1: heart disease (continuous features) ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538cc8e",
   "metadata": {},
   "source": [
    "Load dataset one: heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5934dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_num = '../data/framingham.csv'\n",
    "\n",
    "all_features_num = ['sex', 'age', 'education', 'smoker', 'cigs_per_day', 'bp_meds', 'prevalent_stroke', 'prevelant_hyp', \\\n",
    "                    'diabetes', 'total_chol', 'sys_bp', 'dia_bp', 'bmi', 'heart_rate', 'glucose', 'heart_disease_label']\n",
    "\n",
    "data_num = pd.read_csv(filename_num, names=all_features_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920dcaa3",
   "metadata": {},
   "source": [
    "For this dataset we only look at numerical data so we drop the categorical columns. We also drop the column \"education\" for which there is no feature description on kaggle: https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129424bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cigs_per_day</th>\n",
       "      <th>total_chol</th>\n",
       "      <th>sys_bp</th>\n",
       "      <th>dia_bp</th>\n",
       "      <th>bmi</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>heart_disease_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  cigs_per_day  total_chol  sys_bp  dia_bp    bmi  heart_rate  glucose  \\\n",
       "0   39           0.0       195.0   106.0    70.0  26.97        80.0     77.0   \n",
       "1   46           0.0       250.0   121.0    81.0  28.73        95.0     76.0   \n",
       "2   48          20.0       245.0   127.5    80.0  25.34        75.0     70.0   \n",
       "3   61          30.0       225.0   150.0    95.0  28.58        65.0    103.0   \n",
       "4   46          23.0       285.0   130.0    84.0  23.10        85.0     85.0   \n",
       "\n",
       "   heart_disease_label  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num = data_num.drop('sex', axis=1).drop('smoker', axis=1).drop('bp_meds', axis=1).drop('prevalent_stroke', axis=1)\\\n",
    "    .drop('prevelant_hyp', axis=1).drop('diabetes', axis=1).drop('education', axis=1)\n",
    "\n",
    "data_num.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf05bd6",
   "metadata": {},
   "source": [
    "Remove any rows that are missing data. Afterwards there should be no more entries with NaN values. We also drop any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eca1efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    0\n",
       "cigs_per_day           0\n",
       "total_chol             0\n",
       "sys_bp                 0\n",
       "dia_bp                 0\n",
       "bmi                    0\n",
       "heart_rate             0\n",
       "glucose                0\n",
       "heart_disease_label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num = data_num.dropna()\n",
    "data_num = data_num.drop_duplicates()\n",
    "\n",
    "data_num = data_num.astype(float)\n",
    "\n",
    "data_num.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1908e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features_num = ['age', 'cigs_per_day', 'total_chol', 'sys_bp', 'dia_bp', 'bmi', 'heart_rate', 'glucose']\n",
    "outcome_name_num = 'heart_disease_label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5adf67",
   "metadata": {},
   "source": [
    "# Dataset 2: Census Income (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f645e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Loading dataset 2: census income (categorical features) ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07965e56",
   "metadata": {},
   "source": [
    "Load dataset two: census income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6dedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_cat = '../data/adult.data.csv'\n",
    "\n",
    "all_features_cat = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \\\n",
    "         'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'label']\n",
    "\n",
    "data_cat = pd.read_csv(filename_cat, names=all_features_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fa5d9",
   "metadata": {},
   "source": [
    "There is missing data in the columns workclass, native_country and occupation that needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0b8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_cat[data_cat.workclass != ' ?']\n",
    "data_cat = data_cat[data_cat.native_country != ' ?']\n",
    "data_cat = data_cat[data_cat.occupation != ' ?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d284cd",
   "metadata": {},
   "source": [
    "We will only use the categorical features of this dataset. Remove continuous columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69628566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           workclass   education       marital_status          occupation  \\\n",
       "0          State-gov   Bachelors        Never-married        Adm-clerical   \n",
       "1   Self-emp-not-inc   Bachelors   Married-civ-spouse     Exec-managerial   \n",
       "2            Private     HS-grad             Divorced   Handlers-cleaners   \n",
       "\n",
       "     relationship    race    sex  native_country   label  \n",
       "0   Not-in-family   White   Male   United-States   <=50K  \n",
       "1         Husband   White   Male   United-States   <=50K  \n",
       "2   Not-in-family   White   Male   United-States   <=50K  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat = data_cat.drop('age', axis=1).drop('fnlwgt', axis=1).drop('education_num', axis=1).drop('capital_gain', axis=1)\\\n",
    "    .drop('capital_loss', axis=1).drop('hours_per_week', axis=1)\n",
    "\n",
    "data_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba969a1",
   "metadata": {},
   "source": [
    "Transform workclass, education, marital_status, occupation, relationship, race, sex and native_country into label encoded features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd74e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>workclass_encoded</th>\n",
       "      <th>education_encoded</th>\n",
       "      <th>marital_status_encoded</th>\n",
       "      <th>occupation_encoded</th>\n",
       "      <th>relationship_encoded</th>\n",
       "      <th>race_encoded</th>\n",
       "      <th>native_country_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex   label  workclass_encoded  education_encoded  \\\n",
       "0   Male   <=50K                  5                  9   \n",
       "1   Male   <=50K                  4                  9   \n",
       "2   Male   <=50K                  2                 11   \n",
       "\n",
       "   marital_status_encoded  occupation_encoded  relationship_encoded  \\\n",
       "0                       4                   0                     1   \n",
       "1                       2                   3                     0   \n",
       "2                       0                   5                     1   \n",
       "\n",
       "   race_encoded  native_country_encoded  \n",
       "0             4                      38  \n",
       "1             4                      38  \n",
       "2             4                      38  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat['workclass_encoded'] = LabelEncoder().fit_transform(data_cat['workclass'])\n",
    "data_cat['education_encoded'] = LabelEncoder().fit_transform(data_cat['education'])\n",
    "data_cat['marital_status_encoded'] = LabelEncoder().fit_transform(data_cat['marital_status'])\n",
    "data_cat['occupation_encoded'] = LabelEncoder().fit_transform(data_cat['occupation'])\n",
    "data_cat['relationship_encoded'] = LabelEncoder().fit_transform(data_cat['relationship'])\n",
    "data_cat['race_encoded'] = LabelEncoder().fit_transform(data_cat['race'])\n",
    "data_cat['native_country_encoded'] = LabelEncoder().fit_transform(data_cat['native_country'])\n",
    "\n",
    "data_cat = data_cat.drop('workclass', axis=1).drop('education', axis=1).drop('marital_status', axis=1)\\\n",
    "    .drop('occupation', axis=1).drop('relationship', axis=1).drop('race', axis=1).drop('native_country', axis=1)\n",
    "    \n",
    "data_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32cd22",
   "metadata": {},
   "source": [
    "Transform label and sex into binary encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bb8bc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_encoded</th>\n",
       "      <th>education_encoded</th>\n",
       "      <th>marital_status_encoded</th>\n",
       "      <th>occupation_encoded</th>\n",
       "      <th>relationship_encoded</th>\n",
       "      <th>race_encoded</th>\n",
       "      <th>native_country_encoded</th>\n",
       "      <th>female</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_encoded  education_encoded  marital_status_encoded  \\\n",
       "0                  5                  9                       4   \n",
       "1                  4                  9                       2   \n",
       "2                  2                 11                       0   \n",
       "\n",
       "   occupation_encoded  relationship_encoded  race_encoded  \\\n",
       "0                   0                     1             4   \n",
       "1                   3                     0             4   \n",
       "2                   5                     1             4   \n",
       "\n",
       "   native_country_encoded  female  income  \n",
       "0                      38       0       0  \n",
       "1                      38       0       0  \n",
       "2                      38       0       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat['female'] = data_cat['sex'].map( {' Male': 0, ' Female': 1} )\n",
    "data_cat['income'] = data_cat['label'].map( {' <=50K': 0, ' >50K': 1} )\n",
    "\n",
    "data_cat = data_cat.drop('sex', axis=1).drop('label', axis=1)\n",
    "\n",
    "data_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1cb2f5",
   "metadata": {},
   "source": [
    "Drop duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b735c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_cat.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da608ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features_cat = []\n",
    "\n",
    "outcome_name_cat = 'income'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181b1b2",
   "metadata": {},
   "source": [
    "# Membership Inference and Training Data Extraction Experiment Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2080c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XaiPrivacyExperiment():\n",
    "    \"\"\"Generic framework for an XAI and data privacy experiment (membership inference or training data extraction)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    rs, rng\n",
    "        Random states for numpy\n",
    "    data\n",
    "        Pandas dataframe of the dataset that the experiment is executed on. Contains features and labels.\n",
    "    continuous_features : list[str]\n",
    "        The continuous feature names of the dataset.\n",
    "    categorical_features : list[str]\n",
    "        The categorical feature names of the dataset.\n",
    "    outcome_name : str\n",
    "        The name of the column that contains the labels.\n",
    "    features\n",
    "        Pandas dataframe that only contains the feature values of all samples (not labels).\n",
    "    labels\n",
    "        Pandas dataframe that only contains the labels of all samples (not features).\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    membership_inference_experiment(repetitions: int, model, model_access: bool)\n",
    "        Executes membership inference experiment\n",
    "    train_explainer(data_train, model):\n",
    "        Trains the explainer on the given data and model (abstract method).\n",
    "    membership_inference_attack_model_access(explainer, samples_df, model):\n",
    "        Executes membership inference attack with access to the model\n",
    "    membership_inference_attack_no_model_access(explainer, samples_df):\n",
    "        Executes membership inference attack without access to the model\n",
    "    training_data_extraction_model_access(explainer, stop_after, feature_format, rng, model):\n",
    "        Executes training data extraction attack with access to the model\n",
    "    training_data_extraction_no_model_access(explainer, stop_after, feature_format, rng):\n",
    "        Executes training data extraction attack without access to the model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, continuous_features, outcome_name, random_state: int):\n",
    "        \"\"\"        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data\n",
    "            Pandas dataframe of the dataset that the experiment is executed on. Contains features and labels.\n",
    "        continuous_features : list[str]\n",
    "            The continuous feature names of the dataset.\n",
    "        outcome_name : str\n",
    "            The name of the column that contains the labels.\n",
    "        random_state: int\n",
    "            The seed for all random actions during the experiment (such as drawing test samples)\n",
    "        \"\"\"\n",
    "        # create random state from seed. This will be used for all random actions (such as drawing test samples)\n",
    "        self.rs = np.random.RandomState(seed=random_state)\n",
    "        self.rng = np.random.default_rng(random_state)\n",
    "        random.seed(random_state)\n",
    "        \n",
    "        self.data = data\n",
    "        self.continuous_features = continuous_features\n",
    "        self.outcome_name = outcome_name\n",
    "    \n",
    "        # split dataset into features and labels.\n",
    "        self.features = self.data.drop(outcome_name, axis=1)\n",
    "        self.labels = self.data[outcome_name]\n",
    "        \n",
    "        # names of the categorical features\n",
    "        self.categorical_features = self.features.columns.difference(continuous_features)\n",
    "    \n",
    "    def membership_inference_experiment(self, repetitions: int, model, model_access: bool):\n",
    "        \"\"\"Executes membership inference experiment\n",
    "        \n",
    "        Executes the membership inference experiment with the dataset that this object was instantiated with. Trains given\n",
    "        model on half the dataset and tests accuracy, precision and recall of the implemented membership inference attack.\n",
    "        If model_access is True, the attack method with the parameter \"model\" is used (the attacker has access to the model).\n",
    "        Otherwise, the attack method without that parameter is used (the attacker has no access to the model).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        repetitions : int\n",
    "            Number of test samples that the membership inference attack is attempted on. Should not be greater the len(data)\n",
    "        model\n",
    "            The untrained model used in the experiment\n",
    "        model_access : bool\n",
    "            Whether the membership inference attack is executed with attacker access to the model or without.\n",
    "        \"\"\"\n",
    "        # create pipeline that transforms categorical features to one hot encoding\n",
    "        model = self._model_pipeline(model)\n",
    "\n",
    "        # split data into two halves (one is used for training and inference, the other only for inference)\n",
    "        # data_train contains all training samples with labels, while x_train only contains the samples without labels\n",
    "        # and y_train only contains the labels without features.\n",
    "        data_train, x_train, y_train, x_ctrl, y_ctrl = self._split_data()\n",
    "\n",
    "        # train classifier on training data\n",
    "        model = model.fit(x_train, y_train)\n",
    "\n",
    "        # train explainer on training data and classifier\n",
    "        explainer = self.train_explainer(data_train, model)\n",
    "        \n",
    "        # draw test samples from training and control data. record each sample's membership in training data.\n",
    "        samples_df, actual_membership = self._draw_test_samples(repetitions, x_train, x_ctrl)\n",
    "            \n",
    "        # infer membership using membership inference attack against the explainer\n",
    "        if model_access:\n",
    "            inferred_membership = self.membership_inference_attack_model_access(explainer, samples_df, model)\n",
    "        else:\n",
    "            inferred_membership = self.membership_inference_attack_no_model_access(explainer, samples_df)\n",
    "\n",
    "        # calculate accuracy, precision and recall\n",
    "        return self._calc_accuracy_precision_recall(repetitions, actual_membership, inferred_membership)\n",
    "\n",
    "    def training_data_extraction_experiment(self, stop_after: None or int, model, model_access: bool):\n",
    "        \"\"\"Executes training data extraction experiment\n",
    "        \n",
    "        Executes the training data extraction experiment with the dataset that this object was instantiated with. Trains given\n",
    "        model on dataset and tests precision and recall of the implemented training data extraction attack.\n",
    "        If model_access is True, the attack method with the parameter \"model\" is used (the attacker has access to the model).\n",
    "        Otherwise, the attack method without that parameter is used (the attacker has no access to the model).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        stop_after : None or int\n",
    "            The amount of samples that the attack is meant to attempt extraction for. If None, the attack attempts to extract\n",
    "            the entire dataset.\n",
    "        model\n",
    "            The untrained model used in the experiment.\n",
    "        model_access : bool\n",
    "            Whether the attack is executed with attacker access to the model or without.\n",
    "        \"\"\"\n",
    "        # create pipeline that transforms categorical features to one hot encoding\n",
    "        model = self._model_pipeline(model)\n",
    "\n",
    "        # train classifier on dataset\n",
    "        model = model.fit(self.features, self.labels)\n",
    "\n",
    "        # train explainer on training data and classifier\n",
    "        explainer = self.train_explainer(self.data, model)\n",
    "        \n",
    "        # generate the feature format information that is available to the attacker\n",
    "        feature_format = self._generate_feature_info(self.features, self.continuous_features)\n",
    "            \n",
    "        # extract samples using training data extraction attack against the explainer\n",
    "        if model_access:\n",
    "            extracted_samples = self.training_data_extraction_model_access(explainer, stop_after, feature_format, self.rng, model)\n",
    "        else:\n",
    "            extracted_samples = self.training_data_extraction_no_model_access(explainer, stop_after, feature_format, self.rng)\n",
    "\n",
    "        # compare the extracted samples to the training data -> number of accurate extractions\n",
    "        accurate_samples, num_extracted_samples, all_samples = self._compare_data(extracted_samples, self.data, stop_after)\n",
    "            \n",
    "        # calculate precision and recall\n",
    "        return self._calc_precision_recall_tde(accurate_samples, num_extracted_samples, all_samples)\n",
    "    \n",
    "    def _model_pipeline(self, model):\n",
    "        if len(self.categorical_features) > 0:\n",
    "            # Define transformer to transform categorical features into one-hot encoding\n",
    "            categorical_transformer = Pipeline(steps=[\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ])\n",
    "\n",
    "            transformations = ColumnTransformer(transformers=[\n",
    "                ('cat', categorical_transformer, self.categorical_features)\n",
    "            ])\n",
    "\n",
    "\n",
    "            return Pipeline(steps=[('preprocessor', transformations),\n",
    "                                  ('classifier', model)])\n",
    "        else:\n",
    "            # if there are no categorical features, then nothing needs to be transformed\n",
    "            return model\n",
    "    \n",
    "    def _split_data(self):\n",
    "        # split data into two halves. One is used for training, the other as control data that is not part of the training data.\n",
    "        # this control data will be needed as test samples that do not belong to the training data.\n",
    "        idx_mid = int(self.features.shape[0] / 2)\n",
    "\n",
    "        data_train = self.data.iloc[idx_mid:, :]\n",
    "        \n",
    "        x_train = self.features.iloc[idx_mid:, :]\n",
    "        y_train = self.labels.iloc[idx_mid:]\n",
    "        \n",
    "        x_ctrl = self.features.iloc[:idx_mid, :]\n",
    "        y_ctrl = self.labels.iloc[:idx_mid]\n",
    "        \n",
    "        return data_train, x_train, y_train, x_ctrl, y_ctrl\n",
    "    \n",
    "    def _draw_test_samples(self, repetitions, x_train, x_ctrl):\n",
    "        # create new dataframe that will hold all test samples for the experiment\n",
    "        samples_df = pd.DataFrame(columns=list(self.features.columns.values))\n",
    "        \n",
    "        # record each test samples actual membership. If the sample comes from the training data -> True. If the sample comes\n",
    "        # from the control data -> False.\n",
    "        sample_membership = np.empty(repetitions)\n",
    "\n",
    "        # half the test samples come from the training data, the other half from the control data\n",
    "        for i in range(repetitions):\n",
    "            if i % 2 == 0:\n",
    "                # choose sample from training data.\n",
    "                sample = x_train.sample(random_state=self.rs)\n",
    "                sample_membership[i] = True\n",
    "                logging.debug('%s taken from training data' % sample.to_numpy())\n",
    "            else:\n",
    "                # choose sample from control data.\n",
    "                sample = x_ctrl.sample(random_state=self.rs)\n",
    "                sample_membership[i] = False\n",
    "                logging.debug('%s taken from control data' % sample.to_numpy())\n",
    "\n",
    "            samples_df = samples_df.append(sample, ignore_index=True)\n",
    "            \n",
    "        return samples_df, sample_membership\n",
    "    \n",
    "    @staticmethod\n",
    "    def _calc_accuracy_precision_recall(repetitions, actual_membership, inferred_membership):\n",
    "        samples_in_training_data = np.count_nonzero(actual_membership)\n",
    "        samples_not_in_training_data = repetitions - samples_in_training_data\n",
    "\n",
    "        pred_positives = np.count_nonzero(inferred_membership)\n",
    "\n",
    "        correct_predictions = np.count_nonzero(np.equal(inferred_membership, actual_membership))\n",
    "        true_positives = np.count_nonzero(inferred_membership[actual_membership == True])\n",
    "\n",
    "        accuracy = correct_predictions / repetitions\n",
    "        if pred_positives > 0:\n",
    "            precision = true_positives / pred_positives\n",
    "        else:\n",
    "            # If the attack predicted membership for no test sample then precision cannot be calculated\n",
    "            precision = float(\"NaN\")\n",
    "        recall = true_positives / samples_in_training_data\n",
    "        \n",
    "        print(f'Accuracy: {accuracy}, precision: {precision}, recall: {recall}')\n",
    "        \n",
    "        return accuracy, precision, recall\n",
    "    \n",
    "    @staticmethod\n",
    "    def _generate_feature_info(features, continuous_features):\n",
    "        feature_information = []\n",
    "        \n",
    "        features_np = features.to_numpy()\n",
    "        \n",
    "        # Get the minimum and maximum value for all continuous features in the training data.\n",
    "        # Get the categories for all categorical features.\n",
    "        for i, feature_name in enumerate(features.columns.values):\n",
    "            this_feature = {'name': feature_name}\n",
    "\n",
    "            if feature_name in continuous_features:\n",
    "                this_feature['isCont'] = True\n",
    "\n",
    "                this_feature['min'] = np.amin(features_np[:, i])\n",
    "                this_feature['max'] = np.amax(features_np[:, i])\n",
    "\n",
    "            else:\n",
    "                this_feature['isCont'] = False\n",
    "\n",
    "                this_feature['categories'] = features[feature_name].unique()\n",
    "\n",
    "            feature_information.append(this_feature)\n",
    "            \n",
    "        return feature_information\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compare_data(extracted_samples, actual_samples, stop_after: None or int):\n",
    "        # convert data to numpy so that comparison becomes simpler\n",
    "        extracted_samples = extracted_samples.to_numpy().astype(float)\n",
    "        actual_samples = actual_samples.to_numpy().astype(float)\n",
    "        \n",
    "        # If only the features (without the labels) were extracted, then the labels are cut off from the actual_samples array\n",
    "        # in order to be able to compare the two arrays\n",
    "        if actual_samples.shape[1] > extracted_samples.shape[1]:\n",
    "            actual_samples = actual_samples[:,:-1]\n",
    "            \n",
    "        # drop duplicates from the extracted samples and from the actual samples to get accurate precision/recall\n",
    "        extracted_samples = np.unique(extracted_samples, axis=0)\n",
    "        actual_samples = np.unique(actual_samples, axis=0)\n",
    "        \n",
    "        # all_samples is the maximum amount of samples that could have been extracted during this attack\n",
    "        # If stop_after is None, it means the attack attempted to extracted all samples in the training data.\n",
    "        # Otherwise the attack stopped after the first stop_after training samples.\n",
    "        if stop_after is None:\n",
    "            all_samples = len(actual_samples)\n",
    "        else:\n",
    "            all_samples = stop_after\n",
    "        \n",
    "        num_extracted_samples = extracted_samples.shape[0]\n",
    "        num_accurate_samples = 0\n",
    "        \n",
    "        for extracted_sample in extracted_samples:\n",
    "            logging.debug(f'Extracted sample: {extracted_sample}')\n",
    "\n",
    "            # Get all indices of the extracted sample in the given training data. features_np == row creates a boolean array \n",
    "            # with True if the cells match and False otherwise. all(axis=1) returns for each row if all elements in the row \n",
    "            # are True. np.where returns an array of indices where the boolean array contains the value True.\n",
    "            close_values = np.isclose(actual_samples, extracted_sample)\n",
    "            close_rows = close_values.all(axis=1)\n",
    "            indices_of_sample = np.where(close_rows)[0]\n",
    "\n",
    "            if indices_of_sample.shape[0] > 0:\n",
    "                logging.debug(f'Appears in training data at indices {indices_of_sample}')\n",
    "                num_accurate_samples += 1\n",
    "            else:\n",
    "                logging.debug('Does not appear in training data')\n",
    "        \n",
    "        return num_accurate_samples, num_extracted_samples, all_samples\n",
    "    \n",
    "    @staticmethod\n",
    "    def _calc_precision_recall_tde(accurate_samples, num_extracted_samples, all_samples):\n",
    "        # Percentage of extracted samples that actually appears within the training data\n",
    "        if num_extracted_samples > 0:\n",
    "            precision = accurate_samples / num_extracted_samples\n",
    "        else:\n",
    "            # If the attack did not extract a single sample then precision cannot be calculated\n",
    "            precision = float(\"NaN\")\n",
    "\n",
    "        recall = accurate_samples / all_samples\n",
    "        \n",
    "        print(f'Number of extracted samples: {num_extracted_samples}')\n",
    "        print(f'Number of accurate extracted samples: {accurate_samples}')\n",
    "        print(f'Precision: {precision}, recall: {recall}')\n",
    "        \n",
    "        return precision, recall\n",
    "    \n",
    "    def train_explainer(self, data_train, model):\n",
    "        \"\"\"Trains the explainer on the given data and model\n",
    "        \n",
    "        Abstract method that must be implemented by subclass. Returns the explainer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data_train\n",
    "            The training data (features and labels).\n",
    "        model\n",
    "            The trained model that will be explained by the explainer.\n",
    "            \n",
    "        Raises\n",
    "        ------\n",
    "        NotImplementedError\n",
    "            Must be implemented by subclass.\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @staticmethod\n",
    "    def membership_inference_attack_model_access(explainer, samples_df, model):\n",
    "        \"\"\"Executes membership inference attack with access to the model\n",
    "        \n",
    "        Abstract method that must be implemented by subclass. Executes the attack against the explainer with access to the \n",
    "        model. Infers membership for each sample in samples_df. Returns an numpy array with boolean values indicating the \n",
    "        inferred membership of each test sample. Must be same length as samples_df.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        explainer\n",
    "            The explainer or explanation that will be attacked.\n",
    "        samples_df\n",
    "            A pandas dataframe that contains the feature values of all test samples.\n",
    "        model\n",
    "            The trained model that is explained by the explainer.\n",
    "            \n",
    "        Raises\n",
    "        ------\n",
    "        NotImplementedError\n",
    "            Must be implemented by subclass.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @staticmethod\n",
    "    def membership_inference_attack_no_model_access(explainer, samples_df):\n",
    "        \"\"\"Executes membership inference attack without access to the model\n",
    "        \n",
    "        Abstract method that must be implemented by subclass. Executes the attack against the explainer without access to the \n",
    "        model. Infers membership for each sample in samples_df. Returns an numpy array with boolean values indicating the \n",
    "        inferred membership of each test sample. Must be same length as samples_df.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        explainer\n",
    "            The explainer or explanation that will be attacked.\n",
    "        samples_df\n",
    "            A pandas dataframe that contains the feature values of all test samples.\n",
    "            \n",
    "        Raises\n",
    "        ------\n",
    "        NotImplementedError\n",
    "            Must be implemented by subclass.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @staticmethod\n",
    "    def training_data_extraction_model_access(explainer, stop_after, feature_format, rng, model):\n",
    "        \"\"\"Executes training data extraction attack with access to the model\n",
    "        \n",
    "        Abstract method that must be implemented by subclass. Executes the attack against the explainer with access to the \n",
    "        model. Attempts to extract stop_after samples. If stop_after is None, attempt to extract all samples. \n",
    "        Returns a dataframe containing all extracted samples.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        explainer\n",
    "            The explainer or explanation that will be attacked.\n",
    "        stop_after : None or int\n",
    "            The amount of samples that the attack is meant to attempt extraction for. If None, the attack attempts to extract\n",
    "            the entire dataset.\n",
    "        feature_format\n",
    "            A dictionary that contains information for each sample (whether it is continuous or categorical, minimum, maximum,\n",
    "            the categories)\n",
    "        rng\n",
    "            Numpy rng object that can be used for reproducible random decisions.\n",
    "        model\n",
    "            The trained model that is explained by the explainer.\n",
    "            \n",
    "        Raises\n",
    "        ------\n",
    "        NotImplementedError\n",
    "            Must be implemented by subclass.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @staticmethod\n",
    "    def training_data_extraction_no_model_access(explainer, stop_after, feature_format, rng):\n",
    "        \"\"\"Executes training data extraction attack without access to the model\n",
    "        \n",
    "        Abstract method that must be implemented by subclass. Executes the attack against the explainer without access to the \n",
    "        model. Attempts to extract stop_after samples. If stop_after is None, attempt to extract all samples. \n",
    "        Returns a dataframe containing all extracted samples.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        explainer\n",
    "            The explainer or explanation that will be attacked.\n",
    "        stop_after : None or int\n",
    "            The amount of samples that the attack is meant to attempt extraction for. If None, the attack attempts to extract\n",
    "            the entire dataset.\n",
    "        feature_format\n",
    "            A dictionary that contains information for each sample (whether it is continuous or categorical, minimum, maximum,\n",
    "            the categories)\n",
    "        rng\n",
    "            Numpy rng object that can be used for reproducible random decisions.\n",
    "            \n",
    "        Raises\n",
    "        ------\n",
    "        NotImplementedError\n",
    "            Must be implemented by subclass.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc760a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
