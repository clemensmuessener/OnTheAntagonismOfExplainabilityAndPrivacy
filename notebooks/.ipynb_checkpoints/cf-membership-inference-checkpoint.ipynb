{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75916e17",
   "metadata": {},
   "source": [
    "# Counterfactuals Membership Inference Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6661d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.ensemble as es\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import dice_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a61bbc",
   "metadata": {},
   "source": [
    "This notebook will test whether membership inference is possible with counterfactuals (CF) that are drawn from the training data. Membership inference means an attacker with access to the explanation can determine for any sample whether it was included in the training data or not.\n",
    "\n",
    "First we define the function that will run the experiment for the different variations. The attacker obtains a counterfactual for the test sample (\"counterfactual \\#1\"). They access the explainer a second time to receive a counterfactual for counterfactual \\#1 (\"counterfactual \\#2\"). Counterfactual \\#2 should have the same class as the original test sample. If counterfactual \\#2 is equal to the test sample, then the test sample must be part of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937b3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: pandas dataframe of the all samples in the dataset\n",
    "# repetitions: number of experiment repetitions\n",
    "# continuous_features: names of the continuous features in the training data\n",
    "# outcome_name: name of the label in the training data\n",
    "# clf: machine learning classifier to train on the training data\n",
    "# random_state: seed for random decisions\n",
    "# returns: accuracy, sensitivity and specificity of membership inference with counterfactuals\n",
    "def experiment(data, repetitions, continuous_features, outcome_name, clf, random_state=0):\n",
    "    # create random state from seed. This will be used to draw the test samples for the experiment.\n",
    "    rs = np.random.RandomState(seed=random_state)\n",
    "    \n",
    "    # split dataset into features and labels.\n",
    "    features = data.drop(outcome_name, axis=1)\n",
    "    labels = data[outcome_name]\n",
    "    \n",
    "    # names of the categorical features\n",
    "    categorical_features = features.columns.difference(continuous_features)\n",
    "    \n",
    "    logging.debug(\"Categorical features: %s\" % categorical_features)\n",
    "    \n",
    "    # DiCE needs categorical features to be strings:\n",
    "    for col in categorical_features:\n",
    "        data[col]= data[col].astype(str)\n",
    "        features[col] = features[col].astype(str)\n",
    "    \n",
    "    if len(categorical_features) > 0:\n",
    "        # DiCE did not work without this pipeline for categorical features\n",
    "        # Define transformer to transform categorical features into one-hot encoding\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        transformations = ColumnTransformer(transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    \n",
    "        clf = Pipeline(steps=[('preprocessor', transformations),\n",
    "                              ('classifier', clf)])\n",
    "    else:\n",
    "        # if there are no categorical features, then nothing needs to be transformed\n",
    "        pass\n",
    "        \n",
    "    # split data into two halves. One is used for training, the other as control data that is not part of the training data.\n",
    "    # this control data will be needed as test samples that do not belong to the training data.\n",
    "    idx_mid = int(features.shape[0] / 2)\n",
    "\n",
    "    x_ctrl = features.iloc[:idx_mid, :]\n",
    "    y_ctrl = labels.iloc[:idx_mid]\n",
    "\n",
    "    x_train = features.iloc[idx_mid:, :]\n",
    "    y_train = labels.iloc[idx_mid:]\n",
    "        \n",
    "    # train classifier on training data\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    \n",
    "    # train explainer on training data\n",
    "    # use method \"kd-tree\" to get counterfactuals drawn from the training data\n",
    "    d = dice_ml.Data(dataframe=data.iloc[idx_mid:, :], continuous_features=continuous_features,\\\n",
    "                     outcome_name=outcome_name)\n",
    "    m = dice_ml.Model(model=clf, backend=\"sklearn\", model_type='classifier')\n",
    "    exp = dice_ml.Dice(d, m, method=\"kdtree\")\n",
    "\n",
    "    # boolean numpy arrays for actual and inferred membership of the test samples\n",
    "    sample_membership = np.empty(repetitions)\n",
    "    inferred_membership = np.empty(repetitions)\n",
    "    \n",
    "    for i in range(repetitions):\n",
    "        if i % 2 == 0:\n",
    "            # choose sample from training data.\n",
    "            sample = x_train.sample(random_state=rs)\n",
    "            sample_membership[i] = True\n",
    "            logging.debug('%s taken from training data' % sample.to_numpy())\n",
    "        else:\n",
    "            # choose sample from control data.\n",
    "            sample = x_ctrl.sample(random_state=rs)\n",
    "            sample_membership[i] = False\n",
    "            logging.debug('%s taken from control data' % sample.to_numpy())\n",
    "        \n",
    "        # infer membership using membership inference attack against the explainer\n",
    "        inferred_membership[i] = cf_membership_inference(exp, sample, clf)\n",
    "        \n",
    "    # calculate accuracy, sensitivity and specificity\n",
    "    samples_in_training_data = np.count_nonzero(sample_membership)\n",
    "    samples_not_in_training_data = repetitions - samples_in_training_data\n",
    "        \n",
    "    correct_predictions = np.count_nonzero(np.equal(inferred_membership, sample_membership))\n",
    "    predict_in_training_data_correct = np.count_nonzero(inferred_membership[sample_membership == True])\n",
    "    predict_not_in_training_data_correct = np.count_nonzero(inferred_membership[sample_membership == False] == False)\n",
    "                \n",
    "    ratio_correct = correct_predictions / repetitions\n",
    "    ratio_correct_td = predict_in_training_data_correct / samples_in_training_data\n",
    "    ratio_correct_cd = predict_not_in_training_data_correct / samples_not_in_training_data\n",
    "        \n",
    "    print('Membership Inference Accuracy: %s, Sensitivity: %s, Specificity: %s'\\\n",
    "          % (ratio_correct, ratio_correct_td, ratio_correct_cd))\n",
    "    \n",
    "    return ratio_correct, ratio_correct_td, ratio_correct_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fee7d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer: the trained counterfactual explainer (DiCE)\n",
    "# sample_df: a dataframe containing a single test sample for membership inference\n",
    "# clf: the model. needed because of a bug in DiCE (see comments in method)\n",
    "def cf_membership_inference(explainer, sample_df, clf):\n",
    "    logging.debug(f'Test sample: {sample_df.to_numpy()}')\n",
    "    \n",
    "    # there is an issue with dice where desired_class=\"opposite\" does not calculate counterfactuals of opposite class for \n",
    "    # class 1: https://github.com/interpretml/DiCE/issues/215\n",
    "    # this is why we need to manually set the desired class. This requires access to the model which would otherwise not be\n",
    "    # necessary.\n",
    "    model_pred = clf.predict(sample_df)[0]\n",
    "    logging.debug(f'Prediction by model: {model_pred}')\n",
    "    \n",
    "    # get one counterfactual for test sample:\n",
    "    e1 = explainer.generate_counterfactuals(sample_df, total_CFs=1, desired_class=int(1-model_pred))\n",
    "    cf_dataframe = e1.cf_examples_list[0].final_cfs_df\n",
    "    logging.debug('1st counterfactual: %s' % cf_dataframe.to_numpy())\n",
    "    \n",
    "    # get model prediction as workaround against the DiCE bug mentioned above\n",
    "    model_pred = clf.predict(cf_dataframe)[0]\n",
    "    logging.debug(f'Prediction by model: {model_pred}')\n",
    "    \n",
    "    # get counterfactual for counterfactual:\n",
    "    e2 = explainer.generate_counterfactuals(cf_dataframe, total_CFs=1, desired_class=int(1-model_pred))\n",
    "    cf_cf_df = e2.cf_examples_list[0].final_cfs_df\n",
    "    \n",
    "    logging.debug('2nd counterfactual: %s' % cf_cf_df.to_numpy())\n",
    "    logging.debug(f'Prediction by model: {clf.predict(cf_cf_df)}')\n",
    "\n",
    "    # if the counter-counterfactual is equal to the test sample, then it is part of the training data:\n",
    "    # np.isclose is used for comparison because explainer may round floating point values\n",
    "    result = np.isclose(cf_cf_df.to_numpy().astype(float), sample_df.to_numpy().astype(float)).all()\n",
    "    \n",
    "    logging.debug('Inferred membership: %s' % result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ad724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2ef61e5",
   "metadata": {},
   "source": [
    "# Dataset 1: Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7e1e9",
   "metadata": {},
   "source": [
    "Load dataset one: heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "035f86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/framingham.csv'\n",
    "\n",
    "names = ['sex', 'age', 'education', 'smoker', 'cigs_per_day', 'bp_meds', 'prevalent_stroke', 'prevelant_hyp', 'diabetes', \\\n",
    "         'total_chol', 'sys_bp', 'dia_bp', 'bmi', 'heart_rate', 'glucose', 'heart_disease_label']\n",
    "\n",
    "data = pd.read_csv(filename, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59b38b",
   "metadata": {},
   "source": [
    "For this dataset we only look at numerical data so we drop the categorical columns. We also drop the column \"education\" for which there is no feature description on kaggle: https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c74db71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>total_chol</th>\n",
       "      <th>sys_bp</th>\n",
       "      <th>dia_bp</th>\n",
       "      <th>bmi</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>heart_disease_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  total_chol  sys_bp  dia_bp    bmi  heart_rate  glucose  \\\n",
       "0   39       195.0   106.0    70.0  26.97        80.0     77.0   \n",
       "1   46       250.0   121.0    81.0  28.73        95.0     76.0   \n",
       "2   48       245.0   127.5    80.0  25.34        75.0     70.0   \n",
       "3   61       225.0   150.0    95.0  28.58        65.0    103.0   \n",
       "4   46       285.0   130.0    84.0  23.10        85.0     85.0   \n",
       "\n",
       "   heart_disease_label  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num = data.drop('sex', axis=1).drop('smoker', axis=1).drop('bp_meds', axis=1).drop('prevalent_stroke', axis=1)\\\n",
    "    .drop('prevelant_hyp', axis=1).drop('diabetes', axis=1).drop('education', axis=1)\n",
    "\n",
    "# This feature caused warnings for the counterfactual explainer ('MAD is zero')\n",
    "data_num = data_num.drop('cigs_per_day', axis=1)\n",
    "\n",
    "data_num.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5added0a",
   "metadata": {},
   "source": [
    "Remove any rows that are missing data. Afterwards there should be no more entries with NaN values. We also drop any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "81a93713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    0\n",
       "total_chol             0\n",
       "sys_bp                 0\n",
       "dia_bp                 0\n",
       "bmi                    0\n",
       "heart_rate             0\n",
       "glucose                0\n",
       "heart_disease_label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num = data_num.dropna()\n",
    "data_num = data_num.drop_duplicates()\n",
    "\n",
    "data_num_100 = data_num.sample(n = 100, random_state=13)\n",
    "data_num_100 = data_num_100.reset_index(drop=True)\n",
    "\n",
    "continuous_features_num = ['age', 'total_chol', 'sys_bp', 'dia_bp', 'bmi', 'heart_rate', 'glucose']\n",
    "outcome_name_num = 'heart_disease_label'\n",
    "\n",
    "data_num.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a2083",
   "metadata": {},
   "source": [
    "We now generate five counterfactuals for the first sample from the training data to demonstrate counterfactual explanations in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "64c4cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_num.drop('heart_disease_label', axis=1)\n",
    "labels = data_num['heart_disease_label']\n",
    "\n",
    "# Train a random forest classifier on training data.\n",
    "clf = es.RandomForestClassifier(random_state=0)\n",
    "clf = clf.fit(features, labels)\n",
    "\n",
    "# Train explainer\n",
    "d = dice_ml.Data(dataframe=data_num, continuous_features=continuous_features_num, outcome_name=outcome_name_num)\n",
    "\n",
    "\n",
    "m = dice_ml.Model(model=clf, backend=\"sklearn\", model_type='classifier')\n",
    "# Generating counterfactuals from training data (kd-tree)\n",
    "exp = dice_ml.Dice(d, m, method=\"kdtree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "508a451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>total_chol</th>\n",
       "      <th>sys_bp</th>\n",
       "      <th>dia_bp</th>\n",
       "      <th>bmi</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>heart_disease_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  total_chol  sys_bp  dia_bp    bmi  heart_rate  glucose  \\\n",
       "0   39       195.0   106.0    70.0  26.97        80.0     77.0   \n",
       "\n",
       "   heart_disease_label  \n",
       "0                    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 1.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>total_chol</th>\n",
       "      <th>sys_bp</th>\n",
       "      <th>dia_bp</th>\n",
       "      <th>bmi</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>heart_disease_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>41.0</td>\n",
       "      <td>-</td>\n",
       "      <td>120.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>22.91</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>41.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>63.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>-</td>\n",
       "      <td>77.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>44.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>106.9</td>\n",
       "      <td>-</td>\n",
       "      <td>23.98</td>\n",
       "      <td>92.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>64.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.1</td>\n",
       "      <td>24.77</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>51.0</td>\n",
       "      <td>-</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.9</td>\n",
       "      <td>21.51</td>\n",
       "      <td>81.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age total_chol sys_bp dia_bp    bmi heart_rate glucose  \\\n",
       "2137  41.0          -  120.5   76.0  22.91       75.0    71.0   \n",
       "3406  41.0      212.0  112.0   63.5   25.2          -    77.1   \n",
       "4188  44.0      180.0  106.9      -  23.98       92.0    67.0   \n",
       "1358  64.0      210.0  120.0   70.1  24.77          -       -   \n",
       "4119  51.0          -  122.0   70.9  21.51       81.0    64.0   \n",
       "\n",
       "     heart_disease_label  \n",
       "2137                 1.0  \n",
       "3406                 1.0  \n",
       "4188                 1.0  \n",
       "1358                 1.0  \n",
       "4119                   -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e1 = exp.generate_counterfactuals(features[0:1], total_CFs=5, desired_class=\"opposite\")\n",
    "e1.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084cf1e0",
   "metadata": {},
   "source": [
    "We can see that the counterfactuals are similar to the query sample and that most of them have a flipped prediction. These are the two general properties of counterfactual explanations.\n",
    "\n",
    "We will now do a small proof of concept of the experiment with logging enabled to demonstrate how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cacf1093",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Categorical features: Index([], dtype='object')\n",
      "DEBUG:root:[[ 37.   185.    99.    59.    22.52  70.    69.  ]] taken from training data\n",
      "DEBUG:root:Test sample: [[ 37.   185.    99.    59.    22.52  70.    69.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.33it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 43.   163.   104.5   65.    17.84  75.    71.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 42.   166.   110.    70.    19.97  75.    69.  ]]\n",
      "DEBUG:root:Prediction by model: [0]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 56.   292.   111.    70.    23.17  72.    74.  ]] taken from control data\n",
      "DEBUG:root:Test sample: [[ 56.   292.   111.    70.    23.17  72.    74.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.61it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 56.   296.   111.5   74.    23.38  80.    71.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 59.   293.   124.    74.    25.56  72.    77.  ]]\n",
      "DEBUG:root:Prediction by model: [0]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 60.   235.   108.5   73.5   21.76  65.   102.  ]] taken from training data\n",
      "DEBUG:root:Test sample: [[ 60.   235.   108.5   73.5   21.76  65.   102.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 63.   246.   116.    69.    23.44  65.    78.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 55.   246.   112.5   72.5   27.56  60.    72.  ]]\n",
      "DEBUG:root:Prediction by model: [0]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 56.   261.   145.    77.    26.67  73.    95.  ]] taken from control data\n",
      "DEBUG:root:Test sample: [[ 56.   261.   145.    77.    26.67  73.    95.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 60.   259.   155.    90.    27.94  68.    95.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.57it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 57.   272.   157.    80.    25.15  70.    95.  ]]\n",
      "DEBUG:root:Prediction by model: [1]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 67.   303.   204.    96.    27.86  75.   394.  ]] taken from training data\n",
      "DEBUG:root:Test sample: [[ 67.   303.   204.    96.    27.86  75.   394.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.78it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 46.   233.   106.    60.    20.84  75.   348.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.79it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 67.   303.   204.    96.    27.86  75.   394.  ]]\n",
      "DEBUG:root:Prediction by model: [1]\n",
      "DEBUG:root:Inferred membership: True\n",
      "DEBUG:root:[[ 55.   282.   158.5   81.    30.24  54.    70.  ]] taken from control data\n",
      "DEBUG:root:Test sample: [[ 55.   282.   158.5   81.    30.24  54.    70.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.63it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 62.   282.   175.    79.    28.24  57.    67.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 60.  286.  172.5  85.   22.   72.   71. ]]\n",
      "DEBUG:root:Prediction by model: [1]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 58.   241.   153.   106.    26.94  98.    84.  ]] taken from training data\n",
      "DEBUG:root:Test sample: [[ 58.   241.   153.   106.    26.94  98.    84.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 62.   237.   163.    94.    25.62  85.    84.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 62.   243.   157.    96.    28.83  75.    71.  ]]\n",
      "DEBUG:root:Prediction by model: [0]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 42.   204.   110.    73.    23.72  60.    75.  ]] taken from control data\n",
      "DEBUG:root:Test sample: [[ 42.   204.   110.    73.    23.72  60.    75.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 43.   206.   107.5   73.5   24.17  60.    71.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 38.   215.   106.5   75.    23.82  60.    67.  ]]\n",
      "DEBUG:root:Prediction by model: [0]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 37.   160.   137.    82.    21.03  94.   113.  ]] taken from training data\n",
      "DEBUG:root:Test sample: [[ 37.   160.   137.    82.    21.03  94.   113.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 44.   158.   150.5   87.    21.44  75.    98.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.24it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 50.  167.  159.   95.   25.2  75.   87. ]]\n",
      "DEBUG:root:Prediction by model: [0]\n",
      "DEBUG:root:Inferred membership: False\n",
      "DEBUG:root:[[ 44.   173.   136.5   77.5   26.62  66.    72.  ]] taken from control data\n",
      "DEBUG:root:Test sample: [[ 44.   173.   136.5   77.5   26.62  66.    72.  ]]\n",
      "DEBUG:root:Prediction by model: 0\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n",
      "DEBUG:root:1st counterfactual: [[ 37.   179.   125.    82.    19.53  60.    70.  ]]\n",
      "DEBUG:root:Prediction by model: 1\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n",
      "DEBUG:root:2nd counterfactual: [[ 41.   181.   125.    79.    19.09  60.    70.  ]]\n",
      "DEBUG:root:Prediction by model: [0]\n",
      "DEBUG:root:Inferred membership: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership Inference Accuracy: 0.6, Sensitivity: 0.2, Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "logging.root.setLevel(logging.DEBUG)\n",
    "\n",
    "experiment(data_num, repetitions=10, continuous_features=continuous_features_num, outcome_name=outcome_name_num,\\\n",
    "           random_state=13, clf=DecisionTreeClassifier(random_state=13))\n",
    "\n",
    "logging.root.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "10674b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_ = {'dataset': [], 'model': [], 'accuracy': [], 'sensitivity': [], 'specificity': []}\n",
    "\n",
    "results = pd.DataFrame(data = results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff16a3c",
   "metadata": {},
   "source": [
    "We can now begin with the actual experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "eca0a6ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership Inference Accuracy: 0.62, Sensitivity: 0.24, Specificity: 1.0\n",
      "--- 36.29154968261719 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"features: continuous, model: decision tree.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "accuracy, sensitivity, specificity = experiment(data_num, repetitions=100, continuous_features=continuous_features_num,\\\n",
    "                            outcome_name=outcome_name_num, random_state=0, clf=DecisionTreeClassifier(random_state=0))\n",
    "\n",
    "logging.info(f'accuracy: {accuracy}, sensitivity: {sensitivity}, specificity: {specificity}')\n",
    "results.loc[len(results.index)] = ['continuous', 'decision tree', accuracy, sensitivity, specificity]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "209abdac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.08it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.26it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership Inference Accuracy: 0.62, Sensitivity: 0.24, Specificity: 1.0\n",
      "--- 187.3954713344574 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"features: continuous, model: random forest.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "accuracy, sensitivity, specificity = experiment(data_num, repetitions=100, continuous_features=continuous_features_num, outcome_name=outcome_name_num,\\\n",
    "                      clf=es.RandomForestClassifier(random_state=0), random_state=0)\n",
    "\n",
    "logging.info(f'accuracy: {accuracy}, sensitivity: {sensitivity}, specificity: {specificity}')\n",
    "results.loc[len(results.index)] = ['continuous', 'random forest', accuracy, sensitivity, specificity]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30466d5",
   "metadata": {},
   "source": [
    "# Dataset 2: Census Income (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4191a6b",
   "metadata": {},
   "source": [
    "Load dataset two: census income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5caa753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/adult.data.csv'\n",
    "\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \\\n",
    "         'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'label']\n",
    "\n",
    "data_cat = pd.read_csv(filename, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "85b3f6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country   label  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adfdcb",
   "metadata": {},
   "source": [
    "There is missing data in the columns workclass and native_country that needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "64057c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of columns before removal: \n",
      "[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked']\n",
      "[' United-States' ' Cuba' ' Jamaica' ' India' ' ?' ' Mexico' ' South'\n",
      " ' Puerto-Rico' ' Honduras' ' England' ' Canada' ' Germany' ' Iran'\n",
      " ' Philippines' ' Italy' ' Poland' ' Columbia' ' Cambodia' ' Thailand'\n",
      " ' Ecuador' ' Laos' ' Taiwan' ' Haiti' ' Portugal' ' Dominican-Republic'\n",
      " ' El-Salvador' ' France' ' Guatemala' ' China' ' Japan' ' Yugoslavia'\n",
      " ' Peru' ' Outlying-US(Guam-USVI-etc)' ' Scotland' ' Trinadad&Tobago'\n",
      " ' Greece' ' Nicaragua' ' Vietnam' ' Hong' ' Ireland' ' Hungary'\n",
      " ' Holand-Netherlands']\n",
      "Unique values of columns after removal: \n",
      "[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' Self-emp-inc' ' Without-pay' ' Never-worked']\n",
      "[' United-States' ' Cuba' ' Jamaica' ' India' ' Mexico' ' Puerto-Rico'\n",
      " ' Honduras' ' England' ' Canada' ' Germany' ' Iran' ' Philippines'\n",
      " ' Poland' ' Columbia' ' Cambodia' ' Thailand' ' Ecuador' ' Laos'\n",
      " ' Taiwan' ' Haiti' ' Portugal' ' Dominican-Republic' ' El-Salvador'\n",
      " ' France' ' Guatemala' ' Italy' ' China' ' South' ' Japan' ' Yugoslavia'\n",
      " ' Peru' ' Outlying-US(Guam-USVI-etc)' ' Scotland' ' Trinadad&Tobago'\n",
      " ' Greece' ' Nicaragua' ' Vietnam' ' Hong' ' Ireland' ' Hungary'\n",
      " ' Holand-Netherlands']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values of columns before removal: \")\n",
    "print(data_cat.workclass.unique())\n",
    "print(data_cat.native_country.unique())\n",
    "\n",
    "data_cat = data_cat[data_cat.workclass != ' ?']\n",
    "data_cat = data_cat[data_cat.native_country != ' ?']\n",
    "\n",
    "print(\"Unique values of columns after removal: \")\n",
    "print(data_cat.workclass.unique())\n",
    "print(data_cat.native_country.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a412dc0",
   "metadata": {},
   "source": [
    "We will only use the categorical features of this dataset. Remove continuous columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0845aec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           workclass   education       marital_status          occupation  \\\n",
       "0          State-gov   Bachelors        Never-married        Adm-clerical   \n",
       "1   Self-emp-not-inc   Bachelors   Married-civ-spouse     Exec-managerial   \n",
       "2            Private     HS-grad             Divorced   Handlers-cleaners   \n",
       "\n",
       "     relationship    race    sex  native_country   label  \n",
       "0   Not-in-family   White   Male   United-States   <=50K  \n",
       "1         Husband   White   Male   United-States   <=50K  \n",
       "2   Not-in-family   White   Male   United-States   <=50K  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat = data_cat.drop('age', axis=1).drop('fnlwgt', axis=1).drop('education_num', axis=1).drop('capital_gain', axis=1)\\\n",
    "    .drop('capital_loss', axis=1).drop('hours_per_week', axis=1)\n",
    "\n",
    "data_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97aed2",
   "metadata": {},
   "source": [
    "Drop duplicates and create version with only 100 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d6e8e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat.drop_duplicates()\n",
    "\n",
    "# This needs to be done before the transformations to label encoding. This smaller dataset will contain fewer categories\n",
    "# Otherwise, DiCE will later throw an error if random samples with categories are created, that do not exist in this dataset\n",
    "data_cat_100 = data_cat.sample(n = 100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b8cff",
   "metadata": {},
   "source": [
    "Transform workclass, education, marital_status, occupation, relationship, race, sex and native_country into label encoded features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d11586fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>workclass_encoded</th>\n",
       "      <th>education_encoded</th>\n",
       "      <th>marital_status_encoded</th>\n",
       "      <th>occupation_encoded</th>\n",
       "      <th>relationship_encoded</th>\n",
       "      <th>race_encoded</th>\n",
       "      <th>native_country_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex   label  workclass_encoded  education_encoded  \\\n",
       "0   Male   <=50K                  6                  9   \n",
       "1   Male   <=50K                  5                  9   \n",
       "2   Male   <=50K                  3                 11   \n",
       "\n",
       "   marital_status_encoded  occupation_encoded  relationship_encoded  \\\n",
       "0                       4                   1                     1   \n",
       "1                       2                   4                     0   \n",
       "2                       0                   6                     1   \n",
       "\n",
       "   race_encoded  native_country_encoded  \n",
       "0             4                      38  \n",
       "1             4                      38  \n",
       "2             4                      38  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_dataset(dataset):\n",
    "\n",
    "    dataset['workclass_encoded'] = LabelEncoder().fit_transform(dataset['workclass'])\n",
    "    dataset['education_encoded'] = LabelEncoder().fit_transform(dataset['education'])\n",
    "    dataset['marital_status_encoded'] = LabelEncoder().fit_transform(dataset['marital_status'])\n",
    "    dataset['occupation_encoded'] = LabelEncoder().fit_transform(dataset['occupation'])\n",
    "    dataset['relationship_encoded'] = LabelEncoder().fit_transform(dataset['relationship'])\n",
    "    dataset['race_encoded'] = LabelEncoder().fit_transform(dataset['race'])\n",
    "    dataset['native_country_encoded'] = LabelEncoder().fit_transform(dataset['native_country'])\n",
    "\n",
    "    dataset = dataset.drop('workclass', axis=1).drop('education', axis=1).drop('marital_status', axis=1)\\\n",
    "        .drop('occupation', axis=1).drop('relationship', axis=1).drop('race', axis=1).drop('native_country', axis=1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "data_cat = transform_dataset(data_cat)\n",
    "data_cat_100 = transform_dataset(data_cat_100)\n",
    "    \n",
    "data_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98357919",
   "metadata": {},
   "source": [
    "Transform label and sex into binary encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "166b24eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_encoded</th>\n",
       "      <th>education_encoded</th>\n",
       "      <th>marital_status_encoded</th>\n",
       "      <th>occupation_encoded</th>\n",
       "      <th>relationship_encoded</th>\n",
       "      <th>race_encoded</th>\n",
       "      <th>native_country_encoded</th>\n",
       "      <th>female</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_encoded  education_encoded  marital_status_encoded  \\\n",
       "0                  6                  9                       4   \n",
       "1                  5                  9                       2   \n",
       "2                  3                 11                       0   \n",
       "\n",
       "   occupation_encoded  relationship_encoded  race_encoded  \\\n",
       "0                   1                     1             4   \n",
       "1                   4                     0             4   \n",
       "2                   6                     1             4   \n",
       "\n",
       "   native_country_encoded  female  income  \n",
       "0                      38       0       0  \n",
       "1                      38       0       0  \n",
       "2                      38       0       0  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat['female'] = data_cat['sex'].map( {' Male': 0, ' Female': 1} )\n",
    "data_cat['income'] = data_cat['label'].map( {' <=50K': 0, ' >50K': 1} )\n",
    "\n",
    "data_cat = data_cat.drop('sex', axis=1).drop('label', axis=1)\n",
    "\n",
    "data_cat_100['female'] = data_cat_100['sex'].map( {' Male': 0, ' Female': 1} )\n",
    "data_cat_100['income'] = data_cat_100['label'].map( {' <=50K': 0, ' >50K': 1} )\n",
    "\n",
    "data_cat_100 = data_cat_100.drop('sex', axis=1).drop('label', axis=1)\n",
    "\n",
    "data_cat_100 = data_cat_100.reset_index(drop=True)\n",
    "\n",
    "data_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d86940",
   "metadata": {},
   "source": [
    "Begin with the experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4970b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features_cat = []\n",
    "\n",
    "outcome_name_cat = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b7c5bad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership Inference Accuracy: 0.51, Sensitivity: 0.02, Specificity: 1.0\n",
      "--- 36.802029609680176 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"features: categorical, model: decision tree.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "accuracy, sensitivity, specificity = experiment(data_cat, repetitions=100, continuous_features=continuous_features_cat, outcome_name=outcome_name_cat,\\\n",
    "                      clf=DecisionTreeClassifier(random_state=0), random_state=0)\n",
    "\n",
    "logging.info(f'accuracy: {accuracy}, sensitivity: {sensitivity}, specificity: {specificity}')\n",
    "results.loc[len(results.index)] = ['categorical', 'decision tree', accuracy, sensitivity, specificity]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bb513d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership Inference Accuracy: 0.5, Sensitivity: 0.0, Specificity: 1.0\n",
      "--- 95.0367271900177 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"features: categorical, model: random forest.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "accuracy, sensitivity, specificity = experiment(data_cat, repetitions=100, continuous_features=continuous_features_cat, outcome_name=outcome_name_cat,\\\n",
    "                      clf=es.RandomForestClassifier(random_state=0), random_state=0)\n",
    "\n",
    "logging.info(f'accuracy: {accuracy}, sensitivity: {sensitivity}, specificity: {specificity}')\n",
    "results.loc[len(results.index)] = ['categorical', 'random forest', accuracy, sensitivity, specificity]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1feb9a8",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The results of all variations of the membership inference experiment with counterfactuals. In each experiment, half the samples were picked randomly from the training data, while the other half were picked randomly from the control data not used for training. Both datasets originate from the same source dataset.\n",
    "\n",
    "Accuracy is the percentage of samples whose membership (true or false) was correctly inferred. An algorithm guessing at random would achieve an accuracy of 50 percent.\n",
    "\n",
    "Sensitivity is the percentage of training samples whose membership (true) was correctly inferred.\n",
    "\n",
    "Specificity is the percentage of control samples (not used for training) whose membership (false) was correctly inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "39bb0af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continuous</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continuous</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>categorical</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>categorical</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset          model  accuracy  sensitivity  specificity\n",
       "0   continuous  decision tree      0.62         0.24          1.0\n",
       "1   continuous  random forest      0.62         0.24          1.0\n",
       "2  categorical  decision tree      0.51         0.02          1.0\n",
       "3  categorical  random forest      0.50         0.00          1.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31380dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
