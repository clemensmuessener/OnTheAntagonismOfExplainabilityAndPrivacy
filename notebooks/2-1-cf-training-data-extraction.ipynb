{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75916e17",
   "metadata": {},
   "source": [
    "# Counterfactuals Training Data Extraction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6661d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:15.577215Z",
     "iopub.status.busy": "2022-10-29T17:40:15.572812Z",
     "iopub.status.idle": "2022-10-29T17:40:18.600644Z",
     "shell.execute_reply": "2022-10-29T17:40:18.588362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.ensemble as es\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import dice_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27327d5-6352-40a0-a6d8-5f6298306064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:18.621351Z",
     "iopub.status.busy": "2022-10-29T17:40:18.620110Z",
     "iopub.status.idle": "2022-10-29T17:40:18.633920Z",
     "shell.execute_reply": "2022-10-29T17:40:18.630812Z"
    }
   },
   "outputs": [],
   "source": [
    "threads = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2429dea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:18.647455Z",
     "iopub.status.busy": "2022-10-29T17:40:18.646421Z",
     "iopub.status.idle": "2022-10-29T17:40:21.024992Z",
     "shell.execute_reply": "2022-10-29T17:40:21.017649Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:xai-privacy:Loading dataset 1: heart disease (numeric features) ...\n",
      "INFO:xai-privacy:Loading dataset 2: census income (categorical features) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Age: removed 0 rows for missing values.\n",
      "Feature RestingBP: removed 59 rows for missing values.\n",
      "Feature Cholesterol: removed 27 rows for missing values.\n",
      "Feature FastingBS: add unknown category 2.0\n",
      "Feature RestingECG: add unknown category 3.0\n",
      "Feature MaxHR: removed 0 rows for missing values.\n",
      "Feature Oldpeak: removed 7 rows for missing values.\n",
      "Feature ST_Slope: add unknown category 4.0\n",
      "Feature CA: add unknown category 4.0\n",
      "Feature Thal: add unknown category 8.0\n",
      "Dropped 271 of 1097\n",
      "Dropped 273 of 1097\n",
      "Dropped 277 of 1097\n",
      "Dropped: 2399 of 32561\n",
      "census: Dropped 3848 of 30162\n",
      "num: Dropped 19859 of 30162\n",
      "cat: Dropped 12136 of 30162\n"
     ]
    }
   ],
   "source": [
    "%run experiment_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d487ce1-05ee-4457-8ca1-7163b67fe595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.047676Z",
     "iopub.status.busy": "2022-10-29T17:40:21.042595Z",
     "iopub.status.idle": "2022-10-29T17:40:21.064812Z",
     "shell.execute_reply": "2022-10-29T17:40:21.059050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('xai-privacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a61bbc",
   "metadata": {},
   "source": [
    "This notebook will test whether training data extraction is possible with counterfactuals (CF) that are drawn from the training data. Training data extraction means an attacker can find out the feature values of samples from the training data without prior knowledge of them. The attacker only has access to the model's prediction function and the explanation.\n",
    "\n",
    "This attack should be trivial because any counterfactual that is shown as an explanation was picked directly from the training data.\n",
    "\n",
    "The idea for counterfacutal training data extraction is as follows: The attacker makes repeated queries to the model with random input values. In order to do this, the attacker knows the maximum and minimum value of each feature in the training data (or the categorical values of each feature). The returned counterfactuals are the extracted training data.\n",
    "\n",
    "First, we implement the `train_explainer` and `training_data_extraction_model_access` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca67de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.080788Z",
     "iopub.status.busy": "2022-10-29T17:40:21.079754Z",
     "iopub.status.idle": "2022-10-29T17:40:21.132885Z",
     "shell.execute_reply": "2022-10-29T17:40:21.124719Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CounterfactualTDE(TrainingDataExtraction):\n",
    "    def train_explainer(self, data_train, model):\n",
    "        # train explainer on training data\n",
    "        d = dice_ml.Data(dataframe=data_train, continuous_features=self.numeric_features,\\\n",
    "                         outcome_name=self.outcome_name)\n",
    "        m = dice_ml.Model(model=model, backend=\"sklearn\", model_type='classifier')\n",
    "        \n",
    "        # use method \"kd-tree\" to get counterfactuals drawn from the training data\n",
    "        return dice_ml.Dice(d, m, method=\"kdtree\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def training_data_extraction_no_model_access(explainer, num_queries, feature_formats, rng):\n",
    "        rng = np.random.default_rng(rng)\n",
    "        seed = rng.integers(100000).item()\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # Get all feature names\n",
    "        feature_names = []\n",
    "        \n",
    "        for feature in feature_formats:\n",
    "            feature_names.append(feature['name'])\n",
    "        \n",
    "        samples_df = pd.DataFrame(columns=feature_names)\n",
    "    \n",
    "        # This is the default number of counterfactuals per query used on the github page of DiCE\n",
    "        cfs_per_query = 4\n",
    "    \n",
    "        # Generate random samples as queries for the explainer.\n",
    "        for i in range(num_queries):\n",
    "            sample = {}\n",
    "            for feature in feature_formats:\n",
    "                if feature['isCont']:\n",
    "                    sample[feature['name']] = rng.integers(feature['min'], feature['max'])\n",
    "                else:\n",
    "                    sample[feature['name']] = random.choice(feature['categories'])\n",
    "            sample_df = pd.DataFrame(sample, index=[0])\n",
    "            samples_df = pd.concat([samples_df, sample_df], ignore_index=True)\n",
    "\n",
    "        # Cast categorical features to string again because of DiCE peculiarities\n",
    "        for feature in feature_formats:\n",
    "            if not feature['isCont']:\n",
    "                samples_df[feature['name']] = samples_df[feature['name']].astype(str)\n",
    "            else:\n",
    "                samples_df[feature['name']] = samples_df[feature['name']].astype(int)\n",
    "                \n",
    "        # Generate counterfactuals for all random query samples\n",
    "        e1 = explainer.generate_counterfactuals(samples_df, total_CFs=cfs_per_query, desired_class='opposite')\n",
    "                \n",
    "        # Collect all extracted samples in this dataframe\n",
    "        extracted_samples_df = pd.DataFrame(columns=feature_names)\n",
    "        for index in range(len(samples_df)):\n",
    "            cfs_of_sample = e1.cf_examples_list[index].final_cfs_df\n",
    "            logger.debug(f'Sample {index}: Counterfactuals \\n {cfs_of_sample.to_numpy()}')\n",
    "\n",
    "            extracted_samples_df = pd.concat([extracted_samples_df, cfs_of_sample], ignore_index=True)\n",
    "        \n",
    "        return extracted_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef61e5",
   "metadata": {},
   "source": [
    "# Executing Training Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a2083",
   "metadata": {},
   "source": [
    "We now generate five counterfactuals for the first sample from the training data to demonstrate counterfactual explanations in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c4cf59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.145689Z",
     "iopub.status.busy": "2022-10-29T17:40:21.144210Z",
     "iopub.status.idle": "2022-10-29T17:40:21.451541Z",
     "shell.execute_reply": "2022-10-29T17:40:21.449183Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = data_heart.drop(outcome_name_heart, axis=1)\n",
    "labels = data_heart[outcome_name_heart]\n",
    "\n",
    "# Train a random forest on training data.\n",
    "model = es.RandomForestClassifier(random_state=0)\n",
    "model = model.fit(features, labels)\n",
    "\n",
    "# Train explainer\n",
    "d = dice_ml.Data(dataframe=data_heart, continuous_features=numeric_features_heart, outcome_name=outcome_name_heart)\n",
    "\n",
    "m = dice_ml.Model(model=model, backend=\"sklearn\", model_type='classifier')\n",
    "# Generating counterfactuals from training data (kd-tree)\n",
    "exp = dice_ml.Dice(d, m, method=\"kdtree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508a451a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.472262Z",
     "iopub.status.busy": "2022-10-29T17:40:21.469575Z",
     "iopub.status.idle": "2022-10-29T17:40:27.920613Z",
     "shell.execute_reply": "2022-10-29T17:40:27.917828Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>CA</th>\n",
       "      <th>Thal</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex ChestPainType  RestingBP  Cholesterol FastingBS RestingECG  \\\n",
       "0  47.0  1.0           1.0      110.0        249.0       0.0        0.0   \n",
       "\n",
       "   MaxHR ExerciseAngina  Oldpeak ST_Slope   CA Thal  HeartDisease  \n",
       "0  150.0            0.0      0.0      4.0  4.0  8.0           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set without sparsity correction (new outcome:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>CA</th>\n",
       "      <th>Thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Sex ChestPainType  RestingBP  Cholesterol FastingBS RestingECG  \\\n",
       "388   35.0  1.0           2.0      110.0        257.0       0.0        0.0   \n",
       "434   47.0  1.0           3.0      108.0        243.0       0.0        0.0   \n",
       "705   54.0  1.0           3.0      120.0        237.0       0.0        0.0   \n",
       "320   46.0  1.0           4.0      120.0        249.0       0.0        2.0   \n",
       "1111  33.0  0.0           4.0      100.0        246.0       0.0        0.0   \n",
       "\n",
       "      MaxHR ExerciseAngina  Oldpeak ST_Slope   CA Thal  \n",
       "388   140.0            0.0      0.0      4.0  4.0  8.0  \n",
       "434   152.0            0.0      0.0      1.0  0.0  3.0  \n",
       "705   150.0            1.0      1.5      4.0  4.0  7.0  \n",
       "320   144.0            0.0      0.8      1.0  0.0  7.0  \n",
       "1111  150.0            1.0      1.0      2.0  4.0  8.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e1 = exp.generate_counterfactuals(features[0:1], total_CFs=5, desired_class=\"opposite\")\n",
    "e1.visualize_as_dataframe(display_sparse_df=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084cf1e0",
   "metadata": {},
   "source": [
    "We can see that the counterfactuals are similar to the query sample and that they have a flipped prediction. These are the two general properties of counterfactual explanations.\n",
    "\n",
    "We will now do a small proof of concept of the experiment with logging enabled to demonstrate how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacf1093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:27.940680Z",
     "iopub.status.busy": "2022-10-29T17:40:27.936367Z",
     "iopub.status.idle": "2022-10-29T17:40:58.832968Z",
     "shell.execute_reply": "2022-10-29T17:40:58.828827Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:xai-privacy:Numeric Features: ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
      "DEBUG:xai-privacy:Categorical Features: ['CA', 'ChestPainType', 'ExerciseAngina', 'FastingBS', 'RestingECG', 'ST_Slope', 'Sex', 'Thal']\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:29<00:00,  2.62s/it]\n",
      "DEBUG:xai-privacy:Sample 0: Counterfactuals \n",
      " [[51.0 '1.0' '3.0' 110.0 175.0 '0.0' '0.0' 123.0 '0.0' 0.6 '1.0' '0.0'\n",
      "  '3.0']\n",
      " [49.0 '1.0' '3.0' 118.0 149.0 '0.0' '2.0' 126.0 '0.0' 0.8 '1.0' '3.0'\n",
      "  '3.0']\n",
      " [55.0 '1.0' '4.0' 116.0 186.0 '1.0' '1.0' 102.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [54.0 '1.0' '4.0' 120.0 188.0 '0.0' '0.0' 113.0 '0.0' 1.4 '2.0' '1.0'\n",
      "  '7.0']]\n",
      "DEBUG:xai-privacy:Sample 1: Counterfactuals \n",
      " [[55.0 '1.0' '3.0' 0.0 0.0 '0.0' '0.0' 155.0 '0.0' 1.5 '2.0' '4.0' '8.0']\n",
      " [32.0 '1.0' '1.0' 95.0 0.0 '2.0' '0.0' 127.0 '0.0' 0.7 '1.0' '4.0' '8.0']\n",
      " [38.0 '1.0' '4.0' 92.0 117.0 '0.0' '0.0' 134.0 '1.0' 2.5 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [34.0 '1.0' '4.0' 115.0 0.0 '2.0' '3.0' 154.0 '0.0' 0.2 '1.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 2: Counterfactuals \n",
      " [[57.0 '0.0' '4.0' 120.0 354.0 '0.0' '0.0' 163.0 '1.0' 0.6 '1.0' '0.0'\n",
      "  '3.0']\n",
      " [55.0 '0.0' '2.0' 110.0 344.0 '0.0' '1.0' 160.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [36.0 '1.0' '3.0' 112.0 340.0 '0.0' '0.0' 184.0 '0.0' 1.0 '2.0' '4.0'\n",
      "  '3.0']\n",
      " [58.0 '0.0' '3.0' 120.0 340.0 '0.0' '0.0' 172.0 '0.0' 0.0 '1.0' '0.0'\n",
      "  '3.0']]\n",
      "DEBUG:xai-privacy:Sample 3: Counterfactuals \n",
      " [[77.0 '1.0' '4.0' 125.0 304.0 '0.0' '2.0' 162.0 '1.0' 0.0 '1.0' '3.0'\n",
      "  '3.0']\n",
      " [63.0 '1.0' '4.0' 130.0 330.0 '1.0' '2.0' 132.0 '1.0' 1.8 '1.0' '3.0'\n",
      "  '7.0']\n",
      " [58.0 '1.0' '4.0' 114.0 318.0 '0.0' '1.0' 140.0 '0.0' 4.4 '3.0' '3.0'\n",
      "  '6.0']\n",
      " [64.0 '1.0' '3.0' 140.0 335.0 '0.0' '0.0' 158.0 '0.0' 0.0 '1.0' '0.0'\n",
      "  '3.0']]\n",
      "DEBUG:xai-privacy:Sample 4: Counterfactuals \n",
      " [[52.0 '1.0' '2.0' 140.0 100.0 '0.0' '0.0' 138.0 '1.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [57.0 '1.0' '3.0' 150.0 126.0 '1.0' '0.0' 173.0 '0.0' 0.2 '1.0' '1.0'\n",
      "  '7.0']\n",
      " [56.0 '1.0' '4.0' 120.0 85.0 '0.0' '0.0' 140.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [59.0 '1.0' '4.0' 140.0 177.0 '0.0' '0.0' 162.0 '1.0' 0.0 '1.0' '1.0'\n",
      "  '7.0']]\n",
      "DEBUG:xai-privacy:Sample 5: Counterfactuals \n",
      " [[40.0 '1.0' '4.0' 120.0 466.0 '2.0' '0.0' 152.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '6.0']\n",
      " [53.0 '0.0' '2.0' 113.0 468.0 '2.0' '0.0' 127.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [57.0 '0.0' '4.0' 120.0 354.0 '0.0' '0.0' 163.0 '1.0' 0.6 '1.0' '0.0'\n",
      "  '3.0']\n",
      " [62.0 '0.0' '4.0' 140.0 394.0 '0.0' '2.0' 157.0 '0.0' 1.2 '2.0' '0.0'\n",
      "  '3.0']]\n",
      "DEBUG:xai-privacy:Sample 6: Counterfactuals \n",
      " [[52.0 '1.0' '4.0' 140.0 404.0 '0.0' '0.0' 124.0 '1.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [56.0 '1.0' '4.0' 170.0 388.0 '0.0' '1.0' 122.0 '1.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [48.0 '1.0' '4.0' 160.0 355.0 '0.0' '0.0' 99.0 '1.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [64.0 '1.0' '3.0' 140.0 335.0 '0.0' '0.0' 158.0 '0.0' 0.0 '1.0' '0.0'\n",
      "  '3.0']]\n",
      "DEBUG:xai-privacy:Sample 7: Counterfactuals \n",
      " [[61.0 '1.0' '4.0' 120.0 282.0 '0.0' '1.0' 135.0 '1.0' 4.0 '3.0' '4.0'\n",
      "  '6.0']\n",
      " [58.0 '1.0' '4.0' 114.0 318.0 '0.0' '1.0' 140.0 '0.0' 4.4 '3.0' '3.0'\n",
      "  '6.0']\n",
      " [56.0 '1.0' '4.0' 130.0 283.0 '1.0' '2.0' 103.0 '1.0' 1.6 '3.0' '0.0'\n",
      "  '7.0']\n",
      " [53.0 '1.0' '4.0' 123.0 282.0 '0.0' '0.0' 95.0 '1.0' 2.0 '2.0' '2.0'\n",
      "  '7.0']]\n",
      "DEBUG:xai-privacy:Sample 8: Counterfactuals \n",
      " [[52.0 '1.0' '2.0' 140.0 100.0 '0.0' '0.0' 138.0 '1.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [56.0 '1.0' '4.0' 120.0 85.0 '0.0' '0.0' 140.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [56.0 '1.0' '2.0' 126.0 166.0 '0.0' '1.0' 140.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [41.0 '1.0' '4.0' 130.0 172.0 '0.0' '1.0' 130.0 '0.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 9: Counterfactuals \n",
      " [[54.0 '1.0' '1.0' 120.0 171.0 '0.0' '0.0' 137.0 '0.0' 2.0 '1.0' '4.0'\n",
      "  '8.0']\n",
      " [52.0 '0.0' '4.0' 130.0 180.0 '0.0' '0.0' 140.0 '1.0' 1.5 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [51.0 '1.0' '3.0' 135.0 160.0 '0.0' '0.0' 150.0 '0.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [50.0 '1.0' '2.0' 120.0 168.0 '0.0' '0.0' 160.0 '0.0' 0.0 '4.0' '0.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 10: Counterfactuals \n",
      " [[67.0 '0.0' '3.0' 115.0 564.0 '0.0' '2.0' 160.0 '0.0' 1.6 '2.0' '0.0'\n",
      "  '7.0']\n",
      " [53.0 '1.0' '3.0' 145.0 518.0 '0.0' '0.0' 130.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [32.0 '1.0' '4.0' 118.0 529.0 '0.0' '0.0' 130.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [54.0 '1.0' '4.0' 130.0 603.0 '1.0' '0.0' 125.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 11: Counterfactuals \n",
      " [[67.0 '0.0' '3.0' 115.0 564.0 '0.0' '2.0' 160.0 '0.0' 1.6 '2.0' '0.0'\n",
      "  '7.0']\n",
      " [54.0 '1.0' '4.0' 130.0 603.0 '1.0' '0.0' 125.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [32.0 '1.0' '4.0' 118.0 529.0 '0.0' '0.0' 130.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [53.0 '1.0' '3.0' 145.0 518.0 '0.0' '0.0' 130.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 32.    1.    1.   95.    0.    2.    0.  127.    0.    0.7   1.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [7]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 32.   1.   4. 118. 529.   0.   0. 130.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [10]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 34.    1.    4.  115.    0.    2.    3.  154.    0.    0.2   1.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [19]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 36.   1.   3. 112. 340.   0.   0. 184.   0.   1.   2.   4.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [31]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 38.    1.    4.   92.  117.    0.    0.  134.    1.    2.5   2.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [55]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 40.   1.   4. 120. 466.   2.   0. 152.   1.   1.   2.   4.   6.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [82]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 41.   1.   4. 130. 172.   0.   1. 130.   0.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [107]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 48.   1.   4. 160. 355.   0.   0.  99.   1.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [251]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 49.    1.    3.  118.  149.    0.    2.  126.    0.    0.8   1.    3.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [261]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 50.   1.   2. 120. 168.   0.   0. 160.   0.   0.   4.   0.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [277]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 51.    1.    3.  110.  175.    0.    0.  123.    0.    0.6   1.    0.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [310]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 51.   1.   3. 135. 160.   0.   0. 150.   0.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [312]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 52.    0.    4.  130.  180.    0.    0.  140.    1.    1.5   2.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [327]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 52.   1.   2. 140. 100.   0.   0. 138.   1.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [334]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 52.   1.   4. 140. 404.   0.   0. 124.   1.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [353]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 53.   0.   2. 113. 468.   2.   0. 127.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [357]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 53.   1.   3. 145. 518.   0.   0. 130.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [370]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 53.   1.   4. 123. 282.   0.   0.  95.   1.   2.   2.   2.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [375]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 54.   1.   1. 120. 171.   0.   0. 137.   0.   2.   1.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [403]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 54.    1.    4.  120.  188.    0.    0.  113.    0.    1.4   2.    1.\n",
      "   7. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [419]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 54.   1.   4. 130. 603.   1.   0. 125.   1.   1.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [427]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 55.   0.   2. 110. 344.   0.   1. 160.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [434]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 55.    1.    3.    0.    0.    0.    0.  155.    0.    1.5   2.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [448]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 55.   1.   4. 116. 186.   1.   1. 102.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [453]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 56.   1.   2. 126. 166.   0.   1. 140.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [479]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 56.   1.   4. 120.  85.   0.   0. 140.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [491]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 56.    1.    4.  130.  283.    1.    2.  103.    1.    1.6   3.    0.\n",
      "   7. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [497]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 56.   1.   4. 170. 388.   0.   1. 122.   1.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [503]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 57.    0.    4.  120.  354.    0.    0.  163.    1.    0.6   1.    0.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [506]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 57.    1.    3.  150.  126.    1.    0.  173.    0.    0.2   1.    1.\n",
      "   7. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [517]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 58.   0.   3. 120. 340.   0.   0. 172.   0.   0.   1.   0.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [544]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 58.    1.    4.  114.  318.    0.    1.  140.    0.    4.4   3.    3.\n",
      "   6. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [565]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 59.   1.   4. 140. 177.   0.   0. 162.   1.   0.   1.   1.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [604]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 61.   1.   4. 120. 282.   0.   1. 135.   1.   4.   3.   4.   6.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [654]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 62.    0.    4.  140.  394.    0.    2.  157.    0.    1.2   2.    0.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [674]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 63.    1.    4.  130.  330.    1.    2.  132.    1.    1.8   1.    3.\n",
      "   7. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [710]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 64.   1.   3. 140. 335.   0.   0. 158.   0.   0.   1.   0.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [731]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 67.    0.    3.  115.  564.    0.    2.  160.    0.    1.6   2.    0.\n",
      "   7. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [770]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 77.   1.   4. 125. 304.   0.   2. 162.   1.   0.   1.   3.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 30.86s (training model: 0.38s, training explainer: 0.06s, experiment: 30.42s)\n",
      "Number of extracted samples: 39\n",
      "Number of accurate extracted samples: 39\n",
      "Precision: 1.0, recall: 3.25\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "logging.root.setLevel(logging.ERROR)\n",
    "\n",
    "EXP = CounterfactualTDE(data_heart, numeric_features_heart, outcome_name_heart, random_state=0)\n",
    "EXP.training_data_extraction_experiment(num_queries=12, model=es.RandomForestClassifier(random_state=0), model_access=False)\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e3f0e",
   "metadata": {},
   "source": [
    "The proof of concept should show that each extracted sample is an actual training sample (precision of 100%). Recall is above 100% because this method can extract multiple samples per query (multiple counterfactuals are returned). Recall will reach a reasonable value if the experiment is executed for the full training data. In this case, the attack cannot return more samples than the number of queries because the attack is limited by the number of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff16a3c",
   "metadata": {},
   "source": [
    "Now we begin executing the actual experiment. We begin by defining the table that will hold the results for all our different experiment variations. Then we execute all variations of the experiment for this dataset. We vary the model between a decision tree, a random forest and a neural network. Each model uses the default configuration of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10674b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.846445Z",
     "iopub.status.busy": "2022-10-29T17:40:58.845536Z",
     "iopub.status.idle": "2022-10-29T17:40:58.868857Z",
     "shell.execute_reply": "2022-10-29T17:40:58.860831Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_ = {'dataset': [], 'model': [], 'precision': [], 'recall': []}\n",
    "\n",
    "results = pd.DataFrame(data = results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c541b0b-7348-4aa0-95c8-4c9fafe3f3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.886860Z",
     "iopub.status.busy": "2022-10-29T17:40:58.884781Z",
     "iopub.status.idle": "2022-10-29T17:40:58.905823Z",
     "shell.execute_reply": "2022-10-29T17:40:58.902303Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dicts = [data_heart_dict, data_heart_num_dict, data_heart_cat_dict, data_census_dict, data_census_num_dict, data_census_cat_dict]\n",
    "\n",
    "dt_dict = {'name': 'decision tree', 'model': DecisionTreeClassifier}\n",
    "rf_dict = {'name': 'random forest', 'model': es.RandomForestClassifier}\n",
    "nn_dict = {'name': 'neural network', 'model': MLPClassifier}\n",
    "\n",
    "model_dicts = [dt_dict, rf_dict, nn_dict]\n",
    "\n",
    "# We set the number of extractions to the length of the dataset\n",
    "num_queries_dict = { 'heart': len(data_heart), 'heart numeric': len(data_heart_num), 'heart categorical': len(data_heart_cat), 'census': len(data_census), 'census numeric': len(data_census_num), 'census categorical': len(data_census_cat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f88514-2273-4bba-b3bd-d2558903dd8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.926076Z",
     "iopub.status.busy": "2022-10-29T17:40:58.922427Z",
     "iopub.status.idle": "2022-10-29T17:40:58.939842Z",
     "shell.execute_reply": "2022-10-29T17:40:58.936483Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove pandas warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd26f0ba-1b5c-456e-9c5b-eff254817877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.957826Z",
     "iopub.status.busy": "2022-10-29T17:40:58.956274Z",
     "iopub.status.idle": "2022-10-29T20:54:34.073601Z",
     "shell.execute_reply": "2022-10-29T20:54:34.068627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: heart, model: decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:26<00:00,  1.17s/it]\n",
      " 92%|█████████▏| 24/26 [00:36<00:02,  1.40s/it]\n",
      "100%|██████████| 27/27 [00:37<00:00,  1.98s/it]\n",
      " 70%|███████   | 19/27 [00:37<00:21,  2.74s/it]\n",
      "100%|██████████| 27/27 [00:38<00:00,  1.57s/it]\n",
      "100%|██████████| 27/27 [00:39<00:00,  1.28s/it]\n",
      "100%|██████████| 26/26 [00:39<00:00,  1.10s/it]\n",
      "100%|██████████| 27/27 [00:40<00:00,  1.84s/it]\n",
      "100%|██████████| 27/27 [00:40<00:00,  1.67s/it]\n",
      "100%|██████████| 27/27 [00:40<00:00,  1.05s/it]\n",
      "100%|██████████| 26/26 [00:40<00:00,  1.99s/it]\n",
      "100%|██████████| 26/26 [00:41<00:00,  1.90s/it]\n",
      "100%|██████████| 27/27 [00:41<00:00,  1.40s/it]\n",
      "100%|██████████| 26/26 [00:43<00:00,  1.09s/it]\n",
      "100%|██████████| 27/27 [00:46<00:00,  3.40s/it]\n",
      "100%|██████████| 27/27 [00:46<00:00,  1.07s/it]\n",
      "100%|██████████| 26/26 [00:46<00:00,  2.31s/it]\n",
      "100%|██████████| 26/26 [00:46<00:00,  1.32s/it]\n",
      "100%|██████████| 26/26 [00:47<00:00,  1.36s/it]\n",
      "100%|██████████| 27/27 [00:48<00:00,  1.98s/it]\n",
      "100%|██████████| 27/27 [00:48<00:00,  1.07s/it]\n",
      "100%|██████████| 26/26 [00:49<00:00,  1.81s/it]\n",
      "100%|██████████| 27/27 [00:49<00:00,  2.08s/it]\n",
      "100%|██████████| 26/26 [00:49<00:00,  1.26s/it]\n",
      "100%|██████████| 27/27 [00:49<00:00,  1.29s/it]\n",
      "100%|██████████| 27/27 [00:49<00:00,  1.81s/it]\n",
      "100%|██████████| 26/26 [00:50<00:00,  1.17s/it]\n",
      "100%|██████████| 27/27 [00:51<00:00,  1.11s/it]\n",
      "100%|██████████| 27/27 [00:51<00:00,  2.14s/it]\n",
      "100%|██████████| 27/27 [00:54<00:00,  1.61s/it]\n",
      "100%|██████████| 27/27 [00:57<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 59.68s (training model: 0.04s, training explainer: 0.08s, experiment: 59.56s)\n",
      "Number of extracted samples: 540\n",
      "Number of accurate extracted samples: 540\n",
      "Precision: 1.0, recall: 0.6537530266343826\n",
      "dataset: heart, model: random forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:48<00:00,  2.71s/it]\n",
      "100%|██████████| 26/26 [01:04<00:00,  2.62s/it]\n",
      "100%|██████████| 27/27 [01:07<00:00,  2.13s/it]\n",
      "100%|██████████| 27/27 [01:09<00:00,  2.72s/it]\n",
      "100%|██████████| 27/27 [01:13<00:00,  1.67s/it]\n",
      "100%|██████████| 27/27 [01:14<00:00,  1.20s/it]\n",
      "100%|██████████| 27/27 [01:15<00:00,  4.89s/it]\n",
      " 96%|█████████▌| 25/26 [01:16<00:04,  4.19s/it]\n",
      "100%|██████████| 26/26 [01:17<00:00,  2.15s/it]\n",
      "100%|██████████| 26/26 [01:18<00:00,  3.60s/it]\n",
      "100%|██████████| 27/27 [01:19<00:00,  1.64s/it]\n",
      "100%|██████████| 27/27 [01:19<00:00,  5.06s/it]\n",
      "100%|██████████| 26/26 [01:22<00:00,  1.54s/it]\n",
      "100%|██████████| 27/27 [01:23<00:00,  3.54s/it]\n",
      "100%|██████████| 27/27 [01:23<00:00,  2.08s/it]\n",
      "100%|██████████| 26/26 [01:23<00:00,  3.91s/it]\n",
      "100%|██████████| 26/26 [01:25<00:00,  3.47s/it]\n",
      "100%|██████████| 27/27 [01:25<00:00,  2.02s/it]\n",
      "100%|██████████| 26/26 [01:26<00:00,  2.20s/it]\n",
      "100%|██████████| 26/26 [01:29<00:00,  3.47s/it]\n",
      "100%|██████████| 26/26 [01:31<00:00,  4.02s/it]\n",
      "100%|██████████| 26/26 [01:32<00:00,  3.93s/it]\n",
      "100%|██████████| 27/27 [01:33<00:00,  3.41s/it]\n",
      "100%|██████████| 27/27 [01:33<00:00,  2.32s/it]\n",
      "100%|██████████| 27/27 [01:36<00:00,  3.36s/it]\n",
      "100%|██████████| 26/26 [01:38<00:00,  2.48s/it]\n",
      "100%|██████████| 27/27 [01:39<00:00,  2.33s/it]\n",
      "100%|██████████| 27/27 [01:43<00:00,  1.97s/it]\n",
      "100%|██████████| 27/27 [01:43<00:00,  4.12s/it]\n",
      "100%|██████████| 27/27 [01:48<00:00,  2.57s/it]\n",
      "100%|██████████| 27/27 [02:01<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 125.34s (training model: 0.78s, training explainer: 0.09s, experiment: 124.47s)\n",
      "Number of extracted samples: 482\n",
      "Number of accurate extracted samples: 482\n",
      "Precision: 1.0, recall: 0.5835351089588378\n",
      "dataset: heart, model: neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i40/langema/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "100%|██████████| 27/27 [00:59<00:00,  2.16s/it]\n",
      "100%|██████████| 26/26 [01:05<00:00,  3.62s/it]\n",
      "100%|██████████| 27/27 [01:08<00:00,  1.65s/it]\n",
      "100%|██████████| 26/26 [01:09<00:00,  2.69s/it]\n",
      " 81%|████████▏ | 22/27 [01:14<00:21,  4.32s/it]\n",
      " 96%|█████████▋| 26/27 [01:19<00:05,  5.74s/it]\n",
      "100%|██████████| 27/27 [01:19<00:00,  2.02s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  1.77s/it]\n",
      " 88%|████████▊ | 23/26 [01:20<00:13,  4.45s/it]\n",
      "100%|██████████| 27/27 [01:21<00:00,  2.14s/it]\n",
      "100%|██████████| 27/27 [01:21<00:00,  2.84s/it]\n",
      "100%|██████████| 27/27 [01:23<00:00,  2.11s/it]\n",
      "100%|██████████| 27/27 [01:23<00:00,  4.50s/it]\n",
      "100%|██████████| 27/27 [01:27<00:00,  1.85s/it]\n",
      "100%|██████████| 27/27 [01:27<00:00,  3.10s/it]\n",
      "100%|██████████| 27/27 [01:27<00:00,  4.26s/it]\n",
      "100%|██████████| 26/26 [01:28<00:00,  2.58s/it]\n",
      "100%|██████████| 27/27 [01:28<00:00,  1.50s/it]\n",
      "100%|██████████| 26/26 [01:29<00:00,  3.31s/it]\n",
      "100%|██████████| 27/27 [01:29<00:00,  1.70s/it]\n",
      "100%|██████████| 27/27 [01:30<00:00,  2.55s/it]\n",
      "100%|██████████| 27/27 [01:29<00:00,  2.50s/it]\n",
      "100%|██████████| 26/26 [01:31<00:00,  2.45s/it]\n",
      "100%|██████████| 27/27 [01:32<00:00,  1.61s/it]\n",
      "100%|██████████| 26/26 [01:33<00:00,  1.41s/it]\n",
      "100%|██████████| 26/26 [01:33<00:00,  2.69s/it]\n",
      "100%|██████████| 27/27 [01:34<00:00,  1.25s/it]\n",
      "100%|██████████| 26/26 [01:34<00:00,  2.22s/it]\n",
      "100%|██████████| 27/27 [01:34<00:00,  2.17s/it]\n",
      "100%|██████████| 27/27 [01:40<00:00,  1.01s/it]\n",
      "100%|██████████| 27/27 [01:44<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 111.11s (training model: 4.31s, training explainer: 0.09s, experiment: 106.71s)\n",
      "Number of extracted samples: 469\n",
      "Number of accurate extracted samples: 469\n",
      "Precision: 1.0, recall: 0.5677966101694916\n",
      "dataset: heart numeric, model: decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:14<00:00,  1.37it/s]\n",
      "100%|██████████| 27/27 [00:17<00:00,  1.91it/s]\n",
      "100%|██████████| 27/27 [00:17<00:00,  2.19it/s]\n",
      "100%|██████████| 27/27 [00:17<00:00,  2.23it/s]\n",
      "100%|██████████| 26/26 [00:17<00:00,  1.17it/s]\n",
      " 74%|███████▍  | 20/27 [00:18<00:04,  1.66it/s]\n",
      " 65%|██████▌   | 17/26 [00:18<00:03,  2.30it/s]\n",
      "100%|██████████| 27/27 [00:18<00:00,  1.75it/s]\n",
      "100%|██████████| 26/26 [00:18<00:00,  1.29it/s]\n",
      " 93%|█████████▎| 25/27 [00:19<00:02,  1.05s/it]\n",
      "100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "100%|██████████| 27/27 [00:21<00:00,  1.99it/s]\n",
      "100%|██████████| 26/26 [00:21<00:00,  1.10s/it]\n",
      "100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "100%|██████████| 27/27 [00:21<00:00,  1.56it/s]\n",
      "100%|██████████| 27/27 [00:22<00:00,  1.48it/s]\n",
      "100%|██████████| 27/27 [00:22<00:00,  1.32it/s]\n",
      "100%|██████████| 26/26 [00:22<00:00,  1.13it/s]\n",
      "100%|██████████| 27/27 [00:22<00:00,  1.09s/it]\n",
      "100%|██████████| 27/27 [00:22<00:00,  1.52s/it]\n",
      "\n",
      " 96%|█████████▋| 26/27 [00:22<00:00,  1.58it/s]\n",
      "100%|██████████| 26/26 [00:22<00:00,  1.08s/it]\n",
      " 96%|█████████▌| 25/26 [00:22<00:00,  1.64it/s]\n",
      "100%|██████████| 26/26 [00:22<00:00,  1.86it/s]\n",
      "100%|██████████| 26/26 [00:23<00:00,  2.00it/s]\n",
      "100%|██████████| 27/27 [00:23<00:00,  1.39it/s]\n",
      "100%|██████████| 26/26 [00:23<00:00,  1.83it/s]\n",
      "100%|██████████| 27/27 [00:24<00:00,  1.72it/s]\n",
      "100%|██████████| 27/27 [00:24<00:00,  1.06s/it]\n",
      "100%|██████████| 26/26 [00:26<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 28.31s (training model: 0.01s, training explainer: 0.01s, experiment: 28.30s)\n",
      "Number of extracted samples: 532\n",
      "Number of accurate extracted samples: 532\n",
      "Precision: 1.0, recall: 0.6456310679611651\n",
      "dataset: heart numeric, model: random forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:32<00:00,  1.03it/s]\n",
      "100%|██████████| 27/27 [00:43<00:00,  1.73s/it]\n",
      "100%|██████████| 26/26 [00:46<00:00,  1.93s/it]\n",
      "100%|██████████| 27/27 [00:47<00:00,  1.52s/it]\n",
      "100%|██████████| 26/26 [00:47<00:00,  1.77s/it]\n",
      "100%|██████████| 27/27 [00:46<00:00,  2.04s/it]\n",
      "100%|██████████| 27/27 [00:47<00:00,  1.97s/it]\n",
      "100%|██████████| 27/27 [00:48<00:00,  1.72s/it]\n",
      "100%|██████████| 26/26 [00:49<00:00,  1.12it/s]\n",
      "100%|██████████| 27/27 [00:52<00:00,  1.20s/it]\n",
      "100%|██████████| 26/26 [00:53<00:00,  2.37s/it]\n",
      "100%|██████████| 27/27 [00:53<00:00,  1.04it/s]\n",
      "100%|██████████| 27/27 [00:54<00:00,  2.75s/it]\n",
      "100%|██████████| 26/26 [00:53<00:00,  1.21s/it]\n",
      "100%|██████████| 26/26 [00:54<00:00,  1.95s/it]\n",
      "100%|██████████| 26/26 [00:54<00:00,  2.11s/it]\n",
      "100%|██████████| 26/26 [00:55<00:00,  2.53s/it]\n",
      "100%|██████████| 27/27 [00:56<00:00,  1.64s/it]\n",
      "100%|██████████| 26/26 [00:59<00:00,  1.99s/it]\n",
      "100%|██████████| 26/26 [01:00<00:00,  3.54s/it]\n",
      " 93%|█████████▎| 25/27 [01:01<00:04,  2.13s/it]\n",
      "100%|██████████| 27/27 [01:01<00:00,  1.97s/it]\n",
      "100%|██████████| 27/27 [01:02<00:00,  1.97s/it]\n",
      "100%|██████████| 27/27 [01:02<00:00,  1.73s/it]\n",
      "100%|██████████| 26/26 [01:04<00:00,  1.72s/it]\n",
      "100%|██████████| 27/27 [01:04<00:00,  2.00s/it]\n",
      "100%|██████████| 27/27 [01:05<00:00,  1.79s/it]\n",
      "100%|██████████| 27/27 [01:05<00:00,  2.29s/it]\n",
      "100%|██████████| 27/27 [01:07<00:00,  1.96s/it]\n",
      "100%|██████████| 27/27 [01:11<00:00,  2.31s/it]\n",
      "100%|██████████| 26/26 [01:20<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 83.56s (training model: 0.29s, training explainer: 0.03s, experiment: 83.24s)\n",
      "Number of extracted samples: 504\n",
      "Number of accurate extracted samples: 504\n",
      "Precision: 1.0, recall: 0.6116504854368932\n",
      "dataset: heart numeric, model: neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i40/langema/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "100%|██████████| 27/27 [00:37<00:00,  1.34s/it]\n",
      " 85%|████████▌ | 23/27 [00:40<00:08,  2.22s/it]\n",
      " 89%|████████▉ | 24/27 [00:44<00:04,  1.50s/it]\n",
      "100%|██████████| 26/26 [00:48<00:00,  1.51s/it]\n",
      "100%|██████████| 26/26 [00:49<00:00,  1.99s/it]\n",
      "100%|██████████| 27/27 [00:49<00:00,  2.54s/it]\n",
      "100%|██████████| 26/26 [00:49<00:00,  1.41s/it]\n",
      "100%|██████████| 26/26 [00:50<00:00,  1.44s/it]\n",
      "100%|██████████| 27/27 [00:51<00:00,  2.02s/it]\n",
      "100%|██████████| 26/26 [00:51<00:00,  1.33s/it]\n",
      " 88%|████████▊ | 23/26 [00:53<00:09,  3.31s/it]\n",
      " 93%|█████████▎| 25/27 [00:53<00:06,  3.30s/it]\n",
      "100%|██████████| 26/26 [00:55<00:00,  1.27s/it]\n",
      " 85%|████████▍ | 22/26 [00:55<00:11,  2.86s/it]\n",
      "100%|██████████| 26/26 [00:56<00:00,  1.91s/it]\n",
      "100%|██████████| 26/26 [00:56<00:00,  1.14it/s]\n",
      "100%|██████████| 26/26 [00:56<00:00,  1.63s/it]\n",
      " 88%|████████▊ | 23/26 [00:56<00:06,  2.31s/it]\n",
      "100%|██████████| 26/26 [00:57<00:00,  1.67s/it]\n",
      "100%|██████████| 27/27 [00:56<00:00,  2.26s/it]\n",
      "100%|██████████| 27/27 [00:58<00:00,  1.57s/it]\n",
      " 96%|█████████▌| 25/26 [00:58<00:01,  1.33s/it]\n",
      "100%|██████████| 26/26 [00:59<00:00,  1.10s/it]\n",
      "100%|██████████| 26/26 [00:59<00:00,  1.50s/it]\n",
      "100%|██████████| 27/27 [01:00<00:00,  1.06it/s]\n",
      " 85%|████████▌ | 23/27 [01:01<00:07,  1.88s/it]\n",
      "100%|██████████| 27/27 [01:00<00:00,  1.37s/it]\n",
      "100%|██████████| 26/26 [01:01<00:00,  1.64it/s]\n",
      "100%|██████████| 27/27 [01:01<00:00,  1.25it/s]\n",
      "100%|██████████| 27/27 [01:02<00:00,  1.44s/it]\n",
      "100%|██████████| 27/27 [01:03<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 67.75s (training model: 2.53s, training explainer: 0.03s, experiment: 65.19s)\n",
      "Number of extracted samples: 493\n",
      "Number of accurate extracted samples: 493\n",
      "Precision: 1.0, recall: 0.5983009708737864\n",
      "dataset: heart categorical, model: decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 21/26 [00:08<00:02,  2.26it/s]\n",
      " 77%|███████▋  | 20/26 [00:09<00:02,  2.06it/s]\n",
      " 85%|████████▍ | 22/26 [00:10<00:01,  2.03it/s]\n",
      " 77%|███████▋  | 20/26 [00:09<00:02,  2.09it/s]\n",
      "100%|██████████| 27/27 [00:10<00:00,  2.50it/s]\n",
      "100%|██████████| 26/26 [00:10<00:00,  2.30it/s]\n",
      " 89%|████████▉ | 24/27 [00:10<00:01,  2.01it/s]\n",
      "100%|██████████| 27/27 [00:10<00:00,  2.50it/s]\n",
      "100%|██████████| 27/27 [00:11<00:00,  2.16it/s]\n",
      " 96%|█████████▌| 25/26 [00:11<00:00,  2.13it/s]\n",
      "100%|██████████| 26/26 [00:11<00:00,  2.39it/s]\n",
      " 78%|███████▊  | 21/27 [00:11<00:02,  2.42it/s]\n",
      "100%|██████████| 27/27 [00:11<00:00,  2.58it/s]\n",
      "100%|██████████| 26/26 [00:11<00:00,  2.46it/s]\n",
      "100%|██████████| 26/26 [00:11<00:00,  3.07it/s]\n",
      " 93%|█████████▎| 25/27 [00:11<00:00,  3.13it/s]\n",
      "100%|██████████| 26/26 [00:11<00:00,  2.15it/s]\n",
      "100%|██████████| 26/26 [00:11<00:00,  2.91it/s]\n",
      " 85%|████████▍ | 22/26 [00:11<00:02,  1.38it/s]\n",
      "100%|██████████| 26/26 [00:12<00:00,  1.89it/s]\n",
      "100%|██████████| 27/27 [00:12<00:00,  1.98it/s]\n",
      "100%|██████████| 27/27 [00:12<00:00,  2.56it/s]\n",
      "\n",
      "100%|██████████| 27/27 [00:12<00:00,  2.81it/s]\n",
      "100%|██████████| 26/26 [00:12<00:00,  2.57it/s]\n",
      "100%|██████████| 26/26 [00:12<00:00,  2.77it/s]\n",
      " 96%|█████████▋| 26/27 [00:12<00:00,  3.41it/s]\n",
      "100%|██████████| 27/27 [00:12<00:00,  2.84it/s]\n",
      "100%|██████████| 26/26 [00:13<00:00,  2.59it/s]\n",
      "100%|██████████| 27/27 [00:13<00:00,  3.11it/s]\n",
      "100%|██████████| 27/27 [00:14<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 16.14s (training model: 0.03s, training explainer: 0.04s, experiment: 16.07s)\n",
      "Number of extracted samples: 709\n",
      "Number of accurate extracted samples: 709\n",
      "Precision: 1.0, recall: 0.8646341463414634\n",
      "dataset: heart categorical, model: random forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:15<00:00,  1.88it/s]\n",
      "100%|██████████| 26/26 [00:15<00:00,  1.52it/s]\n",
      "100%|██████████| 26/26 [00:16<00:00,  1.52it/s]\n",
      "100%|██████████| 27/27 [00:17<00:00,  1.73it/s]\n",
      "100%|██████████| 26/26 [00:16<00:00,  1.39it/s]\n",
      "\n",
      "100%|██████████| 26/26 [00:16<00:00,  1.71it/s]\n",
      "100%|██████████| 26/26 [00:17<00:00,  1.48it/s]\n",
      "100%|██████████| 27/27 [00:17<00:00,  1.40it/s]\n",
      "100%|██████████| 26/26 [00:17<00:00,  1.44it/s]\n",
      "100%|██████████| 26/26 [00:17<00:00,  1.39it/s]\n",
      "100%|██████████| 27/27 [00:17<00:00,  1.27it/s]\n",
      "100%|██████████| 26/26 [00:17<00:00,  1.39it/s]\n",
      "100%|██████████| 26/26 [00:18<00:00,  1.33it/s]\n",
      " 96%|█████████▌| 25/26 [00:17<00:00,  1.56it/s]\n",
      "100%|██████████| 26/26 [00:17<00:00,  1.38it/s]\n",
      "100%|██████████| 26/26 [00:17<00:00,  1.72it/s]\n",
      "100%|██████████| 26/26 [00:18<00:00,  1.43it/s]\n",
      "100%|██████████| 26/26 [00:18<00:00,  1.47it/s]\n",
      "100%|██████████| 27/27 [00:18<00:00,  1.42it/s]\n",
      "100%|██████████| 27/27 [00:18<00:00,  1.31it/s]\n",
      " 85%|████████▌ | 23/27 [00:17<00:03,  1.05it/s]\n",
      "100%|██████████| 27/27 [00:18<00:00,  1.39it/s]\n",
      "100%|██████████| 26/26 [00:18<00:00,  1.50it/s]\n",
      "100%|██████████| 27/27 [00:18<00:00,  1.41it/s]\n",
      " 96%|█████████▋| 26/27 [00:18<00:00,  1.63it/s]\n",
      "100%|██████████| 26/26 [00:19<00:00,  1.85it/s]\n",
      "100%|██████████| 26/26 [00:19<00:00,  1.97it/s]\n",
      "100%|██████████| 27/27 [00:19<00:00,  1.83it/s]\n",
      "100%|██████████| 27/27 [00:19<00:00,  1.87it/s]\n",
      "100%|██████████| 27/27 [00:19<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 24.14s (training model: 0.71s, training explainer: 0.05s, experiment: 23.38s)\n",
      "Number of extracted samples: 648\n",
      "Number of accurate extracted samples: 648\n",
      "Precision: 1.0, recall: 0.7902439024390244\n",
      "dataset: heart categorical, model: neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i40/langema/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "100%|██████████| 26/26 [00:38<00:00,  1.60s/it]\n",
      "100%|██████████| 26/26 [00:39<00:00,  1.25s/it]\n",
      " 93%|█████████▎| 25/27 [00:40<00:03,  1.75s/it]\n",
      "100%|██████████| 27/27 [00:40<00:00,  2.03s/it]\n",
      "100%|██████████| 26/26 [00:40<00:00,  1.83s/it]\n",
      "\n",
      " 96%|█████████▌| 25/26 [00:40<00:01,  1.70s/it]\n",
      " 78%|███████▊  | 21/27 [00:40<00:10,  1.76s/it]\n",
      "100%|██████████| 26/26 [00:41<00:00,  1.47s/it]\n",
      " 85%|████████▌ | 23/27 [00:41<00:07,  1.85s/it]\n",
      "100%|██████████| 26/26 [00:40<00:00,  1.54s/it]\n",
      "100%|██████████| 26/26 [00:41<00:00,  1.54s/it]\n",
      "100%|██████████| 27/27 [00:41<00:00,  1.48s/it]\n",
      "100%|██████████| 26/26 [00:41<00:00,  1.56s/it]\n",
      "100%|██████████| 26/26 [00:42<00:00,  1.69s/it]\n",
      " 93%|█████████▎| 25/27 [00:42<00:02,  1.42s/it]\n",
      "100%|██████████| 27/27 [00:42<00:00,  1.33s/it]\n",
      " 85%|████████▌ | 23/27 [00:42<00:05,  1.37s/it]\n",
      " 93%|█████████▎| 25/27 [00:42<00:02,  1.20s/it]\n",
      " 93%|█████████▎| 25/27 [00:43<00:03,  1.64s/it]\n",
      "100%|██████████| 26/26 [00:43<00:00,  1.48s/it]\n",
      "100%|██████████| 27/27 [00:43<00:00,  1.26it/s]\n",
      " 93%|█████████▎| 25/27 [00:43<00:02,  1.06s/it]\n",
      "100%|██████████| 26/26 [00:44<00:00,  1.50s/it]\n",
      "100%|██████████| 27/27 [00:43<00:00,  1.12it/s]\n",
      "100%|██████████| 27/27 [00:44<00:00,  1.16s/it]\n",
      "100%|██████████| 27/27 [00:44<00:00,  1.11s/it]\n",
      "100%|██████████| 27/27 [00:44<00:00,  1.21it/s]\n",
      "100%|██████████| 26/26 [00:45<00:00,  1.28it/s]\n",
      "100%|██████████| 27/27 [00:45<00:00,  1.12it/s]\n",
      "100%|██████████| 27/27 [00:45<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 50.73s (training model: 2.80s, training explainer: 0.04s, experiment: 47.89s)\n",
      "Number of extracted samples: 645\n",
      "Number of accurate extracted samples: 645\n",
      "Precision: 1.0, recall: 0.7865853658536586\n",
      "dataset: census, model: decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 835/848 [18:21<00:18,  1.40s/it]\n",
      "100%|██████████| 849/849 [18:30<00:00,  1.16s/it]\n",
      "100%|██████████| 849/849 [18:31<00:00,  1.09s/it]\n",
      "100%|██████████| 848/848 [18:32<00:00,  1.41s/it]\n",
      "100%|██████████| 849/849 [18:35<00:00,  1.45s/it]\n",
      " 99%|█████████▉| 839/849 [18:37<00:13,  1.40s/it]\n",
      "100%|██████████| 849/849 [18:37<00:00,  1.08it/s]\n",
      "100%|██████████| 849/849 [18:35<00:00,  1.46s/it]\n",
      " 99%|█████████▊| 838/849 [18:37<00:15,  1.42s/it]\n",
      "100%|██████████| 848/848 [18:37<00:00,  1.27s/it]\n",
      "100%|██████████| 849/849 [18:39<00:00,  1.57s/it]\n",
      " 99%|█████████▉| 838/848 [18:38<00:15,  1.50s/it]\n",
      "100%|██████████| 849/849 [18:37<00:00,  1.13s/it]\n",
      "100%|██████████| 849/849 [18:38<00:00,  1.52s/it]\n",
      "100%|██████████| 848/848 [18:41<00:00,  1.31s/it]\n",
      "100%|██████████| 849/849 [18:48<00:00,  1.13s/it]\n",
      "100%|██████████| 849/849 [18:47<00:00,  1.25s/it]\n",
      "100%|██████████| 849/849 [18:47<00:00,  1.29s/it]\n",
      "100%|██████████| 849/849 [18:49<00:00,  1.22s/it]\n",
      "100%|██████████| 849/849 [18:49<00:00,  1.31s/it]\n",
      "100%|██████████| 848/848 [18:49<00:00,  1.12s/it]\n",
      "100%|██████████| 849/849 [18:50<00:00,  1.07s/it]\n",
      "100%|██████████| 849/849 [18:52<00:00,  1.23s/it]\n",
      "100%|██████████| 849/849 [18:51<00:00,  1.18s/it]\n",
      "100%|██████████| 849/849 [18:54<00:00,  1.20s/it]\n",
      "100%|██████████| 849/849 [18:54<00:00,  1.19s/it]\n",
      "100%|██████████| 849/849 [18:55<00:00,  1.25it/s]\n",
      "100%|██████████| 849/849 [18:56<00:00,  1.17it/s]\n",
      "100%|██████████| 849/849 [19:00<00:00,  1.06s/it]\n",
      "100%|██████████| 849/849 [19:05<00:00,  1.18it/s]\n",
      "100%|██████████| 849/849 [19:08<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1179.12s (training model: 1.40s, training explainer: 0.28s, experiment: 1177.43s)\n",
      "Number of extracted samples: 2027\n",
      "Number of accurate extracted samples: 2027\n",
      "Precision: 1.0, recall: 0.07703123812419245\n",
      "dataset: census, model: random forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 849/849 [40:22<00:00,  3.32s/it]\n",
      "100%|██████████| 849/849 [40:26<00:00,  3.19s/it]\n",
      "100%|██████████| 849/849 [40:20<00:00,  2.85s/it]\n",
      "100%|██████████| 848/848 [40:29<00:00,  3.01s/it]\n",
      "100%|██████████| 849/849 [40:21<00:00,  2.73s/it]\n",
      "100%|█████████▉| 847/849 [40:21<00:05,  2.70s/it]\n",
      "100%|██████████| 848/848 [40:31<00:00,  2.75s/it]\n",
      "100%|██████████| 849/849 [40:39<00:00,  3.08s/it]\n",
      "100%|██████████| 849/849 [40:26<00:00,  2.61s/it]\n",
      "100%|██████████| 848/848 [40:30<00:00,  2.99s/it]\n",
      "100%|██████████| 849/849 [40:28<00:00,  2.71s/it]\n",
      "100%|██████████| 848/848 [40:46<00:00,  2.76s/it]\n",
      "100%|██████████| 849/849 [40:35<00:00,  2.66s/it]\n",
      "100%|██████████| 849/849 [40:38<00:00,  2.85s/it]\n",
      "100%|██████████| 849/849 [40:46<00:00,  2.61s/it]\n",
      "100%|██████████| 849/849 [40:50<00:00,  2.75s/it]\n",
      "100%|██████████| 849/849 [40:39<00:00,  2.53s/it]\n",
      "100%|██████████| 849/849 [40:38<00:00,  2.52s/it]\n",
      "100%|██████████| 849/849 [40:44<00:00,  3.06s/it]\n",
      "100%|██████████| 849/849 [40:48<00:00,  2.78s/it]\n",
      "100%|██████████| 849/849 [41:01<00:00,  3.00s/it]\n",
      "100%|██████████| 849/849 [40:54<00:00,  2.69s/it]\n",
      "100%|██████████| 849/849 [41:00<00:00,  2.53s/it]\n",
      "100%|██████████| 849/849 [40:51<00:00,  2.37s/it]\n",
      "100%|██████████| 849/849 [40:58<00:00,  2.62s/it]\n",
      "100%|██████████| 849/849 [40:57<00:00,  2.40s/it]\n",
      "100%|██████████| 849/849 [40:56<00:00,  2.61s/it]\n",
      "100%|██████████| 849/849 [40:57<00:00,  2.33s/it]\n",
      "100%|██████████| 848/848 [41:08<00:00,  2.65s/it]\n",
      "100%|██████████| 849/849 [41:04<00:00,  2.88s/it]\n",
      "100%|██████████| 849/849 [40:59<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2539.67s (training model: 35.51s, training explainer: 0.19s, experiment: 2503.98s)\n",
      "Number of extracted samples: 1476\n",
      "Number of accurate extracted samples: 1476\n",
      "Precision: 1.0, recall: 0.05609181424336855\n",
      "dataset: census, model: neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i40/langema/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 97%|█████████▋| 820/848 [39:33<01:05,  2.34s/it]\n",
      " 98%|█████████▊| 831/849 [39:51<00:45,  2.53s/it]\n",
      "100%|██████████| 848/848 [39:51<00:00,  2.52s/it]\n",
      "100%|██████████| 849/849 [39:54<00:00,  2.57s/it]\n",
      "100%|██████████| 849/849 [40:09<00:00,  2.31s/it]\n",
      "100%|██████████| 849/849 [40:19<00:00,  3.09s/it]\n",
      "100%|██████████| 849/849 [40:27<00:00,  2.31s/it]\n",
      "100%|██████████| 849/849 [40:29<00:00,  2.70s/it]\n",
      "\n",
      " 98%|█████████▊| 831/849 [40:28<00:41,  2.28s/it]\n",
      "100%|██████████| 848/848 [40:29<00:00,  2.42s/it]\n",
      "100%|██████████| 849/849 [40:35<00:00,  2.52s/it]\n",
      "100%|██████████| 849/849 [40:33<00:00,  2.01s/it]\n",
      "100%|██████████| 849/849 [40:35<00:00,  2.16s/it]\n",
      "100%|██████████| 849/849 [40:39<00:00,  2.66s/it]\n",
      "100%|██████████| 849/849 [40:40<00:00,  2.80s/it]\n",
      "100%|██████████| 848/848 [40:40<00:00,  2.17s/it]\n",
      "100%|██████████| 849/849 [40:40<00:00,  2.02s/it]\n",
      "100%|██████████| 849/849 [40:43<00:00,  2.18s/it]\n",
      " 99%|█████████▉| 838/848 [40:41<00:19,  1.95s/it]\n",
      "100%|██████████| 849/849 [40:43<00:00,  1.89s/it]\n",
      "\n",
      " 99%|█████████▊| 838/849 [40:41<00:20,  1.84s/it]\n",
      "100%|██████████| 849/849 [40:41<00:00,  1.69s/it]\n",
      "100%|██████████| 849/849 [40:44<00:00,  1.70s/it]\n",
      "100%|██████████| 849/849 [40:45<00:00,  1.54s/it]\n",
      "100%|██████████| 849/849 [40:49<00:00,  1.74s/it]\n",
      " 99%|█████████▉| 843/849 [40:48<00:08,  1.43s/it]\n",
      "100%|██████████| 849/849 [40:50<00:00,  1.67s/it]\n",
      "100%|██████████| 848/848 [40:55<00:00,  1.28s/it]\n",
      "100%|██████████| 849/849 [40:56<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2617.26s (training model: 132.49s, training explainer: 0.19s, experiment: 2484.57s)\n",
      "Number of extracted samples: 1866\n",
      "Number of accurate extracted samples: 1866\n",
      "Precision: 1.0, recall: 0.07091282207190089\n",
      "dataset: census numeric, model: decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 326/333 [01:20<00:02,  3.05it/s]\n",
      " 98%|█████████▊| 324/332 [01:22<00:01,  4.00it/s]\n",
      " 95%|█████████▍| 315/333 [01:22<00:03,  4.64it/s]\n",
      " 94%|█████████▎| 311/332 [01:22<00:05,  3.52it/s]\n",
      "100%|██████████| 332/332 [01:23<00:00,  4.49it/s]\n",
      "100%|██████████| 332/332 [01:24<00:00,  4.10it/s]\n",
      "100%|██████████| 332/332 [01:24<00:00,  3.95it/s]\n",
      "100%|██████████| 332/332 [01:24<00:00,  3.92it/s]\n",
      " 94%|█████████▍| 313/332 [01:25<00:05,  3.72it/s]\n",
      "100%|██████████| 333/333 [01:25<00:00,  4.13it/s]\n",
      " 99%|█████████▉| 329/332 [01:25<00:00,  5.45it/s]\n",
      "100%|██████████| 332/332 [01:25<00:00,  3.50it/s]\n",
      "100%|██████████| 332/332 [01:26<00:00,  3.43it/s]\n",
      "100%|██████████| 332/332 [01:26<00:00,  4.24it/s]\n",
      "100%|██████████| 332/332 [01:25<00:00,  4.17it/s]\n",
      "100%|██████████| 332/332 [01:26<00:00,  5.38it/s]\n",
      "100%|██████████| 332/332 [01:26<00:00,  4.55it/s]\n",
      " 98%|█████████▊| 326/333 [01:26<00:01,  3.86it/s]\n",
      " 97%|█████████▋| 323/332 [01:27<00:02,  4.39it/s]\n",
      "100%|██████████| 332/332 [01:27<00:00,  4.38it/s]\n",
      "\n",
      "100%|██████████| 333/333 [01:27<00:00,  3.21it/s]\n",
      "100%|██████████| 333/333 [01:26<00:00,  4.14it/s]\n",
      " 99%|█████████▉| 329/332 [01:27<00:00,  4.00it/s]\n",
      "100%|██████████| 333/333 [01:27<00:00,  5.37it/s]\n",
      "100%|██████████| 332/332 [01:28<00:00,  4.42it/s]\n",
      "100%|██████████| 332/332 [01:29<00:00,  4.45it/s]\n",
      "100%|██████████| 332/332 [01:29<00:00,  3.86it/s]\n",
      "100%|██████████| 332/332 [01:30<00:00,  2.87it/s]\n",
      "100%|██████████| 332/332 [01:30<00:00,  3.80it/s]\n",
      "100%|██████████| 333/333 [01:35<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 99.89s (training model: 0.06s, training explainer: 0.03s, experiment: 99.81s)\n",
      "Number of extracted samples: 1377\n",
      "Number of accurate extracted samples: 1377\n",
      "Precision: 1.0, recall: 0.13365039308939144\n",
      "dataset: census numeric, model: random forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [04:19<00:00,  1.58it/s]\n",
      "100%|██████████| 333/333 [04:22<00:00,  1.55it/s]\n",
      "100%|██████████| 332/332 [04:24<00:00,  1.12it/s]\n",
      "100%|██████████| 332/332 [04:20<00:00,  1.13it/s]\n",
      "100%|██████████| 332/332 [04:26<00:00,  1.40it/s]\n",
      "100%|█████████▉| 331/332 [04:23<00:00,  1.47it/s]\n",
      "100%|██████████| 332/332 [04:26<00:00,  1.05it/s]\n",
      "100%|██████████| 332/332 [04:24<00:00,  1.20it/s]\n",
      "100%|██████████| 332/332 [04:26<00:00,  1.16it/s]\n",
      "100%|██████████| 332/332 [04:30<00:00,  1.50it/s]\n",
      "100%|██████████| 332/332 [04:29<00:00,  1.25it/s]\n",
      "100%|██████████| 332/332 [04:26<00:00,  1.09it/s]\n",
      "100%|██████████| 333/333 [04:30<00:00,  1.19it/s]\n",
      "100%|██████████| 333/333 [04:28<00:00,  1.22it/s]\n",
      "100%|██████████| 332/332 [04:29<00:00,  1.27it/s]\n",
      "\n",
      "100%|██████████| 333/333 [04:27<00:00,  1.00it/s]\n",
      "100%|██████████| 333/333 [04:29<00:00,  1.15it/s]\n",
      "100%|██████████| 332/332 [04:32<00:00,  1.20it/s]\n",
      "100%|██████████| 333/333 [04:29<00:00,  1.12it/s]\n",
      "100%|█████████▉| 331/332 [04:34<00:00,  1.14it/s]\n",
      "100%|██████████| 332/332 [04:34<00:00,  1.26it/s]\n",
      "100%|██████████| 333/333 [04:33<00:00,  1.57it/s]\n",
      "100%|██████████| 332/332 [04:30<00:00,  1.64it/s]\n",
      "100%|██████████| 332/332 [04:34<00:00,  1.31it/s]\n",
      "100%|██████████| 333/333 [04:35<00:00,  1.51it/s]\n",
      "100%|██████████| 332/332 [04:32<00:00,  1.73it/s]\n",
      "100%|██████████| 333/333 [04:32<00:00,  1.04s/it]\n",
      "100%|██████████| 332/332 [04:34<00:00,  1.32it/s]\n",
      "100%|██████████| 332/332 [04:35<00:00,  1.14it/s]\n",
      "100%|██████████| 333/333 [04:35<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 289.17s (training model: 1.28s, training explainer: 0.03s, experiment: 287.87s)\n",
      "Number of extracted samples: 1080\n",
      "Number of accurate extracted samples: 1080\n",
      "Precision: 1.0, recall: 0.10482383771716976\n",
      "dataset: census numeric, model: neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i40/langema/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 320/333 [10:13<00:21,  1.62s/it]\n",
      "100%|██████████| 332/332 [10:20<00:00,  2.12s/it]\n",
      "100%|██████████| 333/333 [10:23<00:00,  1.57s/it]\n",
      "100%|██████████| 332/332 [10:22<00:00,  1.73s/it]\n",
      "100%|██████████| 332/332 [10:30<00:00,  1.63s/it]\n",
      " 99%|█████████▉| 329/332 [10:29<00:04,  1.47s/it]\n",
      "100%|██████████| 333/333 [10:29<00:00,  1.23s/it]\n",
      " 99%|█████████▉| 329/332 [10:33<00:04,  1.39s/it]\n",
      "100%|██████████| 332/332 [10:34<00:00,  1.45s/it]\n",
      "100%|██████████| 332/332 [10:32<00:00,  1.53s/it]\n",
      "100%|██████████| 332/332 [10:38<00:00,  1.46s/it]\n",
      " 99%|█████████▉| 328/332 [10:37<00:06,  1.53s/it]\n",
      "100%|██████████| 332/332 [10:38<00:00,  1.64s/it]\n",
      " 98%|█████████▊| 327/333 [10:38<00:11,  1.91s/it]\n",
      "100%|██████████| 333/333 [10:41<00:00,  1.10s/it]\n",
      "100%|██████████| 332/332 [10:41<00:00,  1.10s/it]\n",
      "100%|██████████| 333/333 [10:41<00:00,  1.21s/it]\n",
      "100%|██████████| 333/333 [10:39<00:00,  1.90s/it]\n",
      "100%|██████████| 332/332 [10:42<00:00,  1.17s/it]\n",
      "100%|██████████| 333/333 [10:43<00:00,  1.12s/it]\n",
      "100%|██████████| 332/332 [10:45<00:00,  1.00s/it]\n",
      " 99%|█████████▉| 329/332 [10:43<00:04,  1.48s/it]\n",
      "100%|██████████| 332/332 [10:42<00:00,  1.18s/it]\n",
      "\n",
      "100%|██████████| 332/332 [10:38<00:00,  1.25it/s]\n",
      "100%|██████████| 332/332 [10:45<00:00,  1.16it/s]\n",
      "100%|██████████| 332/332 [10:44<00:00,  1.16it/s]\n",
      "100%|██████████| 333/333 [10:43<00:00,  1.75it/s]\n",
      "100%|██████████| 332/332 [10:46<00:00,  1.31it/s]\n",
      "100%|██████████| 332/332 [10:44<00:00,  1.86it/s]\n",
      "100%|██████████| 332/332 [10:44<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 679.19s (training model: 26.76s, training explainer: 0.02s, experiment: 652.40s)\n",
      "Number of extracted samples: 1468\n",
      "Number of accurate extracted samples: 1468\n",
      "Precision: 1.0, recall: 0.14248277200815296\n",
      "dataset: census categorical, model: decision tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581/581 [10:38<00:00,  1.04s/it]\n",
      "100%|█████████▉| 579/581 [10:41<00:02,  1.21s/it]\n",
      "100%|██████████| 581/581 [10:43<00:00,  1.33it/s]\n",
      "100%|██████████| 581/581 [10:43<00:00,  1.03s/it]\n",
      "100%|██████████| 582/582 [10:49<00:00,  1.01it/s]\n",
      "100%|██████████| 581/581 [10:49<00:00,  1.25it/s]\n",
      "100%|██████████| 582/582 [10:52<00:00,  1.26s/it]\n",
      "100%|██████████| 581/581 [10:52<00:00,  1.00s/it]\n",
      "100%|██████████| 582/582 [10:53<00:00,  1.21s/it]\n",
      "100%|██████████| 581/581 [10:53<00:00,  1.00it/s]\n",
      "100%|██████████| 582/582 [10:55<00:00,  1.04s/it]\n",
      "100%|██████████| 582/582 [10:56<00:00,  1.10s/it]\n",
      "100%|██████████| 581/581 [10:56<00:00,  1.15s/it]\n",
      "100%|██████████| 582/582 [10:56<00:00,  1.37s/it]\n",
      "100%|██████████| 581/581 [10:56<00:00,  1.17s/it]\n",
      "100%|██████████| 582/582 [10:59<00:00,  1.14s/it]\n",
      "100%|██████████| 581/581 [10:58<00:00,  1.05it/s]\n",
      "100%|██████████| 582/582 [10:59<00:00,  1.20s/it]\n",
      "100%|██████████| 582/582 [11:00<00:00,  1.18it/s]\n",
      "100%|██████████| 582/582 [11:00<00:00,  1.07it/s]\n",
      "100%|██████████| 581/581 [11:00<00:00,  1.09s/it]\n",
      "100%|██████████| 581/581 [11:01<00:00,  1.06s/it]\n",
      "100%|██████████| 582/582 [11:02<00:00,  1.31s/it]\n",
      "100%|██████████| 581/581 [11:02<00:00,  1.01s/it]\n",
      "100%|██████████| 582/582 [11:03<00:00,  1.11s/it]\n",
      "100%|██████████| 582/582 [11:02<00:00,  1.18it/s]\n",
      "100%|██████████| 582/582 [11:04<00:00,  1.13it/s]\n",
      "100%|██████████| 582/582 [11:05<00:00,  1.07it/s]\n",
      "100%|██████████| 581/581 [11:06<00:00,  1.02it/s]\n",
      "100%|██████████| 581/581 [11:08<00:00,  1.15s/it]\n",
      "100%|██████████| 581/581 [11:13<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 745.76s (training model: 1.23s, training explainer: 0.56s, experiment: 743.97s)\n",
      "Number of extracted samples: 14178\n",
      "Number of accurate extracted samples: 14178\n",
      "Precision: 1.0, recall: 0.7865305669588373\n",
      "dataset: census categorical, model: random forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581/581 [20:26<00:00,  1.96s/it]\n",
      " 97%|█████████▋| 566/581 [20:29<00:28,  1.89s/it]\n",
      "100%|██████████| 581/581 [20:41<00:00,  1.96s/it]\n",
      "100%|██████████| 582/582 [20:41<00:00,  2.26s/it]\n",
      "100%|██████████| 581/581 [20:38<00:00,  2.30s/it]\n",
      "100%|██████████| 582/582 [20:38<00:00,  2.10s/it]\n",
      " 99%|█████████▉| 575/582 [20:33<00:15,  2.20s/it]\n",
      "100%|██████████| 582/582 [20:37<00:00,  1.66s/it]\n",
      "100%|██████████| 582/582 [20:42<00:00,  2.05s/it]\n",
      "100%|██████████| 582/582 [20:46<00:00,  2.06s/it]\n",
      "100%|██████████| 582/582 [20:42<00:00,  1.78s/it]\n",
      "100%|█████████▉| 580/581 [20:56<00:01,  1.88s/it]\n",
      "100%|██████████| 582/582 [20:54<00:00,  1.98s/it]\n",
      "100%|██████████| 582/582 [20:43<00:00,  1.89s/it]\n",
      "100%|██████████| 581/581 [20:58<00:00,  1.76s/it]\n",
      "100%|██████████| 582/582 [20:46<00:00,  1.86s/it]\n",
      "100%|██████████| 582/582 [20:55<00:00,  2.04s/it]\n",
      "100%|██████████| 581/581 [20:56<00:00,  2.13s/it]\n",
      "100%|██████████| 581/581 [20:57<00:00,  2.19s/it]\n",
      "100%|██████████| 581/581 [20:48<00:00,  1.86s/it]\n",
      "100%|██████████| 581/581 [20:48<00:00,  1.91s/it]\n",
      "100%|██████████| 582/582 [20:54<00:00,  2.08s/it]\n",
      "100%|██████████| 581/581 [20:58<00:00,  2.09s/it]\n",
      "100%|██████████| 581/581 [20:55<00:00,  1.91s/it]\n",
      "100%|██████████| 582/582 [20:59<00:00,  2.01s/it]\n",
      "100%|██████████| 582/582 [21:02<00:00,  2.25s/it]\n",
      "100%|██████████| 581/581 [21:07<00:00,  1.92s/it]\n",
      "100%|██████████| 581/581 [21:00<00:00,  2.28s/it]\n",
      "100%|██████████| 581/581 [21:06<00:00,  1.51s/it]\n",
      "100%|██████████| 582/582 [21:02<00:00,  1.96s/it]\n",
      "100%|██████████| 581/581 [21:28<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1372.50s (training model: 16.91s, training explainer: 0.48s, experiment: 1355.11s)\n",
      "Number of extracted samples: 14038\n",
      "Number of accurate extracted samples: 14038\n",
      "Precision: 1.0, recall: 0.7787640075446577\n",
      "dataset: census categorical, model: neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i40/langema/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 99%|█████████▉| 578/581 [22:04<00:07,  2.51s/it]\n",
      "100%|██████████| 581/581 [22:04<00:00,  2.15s/it]\n",
      "100%|██████████| 581/581 [22:08<00:00,  1.82s/it]\n",
      "100%|██████████| 581/581 [22:10<00:00,  1.79s/it]\n",
      "100%|██████████| 581/581 [22:13<00:00,  2.86s/it]\n",
      "100%|██████████| 581/581 [22:15<00:00,  2.75s/it]\n",
      " 99%|█████████▉| 576/581 [22:17<00:08,  1.75s/it]\n",
      "100%|██████████| 582/582 [22:18<00:00,  1.69s/it]\n",
      "100%|██████████| 582/582 [22:17<00:00,  2.24s/it]\n",
      "100%|██████████| 582/582 [22:23<00:00,  1.97s/it]\n",
      "100%|██████████| 581/581 [22:24<00:00,  1.86s/it]\n",
      "100%|██████████| 582/582 [22:26<00:00,  1.62s/it]\n",
      "100%|██████████| 582/582 [22:27<00:00,  2.36s/it]\n",
      "100%|██████████| 581/581 [22:26<00:00,  1.78s/it]\n",
      "100%|██████████| 581/581 [22:27<00:00,  1.97s/it]\n",
      "100%|██████████| 581/581 [22:25<00:00,  1.70s/it]\n",
      "100%|██████████| 581/581 [22:29<00:00,  1.97s/it]\n",
      "100%|██████████| 581/581 [22:30<00:00,  1.30s/it]\n",
      " 99%|█████████▉| 577/581 [22:31<00:06,  1.58s/it]\n",
      "100%|██████████| 582/582 [22:33<00:00,  1.70s/it]\n",
      " 99%|█████████▉| 578/582 [22:33<00:05,  1.46s/it]\n",
      "100%|██████████| 581/581 [22:36<00:00,  1.37s/it]\n",
      "100%|██████████| 582/582 [22:35<00:00,  1.37s/it]\n",
      "100%|██████████| 581/581 [22:35<00:00,  1.39s/it]\n",
      "100%|██████████| 581/581 [22:35<00:00,  1.27s/it]\n",
      "100%|██████████| 582/582 [22:37<00:00,  1.13s/it]\n",
      "100%|██████████| 581/581 [22:38<00:00,  1.13s/it]\n",
      "100%|██████████| 582/582 [22:42<00:00,  1.13it/s]\n",
      "100%|██████████| 582/582 [22:44<00:00,  1.20it/s]\n",
      "100%|██████████| 582/582 [22:45<00:00,  1.26it/s]\n",
      "100%|██████████| 582/582 [22:44<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1525.03s (training model: 88.70s, training explainer: 0.41s, experiment: 1435.93s)\n",
      "Number of extracted samples: 12541\n",
      "Number of accurate extracted samples: 12541\n",
      "Precision: 1.0, recall: 0.6957172972373239\n"
     ]
    }
   ],
   "source": [
    "# This will run the experiment for each dataset and model combination\n",
    "\n",
    "results = run_all_experiments(CounterfactualTDE, dataset_dicts, model_dicts, random_state=0, num_queries=num_queries_dict, model_access=False, threads=threads, results_table=results, is_mem_inf=False, convert_cat_to_str=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1feb9a8",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Precision is the percentage of extracted samples that is actually from the training data. \n",
    "\n",
    "Recall is the ratio of the number extracted training samples to all training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39bb0af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T20:54:34.095962Z",
     "iopub.status.busy": "2022-10-29T20:54:34.091682Z",
     "iopub.status.idle": "2022-10-29T20:54:34.129628Z",
     "shell.execute_reply": "2022-10-29T20:54:34.126999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heart</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.653753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heart</td>\n",
       "      <td>random forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart</td>\n",
       "      <td>neural network</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heart numeric</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart numeric</td>\n",
       "      <td>random forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heart numeric</td>\n",
       "      <td>neural network</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.598301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>heart categorical</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>heart categorical</td>\n",
       "      <td>random forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.790244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heart categorical</td>\n",
       "      <td>neural network</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>census</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>census</td>\n",
       "      <td>random forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.056092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>census</td>\n",
       "      <td>neural network</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>census numeric</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>census numeric</td>\n",
       "      <td>random forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>census numeric</td>\n",
       "      <td>neural network</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>census categorical</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>census categorical</td>\n",
       "      <td>random forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.778764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>census categorical</td>\n",
       "      <td>neural network</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.695717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset           model  precision    recall\n",
       "0                heart   decision tree        1.0  0.653753\n",
       "1                heart   random forest        1.0  0.583535\n",
       "2                heart  neural network        1.0  0.567797\n",
       "3        heart numeric   decision tree        1.0  0.645631\n",
       "4        heart numeric   random forest        1.0  0.611650\n",
       "5        heart numeric  neural network        1.0  0.598301\n",
       "6    heart categorical   decision tree        1.0  0.864634\n",
       "7    heart categorical   random forest        1.0  0.790244\n",
       "8    heart categorical  neural network        1.0  0.786585\n",
       "9               census   decision tree        1.0  0.077031\n",
       "10              census   random forest        1.0  0.056092\n",
       "11              census  neural network        1.0  0.070913\n",
       "12      census numeric   decision tree        1.0  0.133650\n",
       "13      census numeric   random forest        1.0  0.104824\n",
       "14      census numeric  neural network        1.0  0.142483\n",
       "15  census categorical   decision tree        1.0  0.786531\n",
       "16  census categorical   random forest        1.0  0.778764\n",
       "17  census categorical  neural network        1.0  0.695717"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31380dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T20:54:34.151825Z",
     "iopub.status.busy": "2022-10-29T20:54:34.147925Z",
     "iopub.status.idle": "2022-10-29T20:54:34.173325Z",
     "shell.execute_reply": "2022-10-29T20:54:34.169969Z"
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv('results/2-1-cf-training-data-extraction-results.csv', index=False, na_rep='NaN', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054236f-8d24-4ad8-8b81-fb2ba96cd77b",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "In our experiments, training data extraction with counterfactuals drawn from the training data has a recall between 45% and 67% for numeric data and 30% to 64% for categorical data. Since the attack cannot produce any false positive samples, precision is always 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef338ab-a7ef-46aa-86f5-23ed8dc39a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
