{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75916e17",
   "metadata": {},
   "source": [
    "# Counterfactuals Training Data Extraction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6661d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:15.577215Z",
     "iopub.status.busy": "2022-10-29T17:40:15.572812Z",
     "iopub.status.idle": "2022-10-29T17:40:18.600644Z",
     "shell.execute_reply": "2022-10-29T17:40:18.588362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import sklearn.ensemble as es\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import dice_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27327d5-6352-40a0-a6d8-5f6298306064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:18.621351Z",
     "iopub.status.busy": "2022-10-29T17:40:18.620110Z",
     "iopub.status.idle": "2022-10-29T17:40:18.633920Z",
     "shell.execute_reply": "2022-10-29T17:40:18.630812Z"
    }
   },
   "outputs": [],
   "source": [
    "threads = 15\n",
    "\n",
    "logging.basicConfig()\n",
    "\n",
    "logger = logging.getLogger('xai-privacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2429dea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:18.647455Z",
     "iopub.status.busy": "2022-10-29T17:40:18.646421Z",
     "iopub.status.idle": "2022-10-29T17:40:21.024992Z",
     "shell.execute_reply": "2022-10-29T17:40:21.017649Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment_setup import run_all_experiments\n",
    "from experiment_setup import get_heart_disease_dataset\n",
    "from experiment_setup import get_census_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d487ce1-05ee-4457-8ca1-7163b67fe595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.047676Z",
     "iopub.status.busy": "2022-10-29T17:40:21.042595Z",
     "iopub.status.idle": "2022-10-29T17:40:21.064812Z",
     "shell.execute_reply": "2022-10-29T17:40:21.059050Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Age: removed 0 rows for missing values.\n",
      "Feature RestingBP: removed 59 rows for missing values.\n",
      "Feature Cholesterol: removed 27 rows for missing values.\n",
      "Feature FastingBS: add unknown category 2.0\n",
      "Feature RestingECG: add unknown category 3.0\n",
      "Feature MaxHR: removed 0 rows for missing values.\n",
      "Feature Oldpeak: removed 7 rows for missing values.\n",
      "Feature ST_Slope: add unknown category 4.0\n",
      "Feature CA: add unknown category 4.0\n",
      "Feature Thal: add unknown category 8.0\n",
      "Dropped 271 of 1097\n",
      "Dropped 273 of 1097\n",
      "Dropped 277 of 1097\n",
      "Dropped: 2399 of 32561\n",
      "census: Dropped 3848 of 30162\n",
      "num: Dropped 19859 of 30162\n",
      "cat: Dropped 12136 of 30162\n"
     ]
    }
   ],
   "source": [
    "DATASET_HALF = False\n",
    "\n",
    "data_heart_dict, data_heart_num_dict, data_heart_cat_dict = get_heart_disease_dataset(halve_dataset=DATASET_HALF)\n",
    "data_census_dict, data_census_num_dict, data_census_cat_dict = get_census_dataset(halve_dataset=DATASET_HALF)\n",
    "\n",
    "data_heart = data_heart_dict['dataset']\n",
    "data_heart_num = data_heart_num_dict['dataset']\n",
    "data_heart_cat = data_heart_cat_dict['dataset']\n",
    "data_census = data_census_dict['dataset']\n",
    "data_census_num = data_census_num_dict['dataset']\n",
    "data_census_cat = data_census_cat_dict['dataset']\n",
    "outcome_name_heart = data_heart_dict['outcome']\n",
    "numeric_features_heart = data_heart_dict['num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a61bbc",
   "metadata": {},
   "source": [
    "This notebook will test whether training data extraction is possible with counterfactuals (CF) that are drawn from the training data. Training data extraction means an attacker can find out the feature values of samples from the training data without prior knowledge of them. The attacker only has access to the model's prediction function and the explanation.\n",
    "\n",
    "This attack should be trivial because any counterfactual that is shown as an explanation was picked directly from the training data.\n",
    "\n",
    "The idea for counterfacutal training data extraction is as follows: The attacker makes repeated queries to the model with random input values. In order to do this, the attacker knows the maximum and minimum value of each feature in the training data (or the categorical values of each feature). The returned counterfactuals are the extracted training data.\n",
    "\n",
    "First, we implement the `train_explainer` and `training_data_extraction_model_access` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca67de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.080788Z",
     "iopub.status.busy": "2022-10-29T17:40:21.079754Z",
     "iopub.status.idle": "2022-10-29T17:40:21.132885Z",
     "shell.execute_reply": "2022-10-29T17:40:21.124719Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Attack code must be imported so that multiprocessing pool works. Check out ice_attack.py for the implementation of the attack.\n",
    "from cf_attack import CounterfactualTDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef61e5",
   "metadata": {},
   "source": [
    "# Executing Training Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a2083",
   "metadata": {},
   "source": [
    "We now generate five counterfactuals for the first sample from the training data to demonstrate counterfactual explanations in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c4cf59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.145689Z",
     "iopub.status.busy": "2022-10-29T17:40:21.144210Z",
     "iopub.status.idle": "2022-10-29T17:40:21.451541Z",
     "shell.execute_reply": "2022-10-29T17:40:21.449183Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = data_heart.drop(outcome_name_heart, axis=1)\n",
    "labels = data_heart[outcome_name_heart]\n",
    "\n",
    "# Train a random forest on training data.\n",
    "model = es.RandomForestClassifier(random_state=0)\n",
    "model = model.fit(features, labels)\n",
    "\n",
    "# Train explainer\n",
    "d = dice_ml.Data(dataframe=data_heart, continuous_features=numeric_features_heart, outcome_name=outcome_name_heart)\n",
    "\n",
    "m = dice_ml.Model(model=model, backend=\"sklearn\", model_type='classifier')\n",
    "# Generating counterfactuals from training data (kd-tree)\n",
    "exp = dice_ml.Dice(d, m, method=\"kdtree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "508a451a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:21.472262Z",
     "iopub.status.busy": "2022-10-29T17:40:21.469575Z",
     "iopub.status.idle": "2022-10-29T17:40:27.920613Z",
     "shell.execute_reply": "2022-10-29T17:40:27.917828Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Age  Sex ChestPainType  RestingBP  Cholesterol FastingBS RestingECG  \\\n0  47.0  1.0           1.0      110.0        249.0       0.0        0.0   \n\n   MaxHR ExerciseAngina  Oldpeak ST_Slope   CA Thal  HeartDisease  \n0  150.0            0.0      0.0      4.0  4.0  8.0           0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>CA</th>\n      <th>Thal</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>110.0</td>\n      <td>249.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set without sparsity correction (new outcome:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Age  Sex ChestPainType  RestingBP  Cholesterol FastingBS RestingECG  \\\n388   35.0  1.0           2.0      110.0        257.0       0.0        0.0   \n434   47.0  1.0           3.0      108.0        243.0       0.0        0.0   \n705   54.0  1.0           3.0      120.0        237.0       0.0        0.0   \n320   46.0  1.0           4.0      120.0        249.0       0.0        2.0   \n1111  33.0  0.0           4.0      100.0        246.0       0.0        0.0   \n\n      MaxHR ExerciseAngina  Oldpeak ST_Slope   CA Thal  \n388   140.0            0.0      0.0      4.0  4.0  8.0  \n434   152.0            0.0      0.0      1.0  0.0  3.0  \n705   150.0            1.0      1.5      4.0  4.0  7.0  \n320   144.0            0.0      0.8      1.0  0.0  7.0  \n1111  150.0            1.0      1.0      2.0  4.0  8.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>CA</th>\n      <th>Thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>388</th>\n      <td>35.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>110.0</td>\n      <td>257.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>140.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>47.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>108.0</td>\n      <td>243.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>152.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>705</th>\n      <td>54.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>120.0</td>\n      <td>237.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>150.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>320</th>\n      <td>46.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>249.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>144.0</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>1111</th>\n      <td>33.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>246.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>150.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e1 = exp.generate_counterfactuals(features[0:1], total_CFs=5, desired_class=\"opposite\")\n",
    "e1.visualize_as_dataframe(display_sparse_df=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084cf1e0",
   "metadata": {},
   "source": [
    "We can see that the counterfactuals are similar to the query sample and that they have a flipped prediction. These are the two general properties of counterfactual explanations.\n",
    "\n",
    "We will now do a small proof of concept of the experiment with logging enabled to demonstrate how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cacf1093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:27.940680Z",
     "iopub.status.busy": "2022-10-29T17:40:27.936367Z",
     "iopub.status.idle": "2022-10-29T17:40:58.832968Z",
     "shell.execute_reply": "2022-10-29T17:40:58.828827Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:xai-privacy:Numeric Features: ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
      "DEBUG:xai-privacy:Categorical Features: ['CA', 'ChestPainType', 'ExerciseAngina', 'FastingBS', 'RestingECG', 'ST_Slope', 'Sex', 'Thal']\n",
      "100%|██████████| 12/12 [00:09<00:00,  1.29it/s]\n",
      "DEBUG:xai-privacy:Sample 0: Counterfactuals \n",
      " [[38.0 '1.0' '4.0' 92.0 117.0 '0.0' '0.0' 134.0 '1.0' 2.5 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [57.0 '1.0' '4.0' 130.0 131.0 '0.0' '0.0' 115.0 '1.0' 1.2 '2.0' '1.0'\n",
      "  '7.0']\n",
      " [51.0 '0.0' '4.0' 120.0 0.0 '2.0' '0.0' 127.0 '1.0' 1.5 '1.0' '4.0'\n",
      "  '8.0']\n",
      " [36.0 '1.0' '4.0' 110.0 0.0 '2.0' '0.0' 125.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '6.0']]\n",
      "DEBUG:xai-privacy:Sample 1: Counterfactuals \n",
      " [[48.0 '1.0' '4.0' 160.0 268.0 '0.0' '0.0' 103.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [57.0 '1.0' '4.0' 150.0 276.0 '0.0' '2.0' 112.0 '1.0' 0.6 '2.0' '1.0'\n",
      "  '6.0']\n",
      " [57.0 '1.0' '4.0' 165.0 289.0 '1.0' '2.0' 124.0 '0.0' 1.0 '2.0' '3.0'\n",
      "  '7.0']\n",
      " [56.0 '0.0' '4.0' 200.0 288.0 '1.0' '2.0' 133.0 '1.0' 4.0 '3.0' '2.0'\n",
      "  '7.0']]\n",
      "DEBUG:xai-privacy:Sample 2: Counterfactuals \n",
      " [[58.0 '1.0' '4.0' 132.0 458.0 '1.0' '0.0' 69.0 '0.0' 1.0 '3.0' '4.0'\n",
      "  '8.0']\n",
      " [52.0 '1.0' '4.0' 140.0 404.0 '0.0' '0.0' 124.0 '1.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [48.0 '1.0' '4.0' 160.0 355.0 '0.0' '0.0' 99.0 '1.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [56.0 '1.0' '4.0' 170.0 388.0 '0.0' '1.0' 122.0 '1.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 3: Counterfactuals \n",
      " [[38.0 '0.0' '4.0' 110.0 0.0 '0.0' '0.0' 156.0 '0.0' 0.0 '2.0' '4.0'\n",
      "  '3.0']\n",
      " [34.0 '1.0' '4.0' 115.0 0.0 '2.0' '3.0' 154.0 '0.0' 0.2 '1.0' '4.0'\n",
      "  '8.0']\n",
      " [38.0 '1.0' '3.0' 100.0 0.0 '2.0' '0.0' 179.0 '0.0' -1.1 '1.0' '4.0'\n",
      "  '8.0']\n",
      " [40.0 '1.0' '4.0' 125.0 0.0 '1.0' '0.0' 165.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '7.0']]\n",
      "DEBUG:xai-privacy:Sample 4: Counterfactuals \n",
      " [[38.0 '0.0' '4.0' 110.0 0.0 '0.0' '0.0' 156.0 '0.0' 0.0 '2.0' '4.0'\n",
      "  '3.0']\n",
      " [34.0 '1.0' '4.0' 115.0 0.0 '2.0' '3.0' 154.0 '0.0' 0.2 '1.0' '4.0'\n",
      "  '8.0']\n",
      " [52.0 '1.0' '2.0' 140.0 100.0 '0.0' '0.0' 138.0 '1.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [49.0 '1.0' '3.0' 118.0 149.0 '0.0' '2.0' 126.0 '0.0' 0.8 '1.0' '3.0'\n",
      "  '3.0']]\n",
      "DEBUG:xai-privacy:Sample 5: Counterfactuals \n",
      " [[54.0 '1.0' '4.0' 130.0 603.0 '1.0' '0.0' 125.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [67.0 '0.0' '3.0' 115.0 564.0 '0.0' '2.0' 160.0 '0.0' 1.6 '2.0' '0.0'\n",
      "  '7.0']\n",
      " [40.0 '1.0' '4.0' 120.0 466.0 '2.0' '0.0' 152.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '6.0']\n",
      " [32.0 '1.0' '4.0' 118.0 529.0 '0.0' '0.0' 130.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 6: Counterfactuals \n",
      " [[57.0 '1.0' '4.0' 110.0 335.0 '0.0' '0.0' 143.0 '1.0' 3.0 '2.0' '1.0'\n",
      "  '7.0']\n",
      " [64.0 '0.0' '4.0' 130.0 303.0 '0.0' '0.0' 122.0 '0.0' 2.0 '2.0' '2.0'\n",
      "  '3.0']\n",
      " [58.0 '1.0' '4.0' 114.0 318.0 '0.0' '1.0' 140.0 '0.0' 4.4 '3.0' '3.0'\n",
      "  '6.0']\n",
      " [43.0 '0.0' '4.0' 132.0 341.0 '1.0' '2.0' 136.0 '1.0' 3.0 '2.0' '0.0'\n",
      "  '7.0']]\n",
      "DEBUG:xai-privacy:Sample 7: Counterfactuals \n",
      " [[54.0 '1.0' '4.0' 150.0 365.0 '0.0' '1.0' 134.0 '0.0' 1.0 '1.0' '4.0'\n",
      "  '8.0']\n",
      " [52.0 '1.0' '4.0' 112.0 342.0 '0.0' '1.0' 96.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [49.0 '1.0' '4.0' 130.0 341.0 '0.0' '0.0' 120.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [65.0 '0.0' '3.0' 140.0 417.0 '1.0' '2.0' 157.0 '0.0' 0.8 '1.0' '1.0'\n",
      "  '3.0']]\n",
      "DEBUG:xai-privacy:Sample 8: Counterfactuals \n",
      " [[67.0 '0.0' '3.0' 115.0 564.0 '0.0' '2.0' 160.0 '0.0' 1.6 '2.0' '0.0'\n",
      "  '7.0']\n",
      " [32.0 '1.0' '4.0' 118.0 529.0 '0.0' '0.0' 130.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [53.0 '0.0' '2.0' 113.0 468.0 '2.0' '0.0' 127.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [54.0 '1.0' '4.0' 130.0 603.0 '1.0' '0.0' 125.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 9: Counterfactuals \n",
      " [[52.0 '1.0' '4.0' 140.0 404.0 '0.0' '0.0' 124.0 '1.0' 2.0 '2.0' '4.0'\n",
      "  '8.0']\n",
      " [40.0 '0.0' '4.0' 150.0 392.0 '0.0' '0.0' 130.0 '0.0' 2.0 '2.0' '4.0'\n",
      "  '6.0']\n",
      " [58.0 '0.0' '2.0' 180.0 393.0 '0.0' '0.0' 110.0 '1.0' 1.0 '2.0' '4.0'\n",
      "  '7.0']\n",
      " [63.0 '0.0' '4.0' 150.0 407.0 '0.0' '2.0' 154.0 '0.0' 4.0 '2.0' '3.0'\n",
      "  '7.0']]\n",
      "DEBUG:xai-privacy:Sample 10: Counterfactuals \n",
      " [[55.0 '0.0' '2.0' 130.0 394.0 '0.0' '2.0' 150.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']\n",
      " [62.0 '0.0' '4.0' 140.0 394.0 '0.0' '2.0' 157.0 '0.0' 1.2 '2.0' '0.0'\n",
      "  '3.0']\n",
      " [55.0 '0.0' '2.0' 132.0 342.0 '0.0' '0.0' 166.0 '0.0' 1.2 '1.0' '0.0'\n",
      "  '3.0']\n",
      " [54.0 '1.0' '4.0' 150.0 365.0 '0.0' '1.0' 134.0 '0.0' 1.0 '1.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Sample 11: Counterfactuals \n",
      " [[48.0 '0.0' '4.0' 108.0 163.0 '0.0' '0.0' 175.0 '0.0' 2.0 '1.0' '4.0'\n",
      "  '8.0']\n",
      " [39.0 '0.0' '3.0' 94.0 199.0 '0.0' '0.0' 179.0 '0.0' 0.0 '1.0' '0.0'\n",
      "  '3.0']\n",
      " [41.0 '0.0' '2.0' 105.0 198.0 '0.0' '0.0' 168.0 '0.0' 0.0 '1.0' '1.0'\n",
      "  '3.0']\n",
      " [32.0 '0.0' '2.0' 105.0 198.0 '0.0' '0.0' 165.0 '0.0' 0.0 '4.0' '4.0'\n",
      "  '8.0']]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 32.   0.   2. 105. 198.   0.   0. 165.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [6]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 32.   1.   4. 118. 529.   0.   0. 130.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [10]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 34.    1.    4.  115.    0.    2.    3.  154.    0.    0.2   1.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [19]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 36.   1.   4. 110.   0.   2.   0. 125.   1.   1.   2.   4.   6.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [34]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 38.   0.   4. 110.   0.   0.   0. 156.   0.   0.   2.   4.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [48]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 38.    1.    3.  100.    0.    2.    0.  179.    0.   -1.1   1.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [51]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 38.    1.    4.   92.  117.    0.    0.  134.    1.    2.5   2.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [55]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 39.   0.   3.  94. 199.   0.   0. 179.   0.   0.   1.   0.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [60]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 40.   0.   4. 150. 392.   0.   0. 130.   0.   2.   2.   4.   6.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [73]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 40.   1.   4. 120. 466.   2.   0. 152.   1.   1.   2.   4.   6.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [82]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 40.   1.   4. 125.   0.   1.   0. 165.   0.   0.   4.   4.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [83]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 41.   0.   2. 105. 198.   0.   0. 168.   0.   0.   1.   1.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [85]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 43.   0.   4. 132. 341.   1.   2. 136.   1.   3.   2.   0.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [134]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 48.   0.   4. 108. 163.   0.   0. 175.   0.   2.   1.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [229]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 48.   1.   4. 160. 268.   0.   0. 103.   1.   1.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [249]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 48.   1.   4. 160. 355.   0.   0.  99.   1.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [251]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 49.    1.    3.  118.  149.    0.    2.  126.    0.    0.8   1.    3.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [261]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 49.   1.   4. 130. 341.   0.   0. 120.   1.   1.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [267]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 51.    0.    4.  120.    0.    2.    0.  127.    1.    1.5   1.    4.\n",
      "   8. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [302]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 52.   1.   2. 140. 100.   0.   0. 138.   1.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [334]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 52.   1.   4. 112. 342.   0.   1.  96.   1.   1.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [343]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 52.   1.   4. 140. 404.   0.   0. 124.   1.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [353]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 53.   0.   2. 113. 468.   2.   0. 127.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [357]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 54.   1.   4. 130. 603.   1.   0. 125.   1.   1.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [427]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 54.   1.   4. 150. 365.   0.   1. 134.   0.   1.   1.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [431]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 55.   0.   2. 130. 394.   0.   2. 150.   0.   0.   4.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [436]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 55.    0.    2.  132.  342.    0.    0.  166.    0.    1.2   1.    0.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [437]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 56.   0.   4. 200. 288.   1.   2. 133.   1.   4.   3.   2.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [474]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 56.   1.   4. 170. 388.   0.   1. 122.   1.   2.   2.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [503]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 57.   1.   4. 110. 335.   0.   0. 143.   1.   3.   2.   1.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [523]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 57.    1.    4.  130.  131.    0.    0.  115.    1.    1.2   2.    1.\n",
      "   7. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [526]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 57.    1.    4.  150.  276.    0.    2.  112.    1.    0.6   2.    1.\n",
      "   6. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [536]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 57.   1.   4. 165. 289.   1.   2. 124.   0.   1.   2.   3.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [540]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 58.   0.   2. 180. 393.   0.   0. 110.   1.   1.   2.   4.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [543]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 58.    1.    4.  114.  318.    0.    1.  140.    0.    4.4   3.    3.\n",
      "   6. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [565]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 58.   1.   4. 132. 458.   1.   0.  69.   0.   1.   3.   4.   8.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [574]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 62.    0.    4.  140.  394.    0.    2.  157.    0.    1.2   2.    0.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [674]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 63.   0.   4. 150. 407.   0.   2. 154.   0.   4.   2.   3.   7.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [700]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 64.   0.   4. 130. 303.   0.   0. 122.   0.   2.   2.   2.   3.]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [724]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 65.    0.    3.  140.  417.    1.    2.  157.    0.    0.8   1.    1.\n",
      "   3. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [742]\n",
      "DEBUG:xai-privacy:Extracted sample: [ 67.    0.    3.  115.  564.    0.    2.  160.    0.    1.6   2.    0.\n",
      "   7. ]\n",
      "DEBUG:xai-privacy:Appears in training data at indices [770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 9.74s (training model: 0.05s, training explainer: 0.05s, experiment: 9.64s)\n",
      "Number of extracted samples: 41\n",
      "Number of accurate extracted samples: 41\n",
      "Precision: 1.0, recall: 3.4166666666666665\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "logging.root.setLevel(logging.ERROR)\n",
    "\n",
    "EXP = CounterfactualTDE(data_heart, numeric_features_heart, outcome_name_heart, random_state=0)\n",
    "EXP.training_data_extraction_experiment(num_queries=12, model=es.RandomForestClassifier(random_state=0), model_access=False)\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e3f0e",
   "metadata": {},
   "source": [
    "The proof of concept should show that each extracted sample is an actual training sample (precision of 100%). Recall is above 100% because this method can extract multiple samples per query (multiple counterfactuals are returned). Recall will reach a reasonable value if the experiment is executed for the full training data. In this case, the attack cannot return more samples than the number of queries because the attack is limited by the number of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff16a3c",
   "metadata": {},
   "source": [
    "Now we begin executing the actual experiment. We begin by defining the table that will hold the results for all our different experiment variations. Then we execute all variations of the experiment for this dataset. We vary the model between a decision tree, a random forest and a neural network. Each model uses the default configuration of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10674b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.846445Z",
     "iopub.status.busy": "2022-10-29T17:40:58.845536Z",
     "iopub.status.idle": "2022-10-29T17:40:58.868857Z",
     "shell.execute_reply": "2022-10-29T17:40:58.860831Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c541b0b-7348-4aa0-95c8-4c9fafe3f3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.886860Z",
     "iopub.status.busy": "2022-10-29T17:40:58.884781Z",
     "iopub.status.idle": "2022-10-29T17:40:58.905823Z",
     "shell.execute_reply": "2022-10-29T17:40:58.902303Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dicts = [data_heart_dict, data_heart_num_dict, data_heart_cat_dict, data_census_dict, data_census_num_dict, data_census_cat_dict]\n",
    "\n",
    "dt_dict = {'name': 'decision tree', 'model': DecisionTreeClassifier}\n",
    "rf_dict = {'name': 'random forest', 'model': es.RandomForestClassifier}\n",
    "nn_dict = {'name': 'neural network', 'model': MLPClassifier}\n",
    "\n",
    "model_dicts = [dt_dict, rf_dict, nn_dict]\n",
    "\n",
    "# We set the number of extractions to the length of the dataset\n",
    "num_queries_dict = { 'heart': len(data_heart), 'heart numeric': len(data_heart_num), 'heart categorical': len(data_heart_cat), 'census': len(data_census), 'census numeric': len(data_census_num), 'census categorical': len(data_census_cat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f88514-2273-4bba-b3bd-d2558903dd8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.926076Z",
     "iopub.status.busy": "2022-10-29T17:40:58.922427Z",
     "iopub.status.idle": "2022-10-29T17:40:58.939842Z",
     "shell.execute_reply": "2022-10-29T17:40:58.936483Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove pandas warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26f0ba-1b5c-456e-9c5b-eff254817877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T17:40:58.957826Z",
     "iopub.status.busy": "2022-10-29T17:40:58.956274Z",
     "iopub.status.idle": "2022-10-29T20:54:34.073601Z",
     "shell.execute_reply": "2022-10-29T20:54:34.068627Z"
    },
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: heart, model: decision tree (repetition 0)\n",
      "Total time: 72.08s (training model: 0.02s, training explainer: 0.04s, experiment: 72.03s)\n",
      "Number of extracted samples: 529\n",
      "Number of accurate extracted samples: 529\n",
      "Precision: 1.0, recall: 0.6404358353510896\n",
      "dataset: heart, model: decision tree (repetition 1)\n",
      "Total time: 70.20s (training model: 0.01s, training explainer: 0.03s, experiment: 70.16s)\n",
      "Number of extracted samples: 536\n",
      "Number of accurate extracted samples: 536\n",
      "Precision: 1.0, recall: 0.648910411622276\n",
      "dataset: heart, model: decision tree (repetition 2)\n",
      "Total time: 65.65s (training model: 0.02s, training explainer: 0.03s, experiment: 65.60s)\n",
      "Number of extracted samples: 506\n",
      "Number of accurate extracted samples: 506\n",
      "Precision: 1.0, recall: 0.612590799031477\n",
      "dataset: heart, model: decision tree (repetition 3)\n",
      "Total time: 64.55s (training model: 0.02s, training explainer: 0.02s, experiment: 64.51s)\n",
      "Number of extracted samples: 558\n",
      "Number of accurate extracted samples: 558\n",
      "Precision: 1.0, recall: 0.6755447941888619\n",
      "dataset: heart, model: decision tree (repetition 4)\n",
      "Total time: 62.09s (training model: 0.02s, training explainer: 0.02s, experiment: 62.06s)\n",
      "Number of extracted samples: 540\n",
      "Number of accurate extracted samples: 540\n",
      "Precision: 1.0, recall: 0.6537530266343826\n",
      "dataset: heart, model: decision tree (repetition 5)\n",
      "Total time: 67.51s (training model: 0.01s, training explainer: 0.02s, experiment: 67.48s)\n",
      "Number of extracted samples: 536\n",
      "Number of accurate extracted samples: 536\n",
      "Precision: 1.0, recall: 0.648910411622276\n",
      "dataset: heart, model: decision tree (repetition 6)\n",
      "Total time: 69.21s (training model: 0.00s, training explainer: 0.02s, experiment: 69.20s)\n",
      "Number of extracted samples: 522\n",
      "Number of accurate extracted samples: 522\n",
      "Precision: 1.0, recall: 0.6319612590799032\n",
      "dataset: heart, model: decision tree (repetition 7)\n",
      "Total time: 64.48s (training model: 0.01s, training explainer: 0.02s, experiment: 64.45s)\n",
      "Number of extracted samples: 530\n",
      "Number of accurate extracted samples: 530\n",
      "Precision: 1.0, recall: 0.6416464891041163\n",
      "dataset: heart, model: decision tree (repetition 8)\n",
      "Total time: 65.54s (training model: 0.02s, training explainer: 0.02s, experiment: 65.51s)\n",
      "Number of extracted samples: 514\n",
      "Number of accurate extracted samples: 514\n",
      "Precision: 1.0, recall: 0.6222760290556901\n",
      "dataset: heart, model: decision tree (repetition 9)\n",
      "Total time: 69.99s (training model: 0.02s, training explainer: 0.02s, experiment: 69.96s)\n",
      "Number of extracted samples: 549\n",
      "Number of accurate extracted samples: 549\n",
      "Precision: 1.0, recall: 0.6646489104116223\n",
      "dataset: heart, model: random forest (repetition 0)\n",
      "Total time: 66.59s (training model: 0.05s, training explainer: 0.02s, experiment: 66.52s)\n",
      "Number of extracted samples: 498\n",
      "Number of accurate extracted samples: 498\n",
      "Precision: 1.0, recall: 0.6029055690072639\n",
      "dataset: heart, model: random forest (repetition 1)\n",
      "Total time: 67.00s (training model: 0.05s, training explainer: 0.02s, experiment: 66.93s)\n",
      "Number of extracted samples: 463\n",
      "Number of accurate extracted samples: 463\n",
      "Precision: 1.0, recall: 0.5605326876513317\n",
      "dataset: heart, model: random forest (repetition 2)\n",
      "Total time: 70.23s (training model: 0.05s, training explainer: 0.02s, experiment: 70.17s)\n",
      "Number of extracted samples: 457\n",
      "Number of accurate extracted samples: 457\n",
      "Precision: 1.0, recall: 0.5532687651331719\n",
      "dataset: heart, model: random forest (repetition 3)\n",
      "Total time: 69.76s (training model: 0.05s, training explainer: 0.02s, experiment: 69.69s)\n",
      "Number of extracted samples: 457\n",
      "Number of accurate extracted samples: 457\n",
      "Precision: 1.0, recall: 0.5532687651331719\n",
      "dataset: heart, model: random forest (repetition 4)\n",
      "Total time: 72.83s (training model: 0.03s, training explainer: 0.02s, experiment: 72.78s)\n",
      "Number of extracted samples: 453\n",
      "Number of accurate extracted samples: 453\n",
      "Precision: 1.0, recall: 0.5484261501210653\n",
      "dataset: heart, model: random forest (repetition 5)\n",
      "Total time: 72.27s (training model: 0.02s, training explainer: 0.01s, experiment: 72.23s)\n",
      "Number of extracted samples: 479\n",
      "Number of accurate extracted samples: 479\n",
      "Precision: 1.0, recall: 0.5799031476997578\n",
      "dataset: heart, model: random forest (repetition 6)\n",
      "Total time: 67.58s (training model: 0.05s, training explainer: 0.02s, experiment: 67.52s)\n",
      "Number of extracted samples: 497\n",
      "Number of accurate extracted samples: 497\n",
      "Precision: 1.0, recall: 0.6016949152542372\n",
      "dataset: heart, model: random forest (repetition 7)\n",
      "Total time: 70.31s (training model: 0.05s, training explainer: 0.02s, experiment: 70.24s)\n",
      "Number of extracted samples: 496\n",
      "Number of accurate extracted samples: 496\n",
      "Precision: 1.0, recall: 0.6004842615012107\n",
      "dataset: heart, model: random forest (repetition 8)\n",
      "Total time: 67.69s (training model: 0.03s, training explainer: 0.02s, experiment: 67.65s)\n",
      "Number of extracted samples: 496\n",
      "Number of accurate extracted samples: 496\n",
      "Precision: 1.0, recall: 0.6004842615012107\n",
      "dataset: heart, model: random forest (repetition 9)\n",
      "Total time: 66.03s (training model: 0.05s, training explainer: 0.02s, experiment: 65.96s)\n",
      "Number of extracted samples: 490\n",
      "Number of accurate extracted samples: 490\n",
      "Precision: 1.0, recall: 0.5932203389830508\n",
      "dataset: heart, model: neural network (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 69.01s (training model: 1.95s, training explainer: 0.01s, experiment: 67.05s)\n",
      "Number of extracted samples: 466\n",
      "Number of accurate extracted samples: 466\n",
      "Precision: 1.0, recall: 0.5641646489104116\n",
      "dataset: heart, model: neural network (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 67.93s (training model: 1.90s, training explainer: 0.01s, experiment: 66.02s)\n",
      "Number of extracted samples: 419\n",
      "Number of accurate extracted samples: 419\n",
      "Precision: 1.0, recall: 0.5072639225181598\n",
      "dataset: heart, model: neural network (repetition 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 66.52s (training model: 1.92s, training explainer: 0.01s, experiment: 64.60s)\n",
      "Number of extracted samples: 435\n",
      "Number of accurate extracted samples: 435\n",
      "Precision: 1.0, recall: 0.5266343825665859\n",
      "dataset: heart, model: neural network (repetition 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 69.43s (training model: 1.88s, training explainer: 0.00s, experiment: 67.54s)\n",
      "Number of extracted samples: 435\n",
      "Number of accurate extracted samples: 435\n",
      "Precision: 1.0, recall: 0.5266343825665859\n",
      "dataset: heart, model: neural network (repetition 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 67.23s (training model: 1.94s, training explainer: 0.01s, experiment: 65.28s)\n",
      "Number of extracted samples: 464\n",
      "Number of accurate extracted samples: 464\n",
      "Precision: 1.0, recall: 0.5617433414043583\n",
      "dataset: heart, model: neural network (repetition 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 65.40s (training model: 1.96s, training explainer: 0.02s, experiment: 63.42s)\n",
      "Number of extracted samples: 438\n",
      "Number of accurate extracted samples: 438\n",
      "Precision: 1.0, recall: 0.5302663438256658\n",
      "dataset: heart, model: neural network (repetition 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 67.45s (training model: 1.91s, training explainer: 0.01s, experiment: 65.52s)\n",
      "Number of extracted samples: 468\n",
      "Number of accurate extracted samples: 468\n",
      "Precision: 1.0, recall: 0.5665859564164649\n",
      "dataset: heart, model: neural network (repetition 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 69.05s (training model: 1.93s, training explainer: 0.00s, experiment: 67.12s)\n",
      "Number of extracted samples: 461\n",
      "Number of accurate extracted samples: 461\n",
      "Precision: 1.0, recall: 0.5581113801452785\n",
      "dataset: heart, model: neural network (repetition 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 68.83s (training model: 1.92s, training explainer: 0.01s, experiment: 66.91s)\n",
      "Number of extracted samples: 486\n",
      "Number of accurate extracted samples: 486\n",
      "Precision: 1.0, recall: 0.5883777239709443\n",
      "dataset: heart, model: neural network (repetition 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 67.25s (training model: 1.86s, training explainer: 0.01s, experiment: 65.37s)\n",
      "Number of extracted samples: 454\n",
      "Number of accurate extracted samples: 454\n",
      "Precision: 1.0, recall: 0.549636803874092\n",
      "dataset: heart numeric, model: decision tree (repetition 0)\n",
      "Total time: 32.25s (training model: 0.02s, training explainer: 0.00s, experiment: 32.24s)\n",
      "Number of extracted samples: 547\n",
      "Number of accurate extracted samples: 547\n",
      "Precision: 1.0, recall: 0.6638349514563107\n",
      "dataset: heart numeric, model: decision tree (repetition 1)\n",
      "Total time: 30.96s (training model: 0.00s, training explainer: 0.00s, experiment: 30.96s)\n",
      "Number of extracted samples: 534\n",
      "Number of accurate extracted samples: 534\n",
      "Precision: 1.0, recall: 0.6480582524271845\n",
      "dataset: heart numeric, model: decision tree (repetition 2)\n",
      "Total time: 28.90s (training model: 0.00s, training explainer: 0.00s, experiment: 28.90s)\n",
      "Number of extracted samples: 550\n",
      "Number of accurate extracted samples: 550\n",
      "Precision: 1.0, recall: 0.6674757281553398\n",
      "dataset: heart numeric, model: decision tree (repetition 3)\n",
      "Total time: 30.04s (training model: 0.00s, training explainer: 0.00s, experiment: 30.04s)\n",
      "Number of extracted samples: 518\n",
      "Number of accurate extracted samples: 518\n",
      "Precision: 1.0, recall: 0.6286407766990292\n",
      "dataset: heart numeric, model: decision tree (repetition 4)\n",
      "Total time: 29.61s (training model: 0.02s, training explainer: 0.00s, experiment: 29.60s)\n",
      "Number of extracted samples: 530\n",
      "Number of accurate extracted samples: 530\n",
      "Precision: 1.0, recall: 0.6432038834951457\n",
      "dataset: heart numeric, model: decision tree (repetition 5)\n",
      "Total time: 30.75s (training model: 0.00s, training explainer: 0.00s, experiment: 30.75s)\n",
      "Number of extracted samples: 515\n",
      "Number of accurate extracted samples: 515\n",
      "Precision: 1.0, recall: 0.625\n",
      "dataset: heart numeric, model: decision tree (repetition 6)\n",
      "Total time: 30.08s (training model: 0.02s, training explainer: 0.00s, experiment: 30.06s)\n",
      "Number of extracted samples: 529\n",
      "Number of accurate extracted samples: 529\n",
      "Precision: 1.0, recall: 0.6419902912621359\n",
      "dataset: heart numeric, model: decision tree (repetition 7)\n",
      "Total time: 30.14s (training model: 0.00s, training explainer: 0.00s, experiment: 30.14s)\n",
      "Number of extracted samples: 538\n",
      "Number of accurate extracted samples: 538\n",
      "Precision: 1.0, recall: 0.6529126213592233\n",
      "dataset: heart numeric, model: decision tree (repetition 8)\n",
      "Total time: 31.02s (training model: 0.00s, training explainer: 0.00s, experiment: 31.02s)\n",
      "Number of extracted samples: 551\n",
      "Number of accurate extracted samples: 551\n",
      "Precision: 1.0, recall: 0.6686893203883495\n",
      "dataset: heart numeric, model: decision tree (repetition 9)\n",
      "Total time: 29.94s (training model: 0.00s, training explainer: 0.02s, experiment: 29.92s)\n",
      "Number of extracted samples: 539\n",
      "Number of accurate extracted samples: 539\n",
      "Precision: 1.0, recall: 0.654126213592233\n",
      "dataset: heart numeric, model: random forest (repetition 0)\n",
      "Total time: 32.03s (training model: 0.05s, training explainer: 0.02s, experiment: 31.96s)\n",
      "Number of extracted samples: 500\n",
      "Number of accurate extracted samples: 500\n",
      "Precision: 1.0, recall: 0.6067961165048543\n",
      "dataset: heart numeric, model: random forest (repetition 1)\n",
      "Total time: 33.60s (training model: 0.05s, training explainer: 0.00s, experiment: 33.55s)\n",
      "Number of extracted samples: 481\n",
      "Number of accurate extracted samples: 481\n",
      "Precision: 1.0, recall: 0.5837378640776699\n",
      "dataset: heart numeric, model: random forest (repetition 2)\n",
      "Total time: 34.37s (training model: 0.05s, training explainer: 0.00s, experiment: 34.32s)\n",
      "Number of extracted samples: 508\n",
      "Number of accurate extracted samples: 508\n",
      "Precision: 1.0, recall: 0.616504854368932\n",
      "dataset: heart numeric, model: random forest (repetition 3)\n",
      "Total time: 32.92s (training model: 0.03s, training explainer: 0.00s, experiment: 32.89s)\n",
      "Number of extracted samples: 488\n",
      "Number of accurate extracted samples: 488\n",
      "Precision: 1.0, recall: 0.5922330097087378\n",
      "dataset: heart numeric, model: random forest (repetition 4)\n",
      "Total time: 32.39s (training model: 0.03s, training explainer: 0.00s, experiment: 32.36s)\n",
      "Number of extracted samples: 512\n",
      "Number of accurate extracted samples: 512\n",
      "Precision: 1.0, recall: 0.6213592233009708\n",
      "dataset: heart numeric, model: random forest (repetition 5)\n",
      "Total time: 33.35s (training model: 0.03s, training explainer: 0.00s, experiment: 33.32s)\n",
      "Number of extracted samples: 495\n",
      "Number of accurate extracted samples: 495\n",
      "Precision: 1.0, recall: 0.6007281553398058\n",
      "dataset: heart numeric, model: random forest (repetition 6)\n",
      "Total time: 33.71s (training model: 0.03s, training explainer: 0.02s, experiment: 33.66s)\n",
      "Number of extracted samples: 496\n",
      "Number of accurate extracted samples: 496\n",
      "Precision: 1.0, recall: 0.6019417475728155\n",
      "dataset: heart numeric, model: random forest (repetition 7)\n",
      "Total time: 34.17s (training model: 0.03s, training explainer: 0.00s, experiment: 34.14s)\n",
      "Number of extracted samples: 497\n",
      "Number of accurate extracted samples: 497\n",
      "Precision: 1.0, recall: 0.6031553398058253\n",
      "dataset: heart numeric, model: random forest (repetition 8)\n",
      "Total time: 33.68s (training model: 0.05s, training explainer: 0.01s, experiment: 33.62s)\n",
      "Number of extracted samples: 485\n",
      "Number of accurate extracted samples: 485\n",
      "Precision: 1.0, recall: 0.5885922330097088\n",
      "dataset: heart numeric, model: random forest (repetition 9)\n",
      "Total time: 32.96s (training model: 0.03s, training explainer: 0.02s, experiment: 32.91s)\n",
      "Number of extracted samples: 494\n",
      "Number of accurate extracted samples: 494\n",
      "Precision: 1.0, recall: 0.5995145631067961\n",
      "dataset: heart numeric, model: neural network (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 31.53s (training model: 1.09s, training explainer: 0.00s, experiment: 30.45s)\n",
      "Number of extracted samples: 496\n",
      "Number of accurate extracted samples: 496\n",
      "Precision: 1.0, recall: 0.6019417475728155\n",
      "dataset: heart numeric, model: neural network (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 32.16s (training model: 1.17s, training explainer: 0.00s, experiment: 31.00s)\n",
      "Number of extracted samples: 493\n",
      "Number of accurate extracted samples: 493\n",
      "Precision: 1.0, recall: 0.5983009708737864\n",
      "dataset: heart numeric, model: neural network (repetition 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 32.26s (training model: 1.09s, training explainer: 0.00s, experiment: 31.17s)\n",
      "Number of extracted samples: 501\n",
      "Number of accurate extracted samples: 501\n",
      "Precision: 1.0, recall: 0.6080097087378641\n",
      "dataset: heart numeric, model: neural network (repetition 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 30.91s (training model: 1.07s, training explainer: 0.02s, experiment: 29.82s)\n",
      "Number of extracted samples: 473\n",
      "Number of accurate extracted samples: 473\n",
      "Precision: 1.0, recall: 0.5740291262135923\n",
      "dataset: heart numeric, model: neural network (repetition 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 32.10s (training model: 1.11s, training explainer: 0.00s, experiment: 30.98s)\n",
      "Number of extracted samples: 518\n",
      "Number of accurate extracted samples: 518\n",
      "Precision: 1.0, recall: 0.6286407766990292\n",
      "dataset: heart numeric, model: neural network (repetition 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 30.16s (training model: 1.08s, training explainer: 0.00s, experiment: 29.08s)\n",
      "Number of extracted samples: 481\n",
      "Number of accurate extracted samples: 481\n",
      "Precision: 1.0, recall: 0.5837378640776699\n",
      "dataset: heart numeric, model: neural network (repetition 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 32.05s (training model: 1.08s, training explainer: 0.00s, experiment: 30.97s)\n",
      "Number of extracted samples: 489\n",
      "Number of accurate extracted samples: 489\n",
      "Precision: 1.0, recall: 0.5934466019417476\n",
      "dataset: heart numeric, model: neural network (repetition 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 30.50s (training model: 1.08s, training explainer: 0.00s, experiment: 29.41s)\n",
      "Number of extracted samples: 469\n",
      "Number of accurate extracted samples: 469\n",
      "Precision: 1.0, recall: 0.5691747572815534\n",
      "dataset: heart numeric, model: neural network (repetition 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 29.00s (training model: 1.11s, training explainer: 0.00s, experiment: 27.89s)\n",
      "Number of extracted samples: 493\n",
      "Number of accurate extracted samples: 493\n",
      "Precision: 1.0, recall: 0.5983009708737864\n",
      "dataset: heart numeric, model: neural network (repetition 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 30.16s (training model: 1.10s, training explainer: 0.00s, experiment: 29.06s)\n",
      "Number of extracted samples: 479\n",
      "Number of accurate extracted samples: 479\n",
      "Precision: 1.0, recall: 0.5813106796116505\n",
      "dataset: heart categorical, model: decision tree (repetition 0)\n",
      "Total time: 22.14s (training model: 0.03s, training explainer: 0.02s, experiment: 22.09s)\n",
      "Number of extracted samples: 702\n",
      "Number of accurate extracted samples: 702\n",
      "Precision: 1.0, recall: 0.8560975609756097\n",
      "dataset: heart categorical, model: decision tree (repetition 1)\n",
      "Total time: 22.97s (training model: 0.02s, training explainer: 0.02s, experiment: 22.94s)\n",
      "Number of extracted samples: 723\n",
      "Number of accurate extracted samples: 723\n",
      "Precision: 1.0, recall: 0.8817073170731707\n",
      "dataset: heart categorical, model: decision tree (repetition 2)\n",
      "Total time: 22.20s (training model: 0.02s, training explainer: 0.02s, experiment: 22.16s)\n",
      "Number of extracted samples: 724\n",
      "Number of accurate extracted samples: 724\n",
      "Precision: 1.0, recall: 0.8829268292682927\n",
      "dataset: heart categorical, model: decision tree (repetition 3)\n",
      "Total time: 22.22s (training model: 0.02s, training explainer: 0.02s, experiment: 22.19s)\n",
      "Number of extracted samples: 702\n",
      "Number of accurate extracted samples: 702\n",
      "Precision: 1.0, recall: 0.8560975609756097\n",
      "dataset: heart categorical, model: decision tree (repetition 4)\n",
      "Total time: 22.13s (training model: 0.02s, training explainer: 0.01s, experiment: 22.10s)\n",
      "Number of extracted samples: 706\n",
      "Number of accurate extracted samples: 706\n",
      "Precision: 1.0, recall: 0.8609756097560975\n",
      "dataset: heart categorical, model: decision tree (repetition 5)\n",
      "Total time: 22.06s (training model: 0.02s, training explainer: 0.02s, experiment: 22.02s)\n",
      "Number of extracted samples: 710\n",
      "Number of accurate extracted samples: 710\n",
      "Precision: 1.0, recall: 0.8658536585365854\n",
      "dataset: heart categorical, model: decision tree (repetition 6)\n",
      "Total time: 22.25s (training model: 0.00s, training explainer: 0.01s, experiment: 22.23s)\n",
      "Number of extracted samples: 697\n",
      "Number of accurate extracted samples: 697\n",
      "Precision: 1.0, recall: 0.85\n",
      "dataset: heart categorical, model: decision tree (repetition 7)\n",
      "Total time: 22.19s (training model: 0.02s, training explainer: 0.02s, experiment: 22.16s)\n",
      "Number of extracted samples: 724\n",
      "Number of accurate extracted samples: 724\n",
      "Precision: 1.0, recall: 0.8829268292682927\n",
      "dataset: heart categorical, model: decision tree (repetition 8)\n",
      "Total time: 22.12s (training model: 0.02s, training explainer: 0.02s, experiment: 22.09s)\n",
      "Number of extracted samples: 728\n",
      "Number of accurate extracted samples: 728\n",
      "Precision: 1.0, recall: 0.8878048780487805\n",
      "dataset: heart categorical, model: decision tree (repetition 9)\n",
      "Total time: 22.23s (training model: 0.02s, training explainer: 0.02s, experiment: 22.20s)\n",
      "Number of extracted samples: 721\n",
      "Number of accurate extracted samples: 721\n",
      "Precision: 1.0, recall: 0.8792682926829268\n",
      "dataset: heart categorical, model: random forest (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.07s (training model: 0.24s, training explainer: 0.03s, experiment: 33.80s)\n",
      "Number of extracted samples: 644\n",
      "Number of accurate extracted samples: 644\n",
      "Precision: 1.0, recall: 0.7853658536585366\n",
      "dataset: heart categorical, model: random forest (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.02s (training model: 0.19s, training explainer: 0.03s, experiment: 33.80s)\n",
      "Number of extracted samples: 647\n",
      "Number of accurate extracted samples: 647\n",
      "Precision: 1.0, recall: 0.7890243902439025\n",
      "dataset: heart categorical, model: random forest (repetition 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 33.96s (training model: 0.19s, training explainer: 0.04s, experiment: 33.74s)\n",
      "Number of extracted samples: 650\n",
      "Number of accurate extracted samples: 650\n",
      "Precision: 1.0, recall: 0.7926829268292683\n",
      "dataset: heart categorical, model: random forest (repetition 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.26s (training model: 0.20s, training explainer: 0.02s, experiment: 34.04s)\n",
      "Number of extracted samples: 659\n",
      "Number of accurate extracted samples: 659\n",
      "Precision: 1.0, recall: 0.8036585365853659\n",
      "dataset: heart categorical, model: random forest (repetition 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.06s (training model: 0.23s, training explainer: 0.02s, experiment: 33.80s)\n",
      "Number of extracted samples: 659\n",
      "Number of accurate extracted samples: 659\n",
      "Precision: 1.0, recall: 0.8036585365853659\n",
      "dataset: heart categorical, model: random forest (repetition 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 33.96s (training model: 0.20s, training explainer: 0.03s, experiment: 33.72s)\n",
      "Number of extracted samples: 678\n",
      "Number of accurate extracted samples: 678\n",
      "Precision: 1.0, recall: 0.8268292682926829\n",
      "dataset: heart categorical, model: random forest (repetition 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.00s (training model: 0.19s, training explainer: 0.03s, experiment: 33.78s)\n",
      "Number of extracted samples: 653\n",
      "Number of accurate extracted samples: 653\n",
      "Precision: 1.0, recall: 0.7963414634146342\n",
      "dataset: heart categorical, model: random forest (repetition 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.24s (training model: 0.21s, training explainer: 0.01s, experiment: 34.02s)\n",
      "Number of extracted samples: 647\n",
      "Number of accurate extracted samples: 647\n",
      "Precision: 1.0, recall: 0.7890243902439025\n",
      "dataset: heart categorical, model: random forest (repetition 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.07s (training model: 0.20s, training explainer: 0.03s, experiment: 33.84s)\n",
      "Number of extracted samples: 669\n",
      "Number of accurate extracted samples: 669\n",
      "Precision: 1.0, recall: 0.8158536585365853\n",
      "dataset: heart categorical, model: random forest (repetition 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 34.16s (training model: 0.22s, training explainer: 0.02s, experiment: 33.92s)\n",
      "Number of extracted samples: 657\n",
      "Number of accurate extracted samples: 657\n",
      "Precision: 1.0, recall: 0.801219512195122\n",
      "dataset: heart categorical, model: neural network (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.66s (training model: 1.56s, training explainer: 0.02s, experiment: 22.08s)\n",
      "Number of extracted samples: 647\n",
      "Number of accurate extracted samples: 647\n",
      "Precision: 1.0, recall: 0.7890243902439025\n",
      "dataset: heart categorical, model: neural network (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.64s (training model: 1.57s, training explainer: 0.02s, experiment: 22.05s)\n",
      "Number of extracted samples: 663\n",
      "Number of accurate extracted samples: 663\n",
      "Precision: 1.0, recall: 0.8085365853658537\n",
      "dataset: heart categorical, model: neural network (repetition 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.84s (training model: 1.60s, training explainer: 0.02s, experiment: 22.22s)\n",
      "Number of extracted samples: 647\n",
      "Number of accurate extracted samples: 647\n",
      "Precision: 1.0, recall: 0.7890243902439025\n",
      "dataset: heart categorical, model: neural network (repetition 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.72s (training model: 1.66s, training explainer: 0.02s, experiment: 22.05s)\n",
      "Number of extracted samples: 655\n",
      "Number of accurate extracted samples: 655\n",
      "Precision: 1.0, recall: 0.7987804878048781\n",
      "dataset: heart categorical, model: neural network (repetition 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.71s (training model: 1.60s, training explainer: 0.02s, experiment: 22.09s)\n",
      "Number of extracted samples: 636\n",
      "Number of accurate extracted samples: 636\n",
      "Precision: 1.0, recall: 0.775609756097561\n",
      "dataset: heart categorical, model: neural network (repetition 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 24.73s (training model: 1.60s, training explainer: 0.02s, experiment: 23.12s)\n",
      "Number of extracted samples: 637\n",
      "Number of accurate extracted samples: 637\n",
      "Precision: 1.0, recall: 0.776829268292683\n",
      "dataset: heart categorical, model: neural network (repetition 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.79s (training model: 1.66s, training explainer: 0.02s, experiment: 22.11s)\n",
      "Number of extracted samples: 622\n",
      "Number of accurate extracted samples: 622\n",
      "Precision: 1.0, recall: 0.7585365853658537\n",
      "dataset: heart categorical, model: neural network (repetition 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.79s (training model: 1.60s, training explainer: 0.02s, experiment: 22.17s)\n",
      "Number of extracted samples: 628\n",
      "Number of accurate extracted samples: 628\n",
      "Precision: 1.0, recall: 0.7658536585365854\n",
      "dataset: heart categorical, model: neural network (repetition 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.82s (training model: 1.83s, training explainer: 0.02s, experiment: 21.98s)\n",
      "Number of extracted samples: 662\n",
      "Number of accurate extracted samples: 662\n",
      "Precision: 1.0, recall: 0.8073170731707318\n",
      "dataset: heart categorical, model: neural network (repetition 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23.72s (training model: 1.61s, training explainer: 0.02s, experiment: 22.09s)\n",
      "Number of extracted samples: 648\n",
      "Number of accurate extracted samples: 648\n",
      "Precision: 1.0, recall: 0.7902439024390244\n",
      "dataset: census, model: decision tree (repetition 0)\n",
      "Total time: 1551.00s (training model: 0.93s, training explainer: 0.12s, experiment: 1549.95s)\n",
      "Number of extracted samples: 1928\n",
      "Number of accurate extracted samples: 1928\n",
      "Precision: 1.0, recall: 0.07326898229079577\n",
      "dataset: census, model: decision tree (repetition 1)\n",
      "Total time: 1550.99s (training model: 0.88s, training explainer: 0.12s, experiment: 1549.99s)\n",
      "Number of extracted samples: 2032\n",
      "Number of accurate extracted samples: 2032\n",
      "Precision: 1.0, recall: 0.07722125104507106\n",
      "dataset: census, model: decision tree (repetition 2)\n",
      "Total time: 1541.56s (training model: 0.95s, training explainer: 0.17s, experiment: 1540.43s)\n",
      "Number of extracted samples: 1926\n",
      "Number of accurate extracted samples: 1926\n",
      "Precision: 1.0, recall: 0.07319297712244432\n",
      "dataset: census, model: decision tree (repetition 3)\n",
      "Total time: 1553.65s (training model: 0.88s, training explainer: 0.12s, experiment: 1552.65s)\n",
      "Number of extracted samples: 2011\n",
      "Number of accurate extracted samples: 2011\n",
      "Precision: 1.0, recall: 0.07642319677738087\n",
      "dataset: census, model: decision tree (repetition 4)\n",
      "Total time: 1547.26s (training model: 0.87s, training explainer: 0.12s, experiment: 1546.26s)\n",
      "Number of extracted samples: 2002\n",
      "Number of accurate extracted samples: 2002\n",
      "Precision: 1.0, recall: 0.07608117351979934\n",
      "dataset: census, model: decision tree (repetition 5)\n",
      "Total time: 1540.36s (training model: 0.88s, training explainer: 0.11s, experiment: 1539.37s)\n",
      "Number of extracted samples: 1943\n",
      "Number of accurate extracted samples: 1943\n",
      "Precision: 1.0, recall: 0.07383902105343164\n",
      "dataset: census, model: decision tree (repetition 6)\n",
      "Total time: 1547.24s (training model: 0.89s, training explainer: 0.13s, experiment: 1546.22s)\n",
      "Number of extracted samples: 2040\n",
      "Number of accurate extracted samples: 2040\n",
      "Precision: 1.0, recall: 0.07752527171847685\n",
      "dataset: census, model: decision tree (repetition 7)\n",
      "Total time: 1554.29s (training model: 0.94s, training explainer: 0.11s, experiment: 1553.24s)\n",
      "Number of extracted samples: 1983\n",
      "Number of accurate extracted samples: 1983\n",
      "Precision: 1.0, recall: 0.0753591244204606\n",
      "dataset: census, model: decision tree (repetition 8)\n",
      "Total time: 1549.51s (training model: 0.89s, training explainer: 0.11s, experiment: 1548.51s)\n",
      "Number of extracted samples: 1945\n",
      "Number of accurate extracted samples: 1945\n",
      "Precision: 1.0, recall: 0.07391502622178309\n",
      "dataset: census, model: decision tree (repetition 9)\n",
      "Total time: 1542.86s (training model: 0.94s, training explainer: 0.13s, experiment: 1541.79s)\n",
      "Number of extracted samples: 1917\n",
      "Number of accurate extracted samples: 1917\n",
      "Precision: 1.0, recall: 0.07285095386486282\n",
      "dataset: census, model: random forest (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3583.59s (training model: 16.73s, training explainer: 0.12s, experiment: 3566.73s)\n",
      "Number of extracted samples: 1380\n",
      "Number of accurate extracted samples: 1380\n",
      "Precision: 1.0, recall: 0.05244356616249905\n",
      "dataset: census, model: random forest (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3586.34s (training model: 16.85s, training explainer: 0.16s, experiment: 3569.34s)\n",
      "Number of extracted samples: 1379\n",
      "Number of accurate extracted samples: 1379\n",
      "Precision: 1.0, recall: 0.05240556357832333\n",
      "dataset: census, model: random forest (repetition 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3614.29s (training model: 16.75s, training explainer: 0.13s, experiment: 3597.42s)\n",
      "Number of extracted samples: 1342\n",
      "Number of accurate extracted samples: 1342\n",
      "Precision: 1.0, recall: 0.05099946796382154\n",
      "dataset: census, model: random forest (repetition 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3591.81s (training model: 16.71s, training explainer: 0.12s, experiment: 3574.97s)\n",
      "Number of extracted samples: 1365\n",
      "Number of accurate extracted samples: 1365\n",
      "Precision: 1.0, recall: 0.051873527399863194\n",
      "dataset: census, model: random forest (repetition 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3624.12s (training model: 17.03s, training explainer: 0.36s, experiment: 3606.73s)\n",
      "Number of extracted samples: 1527\n",
      "Number of accurate extracted samples: 1527\n",
      "Precision: 1.0, recall: 0.05802994603633047\n",
      "dataset: census, model: random forest (repetition 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3600.06s (training model: 16.55s, training explainer: 0.13s, experiment: 3583.38s)\n",
      "Number of extracted samples: 1400\n",
      "Number of accurate extracted samples: 1400\n",
      "Precision: 1.0, recall: 0.05320361784601353\n",
      "dataset: census, model: random forest (repetition 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3661.98s (training model: 16.66s, training explainer: 0.12s, experiment: 3645.19s)\n",
      "Number of extracted samples: 1428\n",
      "Number of accurate extracted samples: 1428\n",
      "Precision: 1.0, recall: 0.0542676902029338\n",
      "dataset: census, model: random forest (repetition 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3606.43s (training model: 16.51s, training explainer: 0.12s, experiment: 3589.80s)\n",
      "Number of extracted samples: 1392\n",
      "Number of accurate extracted samples: 1392\n",
      "Precision: 1.0, recall: 0.05289959717260774\n",
      "dataset: census, model: random forest (repetition 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3588.89s (training model: 16.45s, training explainer: 0.13s, experiment: 3572.31s)\n",
      "Number of extracted samples: 1442\n",
      "Number of accurate extracted samples: 1442\n",
      "Precision: 1.0, recall: 0.05479972638139394\n",
      "dataset: census, model: random forest (repetition 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3582.40s (training model: 16.66s, training explainer: 0.12s, experiment: 3565.61s)\n",
      "Number of extracted samples: 1421\n",
      "Number of accurate extracted samples: 1421\n",
      "Precision: 1.0, recall: 0.054001672113703734\n",
      "dataset: census, model: neural network (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1932.58s (training model: 54.60s, training explainer: 0.13s, experiment: 1877.86s)\n",
      "Number of extracted samples: 1885\n",
      "Number of accurate extracted samples: 1885\n",
      "Precision: 1.0, recall: 0.07163487117123965\n",
      "dataset: census, model: neural network (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2063.71s (training model: 53.73s, training explainer: 0.13s, experiment: 2009.85s)\n",
      "Number of extracted samples: 1876\n",
      "Number of accurate extracted samples: 1876\n",
      "Precision: 1.0, recall: 0.07129284791365813\n",
      "dataset: census, model: neural network (repetition 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1931.95s (training model: 54.31s, training explainer: 0.12s, experiment: 1877.52s)\n",
      "Number of extracted samples: 1765\n",
      "Number of accurate extracted samples: 1765\n",
      "Precision: 1.0, recall: 0.06707456107015278\n",
      "dataset: census, model: neural network (repetition 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1912.46s (training model: 54.09s, training explainer: 0.13s, experiment: 1858.24s)\n",
      "Number of extracted samples: 1928\n",
      "Number of accurate extracted samples: 1928\n",
      "Precision: 1.0, recall: 0.07326898229079577\n",
      "dataset: census, model: neural network (repetition 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1957.18s (training model: 64.30s, training explainer: 0.17s, experiment: 1892.71s)\n",
      "Number of extracted samples: 1857\n",
      "Number of accurate extracted samples: 1857\n",
      "Precision: 1.0, recall: 0.07057079881431938\n",
      "dataset: census, model: neural network (repetition 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1862.12s (training model: 54.45s, training explainer: 0.12s, experiment: 1807.54s)\n",
      "Number of extracted samples: 2010\n",
      "Number of accurate extracted samples: 2010\n",
      "Precision: 1.0, recall: 0.07638519419320514\n",
      "dataset: census, model: neural network (repetition 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1905.53s (training model: 54.40s, training explainer: 0.13s, experiment: 1851.01s)\n",
      "Number of extracted samples: 1900\n",
      "Number of accurate extracted samples: 1900\n",
      "Precision: 1.0, recall: 0.0722049099338755\n",
      "dataset: census, model: neural network (repetition 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1936.91s (training model: 56.75s, training explainer: 0.12s, experiment: 1880.03s)\n",
      "Number of extracted samples: 1892\n",
      "Number of accurate extracted samples: 1892\n",
      "Precision: 1.0, recall: 0.07190088926046971\n",
      "dataset: census, model: neural network (repetition 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1951.41s (training model: 54.13s, training explainer: 0.11s, experiment: 1897.18s)\n",
      "Number of extracted samples: 1964\n",
      "Number of accurate extracted samples: 1964\n",
      "Precision: 1.0, recall: 0.07463707532112183\n",
      "dataset: census, model: neural network (repetition 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2007.82s (training model: 54.65s, training explainer: 0.13s, experiment: 1953.05s)\n",
      "Number of extracted samples: 1865\n",
      "Number of accurate extracted samples: 1865\n",
      "Precision: 1.0, recall: 0.07087481948772517\n",
      "dataset: census numeric, model: decision tree (repetition 0)\n",
      "Total time: 115.57s (training model: 0.03s, training explainer: 0.00s, experiment: 115.54s)\n",
      "Number of extracted samples: 1340\n",
      "Number of accurate extracted samples: 1340\n",
      "Precision: 1.0, recall: 0.1300592060564884\n",
      "dataset: census numeric, model: decision tree (repetition 1)\n",
      "Total time: 115.22s (training model: 0.02s, training explainer: 0.00s, experiment: 115.20s)\n",
      "Number of extracted samples: 1380\n",
      "Number of accurate extracted samples: 1380\n",
      "Precision: 1.0, recall: 0.13394157041638358\n",
      "dataset: census numeric, model: decision tree (repetition 2)\n",
      "Total time: 115.26s (training model: 0.02s, training explainer: 0.02s, experiment: 115.23s)\n",
      "Number of extracted samples: 1427\n",
      "Number of accurate extracted samples: 1427\n",
      "Precision: 1.0, recall: 0.1385033485392604\n",
      "dataset: census numeric, model: decision tree (repetition 3)\n",
      "Total time: 115.46s (training model: 0.02s, training explainer: 0.00s, experiment: 115.45s)\n",
      "Number of extracted samples: 1376\n",
      "Number of accurate extracted samples: 1376\n",
      "Precision: 1.0, recall: 0.13355333398039407\n",
      "dataset: census numeric, model: decision tree (repetition 4)\n",
      "Total time: 115.24s (training model: 0.02s, training explainer: 0.00s, experiment: 115.22s)\n",
      "Number of extracted samples: 1403\n",
      "Number of accurate extracted samples: 1403\n",
      "Precision: 1.0, recall: 0.1361739299233233\n",
      "dataset: census numeric, model: decision tree (repetition 5)\n",
      "Total time: 115.50s (training model: 0.02s, training explainer: 0.00s, experiment: 115.48s)\n",
      "Number of extracted samples: 1338\n",
      "Number of accurate extracted samples: 1338\n",
      "Precision: 1.0, recall: 0.12986508783849365\n",
      "dataset: census numeric, model: decision tree (repetition 6)\n",
      "Total time: 115.50s (training model: 0.02s, training explainer: 0.02s, experiment: 115.46s)\n",
      "Number of extracted samples: 1351\n",
      "Number of accurate extracted samples: 1351\n",
      "Precision: 1.0, recall: 0.13112685625545958\n",
      "dataset: census numeric, model: decision tree (repetition 7)\n",
      "Total time: 115.50s (training model: 0.03s, training explainer: 0.00s, experiment: 115.47s)\n",
      "Number of extracted samples: 1393\n",
      "Number of accurate extracted samples: 1393\n",
      "Precision: 1.0, recall: 0.1352033388333495\n",
      "dataset: census numeric, model: decision tree (repetition 8)\n",
      "Total time: 115.33s (training model: 0.02s, training explainer: 0.00s, experiment: 115.31s)\n",
      "Number of extracted samples: 1353\n",
      "Number of accurate extracted samples: 1353\n",
      "Precision: 1.0, recall: 0.13132097447345434\n",
      "dataset: census numeric, model: decision tree (repetition 9)\n",
      "Total time: 115.34s (training model: 0.02s, training explainer: 0.02s, experiment: 115.31s)\n",
      "Number of extracted samples: 1353\n",
      "Number of accurate extracted samples: 1353\n",
      "Precision: 1.0, recall: 0.13132097447345434\n",
      "dataset: census numeric, model: random forest (repetition 0)\n",
      "Total time: 229.45s (training model: 0.09s, training explainer: 0.02s, experiment: 229.34s)\n",
      "Number of extracted samples: 1162\n",
      "Number of accurate extracted samples: 1162\n",
      "Precision: 1.0, recall: 0.11278268465495486\n",
      "dataset: census numeric, model: random forest (repetition 1)\n",
      "Total time: 230.81s (training model: 0.09s, training explainer: 0.00s, experiment: 230.72s)\n",
      "Number of extracted samples: 1134\n",
      "Number of accurate extracted samples: 1134\n",
      "Precision: 1.0, recall: 0.11006502960302825\n",
      "dataset: census numeric, model: random forest (repetition 2)\n",
      "Total time: 230.97s (training model: 0.09s, training explainer: 0.00s, experiment: 230.88s)\n",
      "Number of extracted samples: 1168\n",
      "Number of accurate extracted samples: 1168\n",
      "Precision: 1.0, recall: 0.11336503930893914\n",
      "dataset: census numeric, model: random forest (repetition 3)\n",
      "Total time: 231.99s (training model: 0.09s, training explainer: 0.00s, experiment: 231.89s)\n",
      "Number of extracted samples: 1100\n",
      "Number of accurate extracted samples: 1100\n",
      "Precision: 1.0, recall: 0.10676501989711734\n",
      "dataset: census numeric, model: random forest (repetition 4)\n",
      "Total time: 230.15s (training model: 0.10s, training explainer: 0.00s, experiment: 230.06s)\n",
      "Number of extracted samples: 1080\n",
      "Number of accurate extracted samples: 1080\n",
      "Precision: 1.0, recall: 0.10482383771716976\n",
      "dataset: census numeric, model: random forest (repetition 5)\n",
      "Total time: 230.46s (training model: 0.09s, training explainer: 0.00s, experiment: 230.37s)\n",
      "Number of extracted samples: 1108\n",
      "Number of accurate extracted samples: 1108\n",
      "Precision: 1.0, recall: 0.10754149276909639\n",
      "dataset: census numeric, model: random forest (repetition 6)\n",
      "Total time: 228.49s (training model: 0.09s, training explainer: 0.00s, experiment: 228.39s)\n",
      "Number of extracted samples: 1105\n",
      "Number of accurate extracted samples: 1105\n",
      "Precision: 1.0, recall: 0.10725031544210424\n",
      "dataset: census numeric, model: random forest (repetition 7)\n",
      "Total time: 230.94s (training model: 0.09s, training explainer: 0.02s, experiment: 230.83s)\n",
      "Number of extracted samples: 1075\n",
      "Number of accurate extracted samples: 1075\n",
      "Precision: 1.0, recall: 0.10433854217218286\n",
      "dataset: census numeric, model: random forest (repetition 8)\n",
      "Total time: 231.77s (training model: 0.09s, training explainer: 0.00s, experiment: 231.67s)\n",
      "Number of extracted samples: 1097\n",
      "Number of accurate extracted samples: 1097\n",
      "Precision: 1.0, recall: 0.10647384257012521\n",
      "dataset: census numeric, model: random forest (repetition 9)\n",
      "Total time: 228.26s (training model: 0.09s, training explainer: 0.00s, experiment: 228.17s)\n",
      "Number of extracted samples: 1049\n",
      "Number of accurate extracted samples: 1049\n",
      "Precision: 1.0, recall: 0.101815005338251\n",
      "dataset: census numeric, model: neural network (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 175.43s (training model: 11.43s, training explainer: 0.02s, experiment: 163.98s)\n",
      "Number of extracted samples: 1216\n",
      "Number of accurate extracted samples: 1216\n",
      "Precision: 1.0, recall: 0.11802387654081335\n",
      "dataset: census numeric, model: neural network (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 184.49s (training model: 11.64s, training explainer: 0.00s, experiment: 172.84s)\n",
      "Number of extracted samples: 1480\n",
      "Number of accurate extracted samples: 1480\n",
      "Precision: 1.0, recall: 0.1436474813161215\n",
      "dataset: census numeric, model: neural network (repetition 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 179.59s (training model: 11.45s, training explainer: 0.02s, experiment: 168.12s)\n",
      "Number of extracted samples: 1203\n",
      "Number of accurate extracted samples: 1203\n",
      "Precision: 1.0, recall: 0.11676210812384742\n",
      "dataset: census numeric, model: neural network (repetition 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 178.62s (training model: 11.50s, training explainer: 0.00s, experiment: 167.11s)\n",
      "Number of extracted samples: 972\n",
      "Number of accurate extracted samples: 972\n",
      "Precision: 1.0, recall: 0.09434145394545278\n",
      "dataset: census numeric, model: neural network (repetition 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 175.44s (training model: 11.59s, training explainer: 0.00s, experiment: 163.85s)\n",
      "Number of extracted samples: 1224\n",
      "Number of accurate extracted samples: 1224\n",
      "Precision: 1.0, recall: 0.1188003494127924\n",
      "dataset: census numeric, model: neural network (repetition 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 185.85s (training model: 11.42s, training explainer: 0.00s, experiment: 174.43s)\n",
      "Number of extracted samples: 1199\n",
      "Number of accurate extracted samples: 1199\n",
      "Precision: 1.0, recall: 0.1163738716878579\n",
      "dataset: census numeric, model: neural network (repetition 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 180.17s (training model: 12.28s, training explainer: 0.02s, experiment: 167.87s)\n",
      "Number of extracted samples: 965\n",
      "Number of accurate extracted samples: 965\n",
      "Precision: 1.0, recall: 0.09366204018247112\n",
      "dataset: census numeric, model: neural network (repetition 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 178.26s (training model: 12.06s, training explainer: 0.00s, experiment: 166.20s)\n",
      "Number of extracted samples: 1393\n",
      "Number of accurate extracted samples: 1393\n",
      "Precision: 1.0, recall: 0.1352033388333495\n",
      "dataset: census numeric, model: neural network (repetition 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 180.30s (training model: 12.27s, training explainer: 0.00s, experiment: 168.04s)\n",
      "Number of extracted samples: 1207\n",
      "Number of accurate extracted samples: 1207\n",
      "Precision: 1.0, recall: 0.11715034455983694\n",
      "dataset: census numeric, model: neural network (repetition 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 180.24s (training model: 12.37s, training explainer: 0.00s, experiment: 167.87s)\n",
      "Number of extracted samples: 1161\n",
      "Number of accurate extracted samples: 1161\n",
      "Precision: 1.0, recall: 0.11268562554595749\n",
      "dataset: census categorical, model: decision tree (repetition 0)\n",
      "Total time: 1043.56s (training model: 0.53s, training explainer: 0.19s, experiment: 1042.84s)\n",
      "Number of extracted samples: 14220\n",
      "Number of accurate extracted samples: 14220\n",
      "Precision: 1.0, recall: 0.788860534783091\n",
      "dataset: census categorical, model: decision tree (repetition 1)\n",
      "Total time: 1047.61s (training model: 0.53s, training explainer: 0.17s, experiment: 1046.91s)\n",
      "Number of extracted samples: 14153\n",
      "Number of accurate extracted samples: 14153\n",
      "Precision: 1.0, recall: 0.7851436813491623\n",
      "dataset: census categorical, model: decision tree (repetition 2)\n",
      "Total time: 1039.98s (training model: 0.56s, training explainer: 0.20s, experiment: 1039.22s)\n",
      "Number of extracted samples: 14057\n",
      "Number of accurate extracted samples: 14057\n",
      "Precision: 1.0, recall: 0.7798180406080106\n",
      "dataset: census categorical, model: decision tree (repetition 3)\n",
      "Total time: 1039.61s (training model: 0.58s, training explainer: 0.22s, experiment: 1038.81s)\n",
      "Number of extracted samples: 14165\n",
      "Number of accurate extracted samples: 14165\n",
      "Precision: 1.0, recall: 0.7858093864418063\n",
      "dataset: census categorical, model: decision tree (repetition 4)\n",
      "Total time: 1030.72s (training model: 0.52s, training explainer: 0.19s, experiment: 1030.01s)\n",
      "Number of extracted samples: 14195\n",
      "Number of accurate extracted samples: 14195\n",
      "Precision: 1.0, recall: 0.7874736491734162\n",
      "dataset: census categorical, model: decision tree (repetition 5)\n",
      "Total time: 1040.36s (training model: 0.53s, training explainer: 0.16s, experiment: 1039.67s)\n",
      "Number of extracted samples: 14117\n",
      "Number of accurate extracted samples: 14117\n",
      "Precision: 1.0, recall: 0.7831465660712305\n",
      "dataset: census categorical, model: decision tree (repetition 6)\n",
      "Total time: 1038.08s (training model: 0.53s, training explainer: 0.17s, experiment: 1037.38s)\n",
      "Number of extracted samples: 14166\n",
      "Number of accurate extracted samples: 14166\n",
      "Precision: 1.0, recall: 0.7858648618661933\n",
      "dataset: census categorical, model: decision tree (repetition 7)\n",
      "Total time: 1039.35s (training model: 0.66s, training explainer: 0.19s, experiment: 1038.51s)\n",
      "Number of extracted samples: 14131\n",
      "Number of accurate extracted samples: 14131\n",
      "Precision: 1.0, recall: 0.7839232220126484\n",
      "dataset: census categorical, model: decision tree (repetition 8)\n",
      "Total time: 1036.07s (training model: 0.69s, training explainer: 0.19s, experiment: 1035.20s)\n",
      "Number of extracted samples: 14219\n",
      "Number of accurate extracted samples: 14219\n",
      "Precision: 1.0, recall: 0.788805059358704\n",
      "dataset: census categorical, model: decision tree (repetition 9)\n",
      "Total time: 1036.76s (training model: 0.67s, training explainer: 0.17s, experiment: 1035.92s)\n",
      "Number of extracted samples: 14122\n",
      "Number of accurate extracted samples: 14122\n",
      "Precision: 1.0, recall: 0.7834239431931654\n",
      "dataset: census categorical, model: random forest (repetition 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1896.08s (training model: 11.03s, training explainer: 0.17s, experiment: 1884.88s)\n",
      "Number of extracted samples: 13927\n",
      "Number of accurate extracted samples: 13927\n",
      "Precision: 1.0, recall: 0.7726062354377011\n",
      "dataset: census categorical, model: random forest (repetition 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ml_ks\\venvs\\xai_new\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# This will run the experiment for each dataset and model combination\n",
    "\n",
    "results = run_all_experiments(CounterfactualTDE, dataset_dicts, model_dicts, random_state=0, num_queries=num_queries_dict, model_access=False, threads=threads, is_mem_inf=False, convert_cat_to_str=True, repeat=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1feb9a8",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Precision is the percentage of extracted samples that is actually from the training data. \n",
    "\n",
    "Recall is the ratio of the number extracted training samples to all training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb0af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T20:54:34.095962Z",
     "iopub.status.busy": "2022-10-29T20:54:34.091682Z",
     "iopub.status.idle": "2022-10-29T20:54:34.129628Z",
     "shell.execute_reply": "2022-10-29T20:54:34.126999Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31380dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T20:54:34.151825Z",
     "iopub.status.busy": "2022-10-29T20:54:34.147925Z",
     "iopub.status.idle": "2022-10-29T20:54:34.173325Z",
     "shell.execute_reply": "2022-10-29T20:54:34.169969Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "file_name = 'results/2-1-cf-training-data-extraction-results'\n",
    "if DATASET_HALF:\n",
    "    file_name += '_dataset_size_halved'\n",
    "results.to_csv(file_name + '.csv', index=False, na_rep='NaN', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054236f-8d24-4ad8-8b81-fb2ba96cd77b",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "In our experiments, training data extraction with counterfactuals drawn from the training data has a recall between 45% and 67% for numeric data and 30% to 64% for categorical data. Since the attack cannot produce any false positive samples, precision is always 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef338ab-a7ef-46aa-86f5-23ed8dc39a8b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}